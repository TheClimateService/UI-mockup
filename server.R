# app.R ##
# Reference:  	https://rstudio.github.io/shinydashboard/
# Icons:	http://fontawesome.io/icons/
#		http://getbootstrap.com/components/#glyphicons

# Notes:
#
#


server <- function(input, output, session) {

# -----------
# LOG IN
# -----------
  userDB = dbsheet10
   
  USER <- reactiveValues(LoggedIn = FALSE)
  
  observeEvent(input$btnLogin, {
    USER$ParentCorpID <- pull(subset(userDB, Username == input$Username, select = "ParentCorpID"))
    USER$ParentCorpName <- pull(subset(userDB, Username == input$Username, select = "ParentCorpName"))
    updateTabItems(session, 'sidebar', 'config')})
    
  output$login_response <- renderText({
    if (USER$LoggedIn == FALSE) {
        Id.username <- which(userDB$Username == input$Username)
        Id.password <- which(userDB$Password == input$Password)
        if (length(Id.username) > 0 & length(Id.password) > 0) {
          if (Id.username == Id.password) {
            USER$ParentCorpID <- pull(subset(userDB, Username == input$Username, select = "ParentCorpID"))
            enable('btnLogin')
            USER$LoggedIn <- TRUE
            }
        } else  {
          "User name or password doesn't match"
        }
    }
  })
  
# ----------------------------
#         CONFIGURE
# ----------------------------
   # UI Inputs

   # Read in James's locations csv (based on Terry's)
   # corpLocations <- readr::read_csv("data/TCSDB/locations.csv")

   # TCSDB in excel format is read in ui.R via:  source("./data/TCSDB/load_tcsdb.r")
   # The locations sheet is currently sheet 3.
   corpLocations = dbsheet3
   businessTypes = dbsheet13
   businessFunctions = dbsheet14
   # userdata now read below in each data type in order to have user see saved data without reinitiation of session.  XXX This may be inefficient when userdata gets very large.
   # userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)

   output$rbLocations <- renderUI({
     locs = pull(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName)))
     # radioButtons('rbLocations',label = 'Select a location to configure',c('All locations',unique(as.character(corpTable$Location))))
     # Note use of inline=TRUE below that is one way to handle long lists (e.g., Safran locations) that, when they extend below the bottom of the adjoining columns, cannot be selected.  This is now handled without setting inline=TRUE by making the buttons at the bottom of the Configure page a separate fluidRow.  There is a note to this effect in ui.R in the CORP CONFIG section.
     radioButtons('rbLocations',label='Select a location to configure', c('All locations',locs), inline=FALSE)
     #selectInput('rbLocations',label='Select a location to configure', c('All locations',locs))
   })

   output$businessTypes <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    btypes = pull(unique(subset(businessTypes, select = BusinessType)))
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations=='All locations')
    btype_from_userdata = as.character(entry$input.cbGroupBizType)
    selectInput('industry_sector',"Industry Sector",c(btypes),selected=btype_from_userdata,selectize = TRUE)
   })


   output$numEmployees <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtNumEmployees
    textInput('numEmployees',"Number of employees",width = "100px", value=n_from_userdata)
    #textInputRow('numEmployees',"Number of employees", value=n_from_userdata)
    #textInputRow('numEmployees2',"Number of employees2", value=n_from_userdata)
   })

   output$assetValue_tx90p <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_tx90p
    textInput('assetValue_tx90p',"Value of assets sensitive to high temperatures ($M)",width = "250px", value=n_from_userdata)
   })

   output$assetValue_pdsisc <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_pdsisc
    textInput('assetValue_pdsisc',"Value of assets sensitive to drought ($M)",width = "250px", value=n_from_userdata)
   })

   output$assetValue_coastalflood <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_coastalflood
    textInput('assetValue_coastalflood',"Value of assets sensitive to coastal flooding ($M)",width = "250px", value=n_from_userdata)
   })

   output$ghgEmissions <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtghgEmissions
    textInput('ghgEmissions',"GHG emissions at this location (Mtonnes/year))",width = "200px", value=n_from_userdata)
   })

   output$businessFunctions <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    bfunctions = pull(unique(subset(businessFunctions, select = BusinessFunction)))
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    bfunctions_from_userdata = as.character(entry$cbBusinessFunctions)
    dbfu = data.frame(bfunctions_from_userdata)
    bfunctions_from_userdata_list = do.call(rbind, str_split(dbfu$bfunctions_from_userdata, ', '))
    #a = dbfu2[1,1]
    #for(i in 1:length(dbfu2)) a = c(a,",",dbfu2[1,i])
    #for(i in 1:1) a = c(a,",",dbfu2[1,i])
    #bfunctions_from_userdata = paste("c(", as.character(entry$cbBusinessFunctions[1]), ")" )
    checkboxGroupInput('cbBusinessFunctions',"Business functions performed at this location",c(bfunctions),selected=bfunctions_from_userdata_list[1,])
   })

   #Maps

   output$facility_location_map <- renderLeaflet({
    map <- (
     leaflet(data = subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationID:lat)) %>%
       # addTiles() %>%
       # export below does not capture map tiles if addTiles() is used.
       # see https://www.rdocumentation.org/packages/leaflet/versions/1.1.0/topics/addProviderTiles and links therein to see specific providers.
       addProviderTiles("OpenStreetMap.Mapnik") %>%
       addScaleBar() %>%
       addMarkers(~lon, ~lat, popup = ~as.character(LocationName))
     )

    if(input$checkbox_plots4report_maps=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$rbLocations, "-map-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(map, plotfile)
      } #endif

    map
   })

   output$individual_location_map <- renderLeaflet({
    map <- (
     leaflet(data = subset(corpLocations, ParentCorpID == USER$ParentCorpID & LocationName == input$rbLocations, select = LocationID:lat)) %>%
       # addTiles() %>%
       # export below does not capture map tiles if addTiles() is used.
       # see https://www.rdocumentation.org/packages/leaflet/versions/1.1.0/topics/addProviderTiles and links therein to see specific providers.
       addProviderTiles("OpenStreetMap.Mapnik") %>%
       addScaleBar() %>%
       addMarkers(~lon, ~lat, popup = ~as.character(LocationName))
     )

    if(input$checkbox_plots4report_maps=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$rbLocations, "-map-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(map, plotfile)
      } #endif

    map
   })
   
   observeEvent(input$btnConfig, {
     updateTabItems(session, 'sidebar', 'analyze')})
   
   observeEvent(input$button_save_data_corp, {
        source("./data/TCSDB/save_user_data.r", local=TRUE)
	# Below is now also part of the runSE_with_userdata button.  However, it is also needed to update ./data/TCSDB/locationvalues4SE.csv and ./data/TCSDB/user_data.csv.latest.csv .
        system("./data/TCSDB/script_apply_userdata4SE ./data/TCSDB/user_data.csv ./data/scoring_engine/nonphysical/locationvalues4SE.csv")
        #userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
      })

# ----------------------------
#         CORP ANALYZE
# ----------------------------  
 
  # Added to assist in navigational awareness when using jump capability. 
  output$thiscorp_name_ticker <- renderText({
	name <- USER$ParentCorpName
	pcdata <- dbsheet4 %>% filter(dbsheet4$ParentCorpName==name)
	ticker <- pcdata$TickerSymbol
	exchange <- pcdata$Exchange
	p1=paste(name, " ", ticker, " ", exchange)
        p1
    }) # end renderText

  # Added for jump-to-drilldown capability. 
  observeEvent(input$jumpToCompanyDrilldown, {
     #portfolio <- input$inputLocationsPort
     #portfolioSheet <- dbsheet15
     #portfolio_members <- portfolioSheet %>% filter(portfolioSheet[[portfolio]]==1)
     #selected_portmember <- portfolio_members %>% filter(portfolio_members$TickerSymbol==input$rbportmembers)
     #USER$ParentCorpID <- selected_portmember$ParentCorpID
     #USER$ParentCorpName <- selected_portmember$ParentCorpName

     # The following don't work because they are reactive inputs.
     #input$selectInput_location_drilldown <- input$selectInput_location
     #input$selectscenario_drilldown <- input$selectInput_scenario
     #input$inputLocations_drilldown <- input$selectInput_location

     # The following cause no errors, but they don't change the location name passed to the drilldown plots, which use input$selectInput_location for the location name.  It should be possible to change the drilldown plotting code to use a variable like loc2use <- input$inputLocations_drilldown.  Then, when loc2use is updated below, the panel update should work.
     # XXX NEXT:  set loc2use as above at lines 525/6 defining locID and key for the hazard plot.
     loc2use <- input$selectInput_location
     scen2use <- input$selectInput_scenario
     updateTabsetPanel(session, "inTabset_corp_meth", selected = "corp_meth_drilldown")
     #updateTabItems(session, 'sidebar', 'config')
     #updateTabItems(session, 'sidebar', 'analyze')
     updateTabItems(session, 'sidebar', 'methodology')
    }) 

  # TCSDB in excel format is read in ui.R via:  source("./data/TCSDB/load_tcsdb.r")
  # The version of this table with scoring-engine outputs for RCP8.5 and 9 decades is sheet 9.
  # When using the decadal form, set the sliderInputYear to the decadal version in ui.R.
  # corpTable = dbsheet9
  #corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure_v3_locations.csv.damages.allDFs.with.nonphysical.csv")
  #corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.with.nonphysical.csv")
  corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")

  # UI Input selectors for the corporate finance page, based on the database values  
  output$selectInput_location <- renderUI({
    selectInput('inputLocations',"Locations",c('All locations', unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))),selected='All locations',selectize = TRUE)
  })
  
  output$selectInput_scenario <- renderUI({
    # XXX If corpTable is set to type reactiveValues and controlled with button_test_reset_data, the following is not initialized properly and does not get updated by the reset button.
    selectInput('inputScenarios',"Scenario",c(unique(as.character(corpTable$ScenarioName))),selected='RCP8.5',selectize = TRUE)
  })
  
  #barByRiskFactor
  output$barByRiskFactor <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")

    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }

    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      corpTable = select(corpTable, RiskFactorName, ValueAtRisk)
      corpTable = as.data.table(corpTable)
      corpTable = corpTable[,lapply(.SD,sum),by="RiskFactorName"]
    }

    barByRiskFactor <- plot_ly(x=corpTable$ValueAtRisk, y=corpTable$RiskFactorName, type = 'bar', orientation = 'h') %>% layout(margin = list(l=180, b=100)) %>% layout(xaxis = list(title = 'Impact ($M)'))

    if(input$checkbox_plots4report=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations, "-barByRiskFactor(", input$sliderInputYear,")-", Sys.Date(), ".png", sep="")
      #plotfile <- paste(dirname, USER$ParentCorpName, "-barByRiskFactor","-", input$inputLocations,"-", input$sliderInputYear, "-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(barByRiskFactor, plotfile)
      } #endif

    barByRiskFactor
  }) 
  
  #barByLocation
  output$barByLocation <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
    }
    ncorp <- pull(count(corpTable))

    barByLocation <- plot_ly(corpTable, x = ~Location, y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>% layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))

    if(input$checkbox_plots4report=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations, "-barByLocation(", input$sliderInputYear,")-", Sys.Date(), ".png", sep="")
      #plotfile <- paste(dirname, USER$ParentCorpName, "-barByLocation","-", input$inputLocations,"-", input$sliderInputYear, "-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(barByLocation, plotfile)
      } #endif
    
    barByLocation
  }) # end barByLocation 
  
  #stacked area by Time
  output$areaByTime <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID),]
      #corpTable = select(corpTable, RiskYear, ValueAtRisk)
      #corpTable = as.data.table(corpTable)
      #corpTable = corpTable[,lapply(.SD,sum),by="RiskYear"]
    }
    
    # to chart a time series, need to build a new datafame with additive traces. I'm sure there's a better way to do this.
    nriskyears = length(corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull())
    time_series = as.data.frame( matrix(0, nrow = nriskyears, ncol = 10, dimnames = list(c(1:nriskyears), c("RiskYear", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9"))) )

    time_series$RiskYear <- corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull()
    time_series$s1 <- corpTable %>% filter(TCFDSubCatName=='Policy and Legal') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$s2 <- corpTable %>% filter(TCFDSubCatName=='Technology') %>% group_by(RiskYear) %>% summarise(s2=sum(ValueAtRisk)) %>% select(s2) %>% pull()
    time_series$s3 <- corpTable %>% filter(TCFDSubCatName=='Market') %>% group_by(RiskYear) %>% summarise(s3=sum(ValueAtRisk)) %>% select(s3) %>% pull()
    time_series$s4 <- corpTable %>% filter(TCFDSubCatName=='Reputation') %>% group_by(RiskYear) %>% summarise(s4=sum(ValueAtRisk)) %>% select(s4) %>% pull()
    time_series$s5 <- corpTable %>% filter(TCFDSubCatName=='Acute') %>% group_by(RiskYear) %>% summarise(s5=sum(ValueAtRisk)) %>% select(s5) %>% pull()
    time_series$s6 <- corpTable %>% filter(TCFDSubCatName=='Chronic') %>% group_by(RiskYear) %>% summarise(s6=sum(ValueAtRisk)) %>% select(s6) %>% pull()
    time_series$s7 <- corpTable %>% filter(TCFDSubCatName=='Resource Efficiency') %>% group_by(RiskYear) %>% summarise(s7=sum(ValueAtRisk)) %>% select(s7) %>% pull()
    time_series$s8 <- corpTable %>% filter(TCFDSubCatName=='Energy Source') %>% group_by(RiskYear) %>% summarise(s8=sum(ValueAtRisk)) %>% select(s8) %>% pull()
    time_series$s9 <- corpTable %>% filter(TCFDSubCatName=='Resilience') %>% group_by(RiskYear) %>% summarise(s9=sum(ValueAtRisk)) %>% select(s9) %>% pull()

    # hack the stacking (plotly doesn't actually do stacking - it's a documented problem.)
  if(input$riskfactor_subset=="All") { 
    time_series$stack1 <- time_series$s1
    time_series$stack2 <- time_series$stack1 + time_series$s2
    time_series$stack3 <- time_series$stack2 + time_series$s3
    time_series$stack4 <- time_series$stack3 + time_series$s4
    time_series$stack5 <- time_series$stack4 + time_series$s5
    time_series$stack6 <- time_series$stack5 + time_series$s6
    time_series$stack7 <- time_series$stack6 + time_series$s7
    time_series$stack8 <- time_series$stack7 + time_series$s8
    time_series$stack9 <- time_series$stack8 + time_series$s9
    } # endif
    
# Draw the graph

  # Note that the plot is saved as object tplot under each conditional; this is needed to avoid the following:
  #    Error in UseMethod: no applicable method for 'ggplotly' applied to an object of class "NULL".

  if(input$riskfactor_subset=="Chronic physical + Carbon price") { 
    time_series$stack1 <- time_series$s1
    time_series$stack2 <- time_series$stack1 + time_series$s6
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal - Carbon Price', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Chronic', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))
    } # endif

  if(input$riskfactor_subset=="All") { 
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Technology', fill = 'tonexty') %>%
      add_trace(y = ~stack3, name = 'Market', fill = 'tonexty') %>%
      add_trace(y = ~stack4, name = 'Reputation', fill = 'tonexty') %>%
      add_trace(y = ~stack5, name = 'Acute', fill = 'tonexty') %>%
      add_trace(y = ~stack6, name = 'Chronic', fill = 'tonexty') %>%
      add_trace(y = ~stack7, name = 'Resource Efficiency', fill = 'tonexty') %>%
      add_trace(y = ~stack8, name = 'Energy Source', fill = 'tonexty') %>%
      add_trace(y = ~stack9, name = 'Resilience', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))
    } # endif

    areaByTime <- tplot

    if(input$checkbox_plots4report=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations, "-areaByTime(", input$sliderInputYear,")-", Sys.Date(), ".png", sep="")
      #plotfile <- paste(dirname, USER$ParentCorpName, "-areaByTime","-", input$inputLocations,"-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(areaByTime, plotfile)
      } #endif
    
    areaByTime

  }) # end areaByTime
  
  # TCFD stacked bar chart
  output$stackedCorpFinImpactsPlot <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      #corpTable = select(corpTable, TCFDCategoryName, ValueAtRisk)
      #corpTable = as.data.table(corpTable)
      #corpTable = corpTable[,lapply(.SD,sum),by="TCFDCategoryName"]
    }
    ncorp <- pull(count(corpTable))
    stackedCorpFinImpactsPlot <- plot_ly(corpTable, x = ~TCFDCategoryName, y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>% layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))
    #plot_ly(corpTable, x = list("Opportunity","Physical Risk","Transition Risk"), y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      #layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100), showlegend=TRUE)

    if(input$checkbox_plots4report=="TRUE") {
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations, "-financialImpacts(", input$sliderInputYear,")-", Sys.Date(), ".png", sep="")
      #plotfile <- paste(dirname, USER$ParentCorpName, "-stackedCorpFinImpactsPlot","-", input$inputLocations,"-", input$sliderInputYear, "-", Sys.Date(), ".png", sep="")
      plotfile <- gsub(" ", "", plotfile)
      export(stackedCorpFinImpactsPlot, plotfile)
      } #endif

    stackedCorpFinImpactsPlot

  }) # end stackedCorpFinImpactsPlot
  
  #Data table
  output$corpFinImpacts <- DT::renderDataTable({
     #colnames(corpTable) = c('Location','TCFD Category','Subcategory','Risk Factor','Scenario','Year','Value at Risk ($M)') #someday figure this out
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
      if (input$inputLocations != 'All locations') {
        corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
      }
      if (input$inputLocations == 'All locations') {
        corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      }
      corpTable[1:7]
  })

# --------------------------------------
#              CORP METHODOLOGY
# --------------------------------------

#  output$selectCausalVariable<- renderUI({
#    selectInput("selectCausalVariable","Causal Variable (Hazard)",c("Temperature","Coastal Flooding","Drought"),selected = c("Coastal Flooding"), selectize=TRUE)
#  })

#  output$selectDamageFunction<- renderUI({
#    selectInput("selectDamageFunction","Damage Function",c("Building Damage","Cooling","Corn Yield"),selected = c("Building Damage"), selectize=TRUE)
#  })

#  output$selectPeriod<- renderUI({
#    selectInput("selectPeriod","Time Period",choices = c("1980","1990","2000","2010","2020","2030","2040","2050","2060","2070","2080","2090","2100"), selected=c("2010"), selectize=TRUE)
#  })

  # UI Input selectors for Corporate/Methodology/Overall, based on the database values  
  output$selectInput_location_overall <- renderUI({
    selectInput('inputLocations_overall',"Select Location",c(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))), selectize = TRUE)
  })
  
  output$plot_selectHazard <- renderPlot({

   if(input$selectCausalVariable=="Temperature") {

	# Using LOCA data from 32 models at 4 locations near Phoenix, AZ, airport.
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(20,55,0.5)
      plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topleft", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)

  } # endif

   if(input$selectCausalVariable=="Drought Severity") {
	source("./data/drought/script_pdsisc_pdfs.r")
   }

   if(input$selectCausalVariable=="Coastal Flooding") {

	source("./data/sealevel_world/input4_plot_sealevel_data_world_ewl_slr.r", local=TRUE)

	if(toString(ele$RLm2yr)!="NA") {
	   show_sealevel_world_plots <- "TRUE"
	   source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)
	}

	if(toString(ele$RLm2yr)=="NA") {
	   source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr_null_data.r", local=TRUE)
	}
   }

  }) # end output$plot_selectHazard
  
  # UI Input selectors for Corporate/Methodology/Drilldown, based on the database values  
  output$selectInput_location_drilldown <- renderUI({
    selectInput('inputLocations_drilldown',"Select Location",c(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))), selectize = TRUE)
  })
 
 
  #output$plot_selectHazard_drilldown <- renderPlot({
  #output$plot_selectHazard_drilldown <- renderImage({
  output$plot_selectHazard_drilldown <- renderPlotly({

   #if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)" | input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)" | input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {

	# Processed drought data is read into dataframe d by ./data/drought/load_drought_data.r, which is sourced at the beginning of server.R.
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	# input$drought_facility is set from TechnicalDetails/LocalizedClimateProbabilities/Drought and consists of concatenated LocationID_ParentCorpID_LocationName generated by script_build_nonphysical within the SE.
	# input$inputLocations_drilldown is set from Corporate/Methodology/Drilldown/selectInput_location_drilldown and consists of just the LocationName.

	# The following sets up the graph based on location selected in TechnicalDetails/LocalClimate/Drought.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	#fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)

	# The following sets up the graph based on location selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
	  nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	  #nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc.nexgddp.rcp85", header=FALSE)
	  # The following sets up the graph based on location selected in TechnicalDetails/LocalClimate/Drought.
	  # values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	  # The following sets up the graph based on location selected in Corporate/Analyze.
	  # The SE is run on drought data with one historical period (1950-99) and 9 future periods.  See script_runall_physical.  Using the nex-gddp data, there are three sets of values for pdsi, scpdsi, and zindex in the table read into nd.  For scpdsi, use the second set in colums V18:V27.
	  #values = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  #firstfield = values$V8
	  values = nd %>% filter(nd$V1==key) %>% select(V18:V27)
	  firstfield = values$V18
	  periods = c("1950-99","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = 100*as.numeric( t(values) )
	  ylabel = "Ann. Prob. of 90th-pctile Drought (%)"
    	  yrange <- c(0,200)
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
	  nd = read.table("./data/scoring_engine/tmax90pct/TCSDB_structure.locations.csv.tx90p", header=FALSE)
	  # The SE is run on tmax90p data with one historical period (1970-99) and 9 future periods.  See script_runall_physical.  
	  # Note that there are 5 historical periods in the data, but the last one (1970-99) is used as the baseline for scoring of tmax90p impacts.
	  values = nd %>% filter(nd$V1==key) %>% select(V12,V17:V25)
	  firstfield = values$V12
	  periods = c("1970-99","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = as.numeric( t(values) )
	  ylabel = "Percent of Days Above 90th Percentile"
    	  yrange <- c(0,100)
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Carbon Price") {
	  nd = read.table("./data/scoring_engine/carbonprice/TCSDB_structure.locations.csv.carbonprice", header=FALSE)
	  # The SE is run on carbonprice data with one historical period and 9 future periods.  See script_runall_physical.  
	  values = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  firstfield = values$V8
	  periods = c("Hist","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = as.numeric( t(values) )
	  ylabel = "Carbon Price (US$2005/t CO2)"
    	  yrange <- c(0,150)
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
	  # The SE is run on coastal-flood data and finds the annual probability of the historical 100-year flood level for 9 future periods.  See script_runall_physical.  
	  data = read.table("./data/scoring_engine/coastalflooding/input4r.nearest.gtsr.segment", header=TRUE)
	  data2 = read.table("./data/scoring_engine/coastalflooding/future_annprob_fromR", header=TRUE)
	  locs <- select(data, LocationID_ParentCorpID_LocationName)
	  annPhist100_historical <- matrix(0.01, nrow=length(locs))
	  histvalues <- data.frame(annPhist100_historical)
	  nd <- cbind(locs, histvalues, data2)
	  values = nd %>% filter(nd$LocationID_ParentCorpID_LocationName==key) %>% select(annPhist100_historical:annPhist100_rcp85_2090)
	  firstfield = values$annPhist100_rcp85_2010
	  #nd = read.table("./data/scoring_engine/tmax90pct/TCSDB_structure.locations.csv.tx90p", header=FALSE)
	  #values = nd %>% filter(nd$V1==key) %>% select(V12,V17:V25)
	  #firstfield = values$V12
	  periods = c("Hist","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = 100*as.numeric( t(values) )
	  ylabel = "Annual Probability of 100-year Flood Level (%)"
    	  yrange <- c(0,200)
	  legend_nodata="Does not apply; location not close to coast."
	} # endif on coastal flooding

       p <- function() { 
	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,200), xlab="Period", ylab=ylabel, xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
	# For coastal flooding, the following line corresponds to the lower limit on the future value of the return period of the historical 100-year return level.  This is applied in ./data/scoring_engine/coastal_flooding/script_estimate_future_rp_v1.r.  This is currently set to 1.0, so the annual probability has an upper limit of 100%.
	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
	   abline(h=100, col = "red", lty=2)  }
     	if(firstfield=="No_data" | firstfield=="Inf") { 
	   legend("center", legend=legend_nodata)
	   #legend("center", legend=legend_nodata, bg="red", text.col="white", text.font=2)
	  } else {
     	   legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
	}
       } # end p function

       # Set up data for plotting by ggplot or plot_ly.
       df2 <- data.frame(grp = factor(periods), val = tvalues, row.names=NULL)

       # fct_inorder orders the groups according to how they are constructed, rather than alphabetically.  See library(forcats).
       pgg <- function() { 
	ggplot(df2, aes(x=fct_inorder(grp), y=val, group=1)) +
	  geom_line()
       } # end pgg function

      # Set directory and plotfile names.
      #dirname <- paste("./report/",key,"/")
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      system( paste("mkdir",dirname) )
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations_drilldown, "-hazard-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations_drilldown, "-hazard-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, input$inputLocations_drilldown, "-hazard", "-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, key, "-hazard", "-", locID,"-", Sys.Date(), ".png", sep="")
      #plotfile <- paste(dirname, key, "-hazard", "-", locID,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, key, "-hazard", "-", input$selectCausalVariable_drilldown, "-", locID,"-", Sys.Date(), ".ps", sep="")
      plotfile <- gsub(" ", "", plotfile)
      plotfile_ps <- paste(plotfile, ".ps", sep="")
      plotfile_png <- paste(plotfile, ".png", sep="")

      # Optional ps and png images for use in renderImage
      # png and postscript call a plotting function, not a plot.  p above is now a function.
      # Create .ps image.
     	# setEPS()
      	# postscript(plotfile_ps,width=6,height=4)
      	# p()
      	# dev.off()
      # Create .png since renderImage (on Safari, at least) is not showing the .ps image.
      	# png(plotfile_png)
      	# Note that print for the ggplot version is required below.
      	# print( pgg() ) 
      	# dev.off()

      # When using renderImage, show the .png version in the shiny app.
      # list(src = plotfile_png, height="300px", alt = paste("hazard plot"))
      #plotPNG(func=p(), plotfile)
      #	p()

      # Use ggplot form, if desired.
      # ggplotly( pgg() )

    # Version for plot_ly.
    # Enforce the order of the categories as given in periods, otherwise they are plotted alphabetically.
    xform <- list(title="Period", categoryorder="array", categoryarray=periods)
    yform <- list(title=ylabel, range=yrange)
    marform <- list(l = 50, r = 50, b = 80, t = 40, pad = 4)
    if(firstfield=="No_data" | firstfield=="Inf") { message=legend_nodata } else { message="" }
    # Reference for annotations:  https://plot.ly/r/reference/#layout-annotations
    ply <- plot_ly(df2, x=~grp, y=~val, type='scatter', mode='lines', fill='tonexty', color=I("green") ) %>% 
           layout(xaxis = xform, yaxis = yform, margin=marform, title=paste("Hazard:",ylabel), 
		titlefont=list(family = "sans serif", size = 14, color = 'black'),
		  annotations=list(text=message, showarrow=FALSE, xref="paper" , yref="paper", x=0.5, y=0.5) )

    # Export for report.
    if(input$checkbox_plots4report_drilldown=="TRUE") {
      system( paste("mkdir",dirname) )
      export(ply, plotfile_png)
      } #endif

    ply

    #}, deleteFile=FALSE) # end output$plot_selectHazard_drilldown as renderImage
  }) # end output$plot_selectHazard_drilldown as renderPlot or renderPlotly
 
  output$plot_selectHazard_drilldown_testing <- renderPlotly({
    #if(input$checkbox_showtestplots=="TRUE") {
	# The following sets up the graph based on location selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	  nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc.nexgddp.rcp85", header=FALSE)
	  # The NEX-GDDP data is organized into values for 10 periods.  Two historical decades and 8 future decades.  After 7 location-related fields, there are three sets of 10 values for pdsi, scpdsi, and the zindex.
	  values_pdsi = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  values_scpdsi = nd %>% filter(nd$V1==key) %>% select(V18:V27)
	  values_zindex = nd %>% filter(nd$V1==key) %>% select(V28:V37)
	  tvalues_pdsi = 100*as.numeric( t(values_pdsi) )
	  tvalues_scpdsi = 100*as.numeric( t(values_scpdsi) )
	  tvalues_zindex = 100*as.numeric( t(values_zindex) )
	  firstfield = values_pdsi$V8
	  periods = c("1980s","1990s","2020s","2030s","2040s","2050s","2060s","2070s","2080s","2090s")
	  ylabel = "Ann. Prob. of 90th-pctile Level (%)"
    	  yrange <- c(0,100)
	  legend_nodata="No data available at this location."

       # Set up data for plotting by ggplot or plot_ly.
       df2 <- data.frame(grp=factor(periods), valp=tvalues_pdsi, vals=tvalues_scpdsi, valz=tvalues_zindex, row.names=NULL)

    # Enforce the order of the categories as given in periods, otherwise they are plotted alphabetically.
    xform <- list(title="Period", categoryorder="array", categoryarray=periods)
    yform <- list(title=ylabel, range=yrange)
    marform <- list(l = 50, r = 50, b = 80, t = 40, pad = 4)
    if(firstfield=="No_data" | firstfield=="Inf") { message=legend_nodata } else { message="" }
    # Reference for annotations:  https://plot.ly/r/reference/#layout-annotations
    #ply <- plot_ly(df2, x=~grp, y=~valp, type='scatter', mode='lines', fill='tonexty', color=I("green"), name='pdsi' ) %>% 
    ply <- plot_ly(df2, x=~grp, y=~valp, type='scatter', mode='lines', color=I("blue"), name='pdsi' ) %>% 
	   add_trace(y = ~vals, name='sc_pdsi', mode='lines', color=I("green")) %>%
	   add_trace(y = ~valz, name='z index', mode='lines', color=I("red")) %>%
           layout(xaxis = xform, yaxis = yform, margin=marform, title=paste("Hazard:",ylabel), 
		titlefont=list(family = "sans serif", size = 14, color = 'black'),
		  annotations=list(text=message, showarrow=FALSE, xref="paper" , yref="paper", x=0.5, y=0.5) )

    ply
   #} # endif on show test plots
  }) # end output$plot_selectHazard_drilldown_testing as renderPlot or renderPlotly

  output$plot_selectHazard_drilldown_testing2 <- renderPlotly({
    #if(input$checkbox_showtestplots=="TRUE") {
	# The following sets up the graph based on location selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	  #nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc.nexgddp.rcp85_minus2degC", header=FALSE)
	  nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc.nexgddp.rcp45", header=FALSE)
	  # The NEX-GDDP data is organized into values for 10 periods.  Two historical decades and 8 future decades.  After 7 location-related fields, there are three sets of 10 values for pdsi, scpdsi, and the zindex.
	  values_pdsi = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  values_scpdsi = nd %>% filter(nd$V1==key) %>% select(V18:V27)
	  values_zindex = nd %>% filter(nd$V1==key) %>% select(V28:V37)
	  tvalues_pdsi = 100*as.numeric( t(values_pdsi) )
	  tvalues_scpdsi = 100*as.numeric( t(values_scpdsi) )
	  tvalues_zindex = 100*as.numeric( t(values_zindex) )
	  firstfield = values_pdsi$V8
	  periods = c("1980s","1990s","2020s","2030s","2040s","2050s","2060s","2070s","2080s","2090s")
	  ylabel = "Ann. Prob. of 90th-pctile Level (%)"
    	  yrange <- c(0,100)
	  legend_nodata="No data available at this location."

       # Set up data for plotting by ggplot or plot_ly.
       df2 <- data.frame(grp=factor(periods), valp=tvalues_pdsi, vals=tvalues_scpdsi, valz=tvalues_zindex, row.names=NULL)

    # Enforce the order of the categories as given in periods, otherwise they are plotted alphabetically.
    xform <- list(title="Period", categoryorder="array", categoryarray=periods)
    yform <- list(title=ylabel, range=yrange)
    marform <- list(l = 50, r = 50, b = 80, t = 40, pad = 4)
    if(firstfield=="No_data" | firstfield=="Inf") { message=legend_nodata } else { message="" }
    # Reference for annotations:  https://plot.ly/r/reference/#layout-annotations
    #ply <- plot_ly(df2, x=~grp, y=~valp, type='scatter', mode='lines', fill='tonexty', color=I("green"), name='pdsi' ) %>% 
    ply <- plot_ly(df2, x=~grp, y=~valp, type='scatter', mode='lines', color=I("blue"), name='pdsi' ) %>% 
	   add_trace(y = ~vals, name='sc_pdsi', mode='lines', color=I("green")) %>%
	   add_trace(y = ~valz, name='z index', mode='lines', color=I("red")) %>%
           layout(xaxis = xform, yaxis = yform, margin=marform, title=paste("Hazard:",ylabel), 
		titlefont=list(family = "sans serif", size = 14, color = 'black'),
		  annotations=list(text=message, showarrow=FALSE, xref="paper" , yref="paper", x=0.5, y=0.5) )

    ply
   #} # endif on show test plots
  }) # end output$plot_selectHazard_drilldown_testing2 as renderPlot or renderPlotly
 
  output$plot_selectDamageFunction <- renderPlot({

   if(input$selectDamageFunction=="Building Damage") {
    # Select hazus DF from the SectorImpactFunctions/Fitted page.
    damage_function_name = as.character(input$hazus_damage_function_id)
    s = unlist( strsplit(damage_function_name, "_") )
    # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    #s2 = paste(s[1])
    damage_function_id = as.numeric(s[1])
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
   }

   if(input$selectDamageFunction=="Corn Yield") {
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
   }

   if(input$selectDamageFunction=="Cooling") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
   }

  }) # end output$plot_selectDamageFunction


  #output$plot_selectDamageFunction_drilldown <- renderPlot({
  output$plot_selectDamageFunction_drilldown <- renderPlotly({

   if(input$selectDamageFunction_drilldown=="Selected Location and Hazard") {

   #if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)" | input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)" | input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {

	dfdata = read.table("./data/scoring_engine/df.csv.cln", sep=",", header=TRUE)

	if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_pdsisc)
	}

	if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_tx90p)
	}

	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_coastalflood)
	}
	
	if(input$selectCausalVariable_drilldown=="Carbon Price") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_carbonprice)
	}
	
	  loc_df <- as.character(loc_df[1,])  # converts to character string for use in filter below.
	  xvalues <- dfdata %>% filter(dfdata$id==loc_df) %>% select(list_xvalues)
	  x2 <- strsplit(as.character(xvalues[1,]), ";", fixed=TRUE)
	  x3 <- as.numeric( unlist(x2) )
	  yvalues <- dfdata %>% filter(dfdata$id==loc_df) %>% select(list_yvalues)
	  y2 <- strsplit(as.character(yvalues[1,]), ";", fixed=TRUE)
	  y3 <- as.numeric( unlist(y2) )

	  xrange = c(min(x3), max(x3))
	  if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {xrange = c(min(x3), 1.1) }

	  xvariable <- dfdata %>% filter(dfdata$id==loc_df) %>% select(xvariable)
	  xvariable <- as.character(xvariable[1,])
	  yvariable <- dfdata %>% filter(dfdata$id==loc_df) %>% select(yvariable)
	  yvariable <- as.character(yvariable[1,])

	  xunits <- dfdata %>% filter(dfdata$id==loc_df) %>% select(xunits)
	  xunits <- as.character(xunits[1,])
	  yunits <- dfdata %>% filter(dfdata$id==loc_df) %>% select(yunits)
	  yunits <- as.character(yunits[1,])
	  
       p <- function() { 
	plot(x3, y3, type="l", lwd=3, lty=1, col="black", xlab=paste(xvariable,",",xunits), ylab=paste(yvariable,",",yunits), xlim=xrange )
	legend("topright", title="Damage Function", legend=loc_df)
	} 

    # Set up data for plotting by ggplot or plot_ly.
    df2 <- data.frame(grp = x3, val = y3, row.names=NULL)

    # Version for plot_ly.
    # Enforce the order of the categories as given in periods, otherwise they are plotted alphabetically.
    xform <- list(title=paste(xvariable,",",xunits), range=xrange)
    yform <- list(title=paste(yvariable,",",yunits))
    marform <- list(l = 50, r = 50, b = 80, t = 40, pad = 4)
    ply <- plot_ly(df2, x=~grp, y=~val, type='scatter', mode='lines', fill='tonexty', color=I("blue") ) %>% 
           layout(xaxis = xform, yaxis = yform, margin=marform, title=paste("Damage Function:",loc_df),
		titlefont=list(family = "sans serif", size = 14, color = 'black') )

    # Export for report.
    if(input$checkbox_plots4report_drilldown=="TRUE") {
      # Set directory and plotfile names.
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations_drilldown, "-vulnerability-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, input$inputLocations_drilldown, "-df", "-", loc_df,"-", Sys.Date(), sep="")
      plotfile <- gsub(" ", "", plotfile)
      plotfile_png <- paste(plotfile, ".png", sep="")

      system( paste("mkdir",dirname) )
      export(ply, plotfile_png)
      } #endif

    ply
    # Version for plot
    # p()

   } # end if(input$selectDamageFunction_drilldown=="Selected Location and Hazard")

  }) # end output$plot_selectDamageFunction_drilldown
 
  output$losscurve <- renderImage({list(src = "./images/Mandel-121514-graph.png", height="230px", alt = paste("loss curve"))
  }, deleteFile = FALSE)

  output$plot_losscurve2 <- renderPlot({

	ntimeperiods <- 4

   if(input$selectCausalVariable=="Temperature" & input$selectDamageFunction=="Cooling") {

	# The following creates functions f4avgload(t) and f4peakload(t).
        source("./functions/fit_elec_load_v1.r.noplot", local=TRUE)

	# Using LOCA data from 32 models at 4 locations near Phoenix, AZ, airport.
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
	tdist <- function(x) {dweibull(x, shape=shapes[1], scale=scales[1]) }
	if(input$selectPeriod=="2011-2030") {tdist <- function(x) {dweibull(x, shape=shapes[2], scale=scales[2]) } }
	if(input$selectPeriod=="2041-2060") {tdist <- function(x) {dweibull(x, shape=shapes[3], scale=scales[3]) } }
	if(input$selectPeriod=="2071-2090") {tdist <- function(x) {dweibull(x, shape=shapes[4], scale=scales[4]) } }
	tmin <- 20
	tmax <- 55
	t <- seq(tmin, tmax)
	tlen <- length(t)

	# Get the damage values and the probability values across the range of temperatures.
	damvals <- matrix(0, nrow=1, ncol=tlen)
	probvals <- matrix(0, nrow=1, ncol=tlen)
	for(i in 1:tlen) damvals[1,i] = f4avgload(i+tmin-1)
	for(i in 1:tlen) probvals[1,i] = tdist(i+tmin-1)

	# Get the expected value of the damage.
	eval <- sum(probvals * damvals)

	# Plot the product of the temperature distribution and the damage function.
	#fproduct <- function(t) { tdist(t) * f4avgload(t) }
	#plot(fproduct, xlim = c(min(t), max(t)) )

	# Plot the loss curve as probability versus damage values.
	plot(damvals, probvals, type="l", lwd=3, col="blue",
		main="Average Load Probability Distribution",
		xlab="Load (Mw) Relative to 15-18 degC",
		ylab="Probability")
	abline(v=eval, col = "blue", lty=2)
	#abline(h=0.01, col = "red", lty=2)
    	legend("topleft", inset=.01, "Expected Value", lwd=2, lty=2, col="blue")
	grid(col="lightgray")
	
     } # endif on temperature and cooling

   if(input$selectCausalVariable=="Drought Severity" & input$selectDamageFunction=="Corn Yield") {

	# The normal fits for 4 periods described by para2, para3, etc., were created by ./data/drought/script_pdsisc_pdfs.r .
	# defined above:  ntimeperiods <- 4
	function1 <- function(x) { dnorm(x, para2[1], para2[2]) }
	function2 <- function(x) { dnorm(x, para3[1], para3[2]) }
	function3 <- function(x) { dnorm(x, para4[1], para4[2]) }
	function4 <- function(x) { dnorm(x, para5[1], para5[2]) }

	# Set up return periods and calculate corresponding quantile values.  qnorm(1/rp) gives the value of the variable in the normal distribution that has cumulative probability <= 1/rp.  For example qnorm(0.2)=-.84, where the distribution has default values mean=0 and sd=1.
	# The following corresponds to return periods of 2, 5, 10, 20, 50, and 100 years.
	rp <- c(2, 5, 10, 20, 50, 100)
	#rp <- c(1, 2, 5, 10, 20, 50, 100)
	rp <- c(1, 1.5, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 100, 200, 500, 1000, 2000, 5000)
	#rp <- seq(1,500, by=0.5)
	qnorm_values <- qnorm(1/rp)
	#qnorm_values = c(qnorm(0.5), qnorm(0.2),qnorm(0.1),qnorm(0.05),qnorm(0.02),qnorm(0.01) )

	nvals <- length(rp)

	# Calculate values of the drought index corresponding to each return period.
	# The index-value formula is based on adjusting the qnorm values above that use mean=0, sd=1.  For example, qnorm(0.2, mean=m, sd=s)=qnorm(0.2)*s + m.
        index_values <- matrix(0, nrow=ntimeperiods, ncol=nvals)
	# index_values[1,] contains the drought-index values for the historical return periods.
	index_values[1,] <- qnorm_values * as.numeric(para2[2]) + as.numeric(para2[1])
	# The following are drought index values associated with the standard return periods in the future.  They are not used futher in this calculation.  See below.
	index_values[2,] <- qnorm_values * as.numeric(para3[2]) + as.numeric(para3[1])
	index_values[3,] <- qnorm_values * as.numeric(para4[2]) + as.numeric(para4[1])
	index_values[4,] <- qnorm_values * as.numeric(para5[2]) + as.numeric(para5[1])

	# This creates the DF f4yield_reduction_pct; note that the x variable is log10(drought return period in years).
    	source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
	
	# Get the damage values and the probability values across the range of temperatures.
	damvals <- matrix(0, nrow=1, ncol=nvals)
	probvals <- matrix(0, nrow=ntimeperiods, ncol=nvals)
	for(i in 1:nvals) damvals[1,i] = f4yield_reduction_pct( log(rp[i],10) )
	# Note that only the historical index_values[1,i] are used since these are the values of the drought index that correspond to the damages associated with the historical return periods.  The probabilities of these drought-index values change throught time.
	for(i in 1:nvals) probvals[1,i] = function1(index_values[1,i])
	for(i in 1:nvals) probvals[2,i] = function2(index_values[1,i])
	for(i in 1:nvals) probvals[3,i] = function3(index_values[1,i])
	for(i in 1:nvals) probvals[4,i] = function4(index_values[1,i])

	# Get the expected value of the damage for each time period.
	evals <- matrix(0, nrow=1, ncol=ntimeperiods)
	for(i in 1:ntimeperiods) evals[i] <- sum(probvals[i,] * damvals)/sum(probvals[i,])
	# XXX should the widths of the damvals intervals be used?
	#damvals_widths <- damvals
	#for(i in 2:nvals) damvals_widths[,i] <- damvals[,i] - damvals[,i-1]
	#for(i in 1:ntimeperiods) evals[i] <- sum(probvals[i,] * damvals_widths)

	#fproduct <- function(rp) { index_historical(rp) * f4yield_reduction_pct(rp) }
	
	#curve(dnorm(x, para2[1], para2[2]), from=-5, to=5, col = 3, ylim=c(0,0.5), ylab="Probability", xlab="Drought Severity Index (lower value = worse drought)")

	prob2plot <- probvals[1,]/sum(probvals[1,])
	eval2plot <- evals[1]
	if(input$selectPeriod=="2011-2030") {prob2plot <- probvals[2,]/sum(probvals[2,]); eval2plot <- evals[2]}
	if(input$selectPeriod=="2041-2060") {prob2plot <- probvals[3,]/sum(probvals[3,]); eval2plot <- evals[3]}
	if(input$selectPeriod=="2071-2090") {prob2plot <- probvals[4,]/sum(probvals[4,]); eval2plot <- evals[4]}

	# Plot the loss curve as probability versus damage values.
	plot(damvals, prob2plot, type="l", lwd=3, col="blue",
		main="Yield Reduction Probability Distribution",
		xlab="Yield Reduction (%)", xlim=c(0,100),
		ylab="Probability")
	abline(v=eval2plot, col = "blue", lty=2)
	#abline(h=0.01, col = "red", lty=2)
    	legend("topright", inset=.01, "Expected Value", lwd=2, lty=2, col="blue")
	grid(col="lightgray")

     } # endif on drought severity and corn yield

   if(input$selectCausalVariable=="Coastal Flooding" & input$selectDamageFunction=="Building Damage") {
	# The function for the rl distribution (prob versus rl) is defined in ./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r .

	source("./data/sealevel_world/input4_plot_sealevel_data_world_ewl_slr.r", local=TRUE)

	if(toString(ele$RLm2yr)!="NA") {

	  show_sealevel_world_plots <- "FALSE"
	  source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)

	  # rlvals are the calculated return levels for the current location, as determined in the script above.
	  #curve(f4rldistmodel, min(rlvals), max(rlvals))

    	# Select hazus DF from the SectorImpactFunctions/Fitted page.
    	damage_function_name = as.character(input$hazus_damage_function_id)
    	s = unlist( strsplit(damage_function_name, "_") )
    	damage_function_id = as.numeric(s[1])
        source("./data/hazus/function_extract_hazus_flood_depth_damage_return_damage_at_depth.r", local=TRUE)

	# Get the damage values and the probability values across the range of return levels.
	# There are 4 timeperiods, as defined above.
	nvals <- length(rlvals)
	damvals <- matrix(0, nrow=ntimeperiods, ncol=nvals)
	probvals <- matrix(0, nrow=ntimeperiods, ncol=nvals)

	# Drive damage values with a flood depth, rather than a return level.  RL can be used for local flood depth only if they are both referenced to the same local datum.  This means we need a local definition of flood level/severity.  See report from Sweet, et al, on local flood levels.
	# z[1] is the historical 2-year return level, in meters.  Use this as the base for determining flood depth. 
	depth_hist <- rlvals - z[1]
	depth_rcp85_2030 <- rlvals2 - z[1]
	depth_rcp85_2050 <- rlvals3 - z[1]
	depth_rcp85_2100 <- rlvals4 - z[1]
	for(i in 1:nvals) damvals[1,i] = get_hazus_damage_function_return_damage_at_depth(damage_function_id, depth_hist[i])
	for(i in 1:nvals) damvals[2,i] = get_hazus_damage_function_return_damage_at_depth(damage_function_id, depth_rcp85_2030[i])
	for(i in 1:nvals) damvals[3,i] = get_hazus_damage_function_return_damage_at_depth(damage_function_id, depth_rcp85_2050[i])
	for(i in 1:nvals) damvals[4,i] = get_hazus_damage_function_return_damage_at_depth(damage_function_id, depth_rcp85_2100[i])

	# Get the probability-distribution values from f4rldistmodels defined in ./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r .  There is one model for each time period
	for(i in 1:nvals) probvals[1,i] = f4rldistmodel(rlvals[i])
	for(i in 1:nvals) probvals[2,i] = f4rldistmodel2(rlvals2[i])
	for(i in 1:nvals) probvals[3,i] = f4rldistmodel3(rlvals3[i])
	for(i in 1:nvals) probvals[4,i] = f4rldistmodel4(rlvals4[i])

	# Get the expected value of the damage for each of the time periods.
	evals <- matrix(0, nrow=1, ncol=ntimeperiods)
	for(i in 1:ntimeperiods) evals[i] <- sum(probvals[i,] * damvals[i,])/sum(probvals[i,])

	prob2plot <- probvals[1,]/sum(probvals[1,])
	dam2plot <- damvals[1,]
	eval2plot <- evals[1]
	if(input$selectPeriod=="2011-2030") {prob2plot <- probvals[2,]/sum(probvals[2,]); dam2plot <- damvals[2,]; eval2plot <- evals[2]}
	if(input$selectPeriod=="2041-2060") {prob2plot <- probvals[3,]/sum(probvals[3,]); dam2plot <- damvals[3,]; eval2plot <- evals[3]}
	if(input$selectPeriod=="2071-2090") {prob2plot <- probvals[4,]/sum(probvals[4,]); dam2plot <- damvals[4,]; eval2plot <- evals[4]}

	# Plot the loss curve for the selected time period as probability versus damage values.
	# See note above on assumed flood level.
	plot(dam2plot, prob2plot, type="l", lwd=3, col="blue",
		main="Building Damage Probability Distribution",
		sub="(flood depth zero point = extreme water level with 2-year return period)",
		xlab="Building Damage (%)", xlim=c(0.0, max(dam2plot)),
		ylab="Probability", ylim=c(0.0, max(prob2plot))  )
	abline(v=eval2plot, col = "blue", lty=2)
	#abline(h=0.01, col = "red", lty=2)
    	legend("topleft", inset=.01, "Expected Value", lwd=2, lty=2, col="blue")
	grid(col="lightgray")

        } # endif on ele$RLm2yr

     } # endif on coastal flooding and building damage

  }) # end output$plot_losscurve2

  output$plot_expectedDamage <- renderPlotly({

   if(input$selectDamageFunction_drilldown=="Selected Location and Hazard" & input$selectPeriod_drilldown=="All Periods") { 
	#source("./functions/plot_area_by_time_single_hazards.r", local=TRUE)

    corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")

    if (input$inputLocations_drilldown != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations_drilldown),]
    }
    if (input$inputLocations_drilldown == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID),]
    }

    nriskyears = length(corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull())
    time_series = as.data.frame( matrix(0, nrow = nriskyears, ncol = 10, dimnames = list(c(1:nriskyears), c("RiskYear", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9"))) )

    time_series$RiskYear <- corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull()
    time_series$s1 <- corpTable %>% filter(RiskFactorName=='Temperature extremes') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$s2 <- corpTable %>% filter(RiskFactorName=='Drought') %>% group_by(RiskYear) %>% summarise(s2=sum(ValueAtRisk)) %>% select(s2) %>% pull()
    time_series$s3 <- corpTable %>% filter(RiskFactorName=='Coastal flooding') %>% group_by(RiskYear) %>% summarise(s3=sum(ValueAtRisk)) %>% select(s3) %>% pull()
    time_series$s4 <- corpTable %>% filter(RiskFactorName=='Carbon pricing') %>% group_by(RiskYear) %>% summarise(s4=sum(ValueAtRisk)) %>% select(s4) %>% pull()

  if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s1, name='Temperature (daily maximum 90th percentile)', type='scatter', mode = 'lines', fill = 'tonexty', color=I("red") )
    } # endif

  if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s2, name='Drought Severity (90th percentile)', type='scatter', mode = 'lines', fill = 'tonexty', color=I("red") )
    } # endif

  if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s3, name='Coastal Flooding (return period 100yr level)', type='scatter', mode = 'lines', fill = 'tonexty', color=I("red") )
    } # endif

  if(input$selectCausalVariable_drilldown=="Carbon Price") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s4, name='Carbon Price', type='scatter', mode = 'lines', fill = 'tonexty', color=I("red") )
    } # endif

   marform <- list(l = 50, r = 50, b = 80, t = 40, pad = 4)
   tplot <- tplot %>%
       layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(title = 'Period',showgrid = TRUE), margin = marform, title=paste("Risk:",input$selectCausalVariable_drilldown), 
	titlefont=list(family = "sans serif", size = 14, color = 'black') )

    # Export for report.
    if(input$checkbox_plots4report_drilldown=="TRUE") {
      # Set directory and plotfile names.
      dirname <- paste("./report/",USER$ParentCorpName,"/")
      dirname <- gsub(" ", "", dirname)
      plotfile <- paste(dirname, USER$ParentCorpName, "-", input$inputLocations_drilldown, "-risk-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      #plotfile <- paste(dirname, input$inputLocations_drilldown, "-damage", "-", input$selectCausalVariable_drilldown,"-", Sys.Date(), sep="")
      plotfile <- gsub(" ", "", plotfile)
      plotfile_png <- paste(plotfile, ".png", sep="")

      system( paste("mkdir",dirname) )
      export(tplot, plotfile_png)
      } #endif

    tplot

  } # endif on input$selectDamageFunction & input$selectPeriod

  }) # end output$plot_expectedDamage

# --------------------------------------
# TRACEBACK/DRILLDOWN
# --------------------------------------
  
# Note use of "sep" below to get line break via verbatimTextOutput in ui.R.

  output$tracebackHazard <- renderText({

  # XXX This structure does not return "Select a location" when input$inputLocations != 'All locations'

    if (input$inputLocations_overall == 'All locations') {
        p5=paste("Select a location.")
	p1=" "
	p3=" " 
    }

    if (input$inputLocations_overall != 'All locations') {
        p5 = paste("Temperature (all values) - ","Phoenix, AZ; 32 models; LOCA downscaling to 7-km resolution") 
        p1 = paste("Drought severity (all values) - ","Boise, Idaho")

	# locID is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        #locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_overall) %>% select(LocationID)
	#key <- paste(locID,USER$ParentCorpID,input$inputLocations_overall)
	#key <- gsub(" ","_",key)

	# Get locID, key, and key2 from the input for sealevel plots.
	source("./data/sealevel_world/input4_plot_sealevel_data_world_ewl_slr.r", local=TRUE)

        #p3 = paste("Sea-level projection - ",input$sealevelProjectionLocation)
        p3 = paste("Coastal Flooding (all EWLs with SLR) - ",as.character(key),"(",as.character(key2),")" )

    } 

	paste(p5," ",p1," ",p3,sep="\n")
  })

  output$tracebackHazard_drilldown <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	# The following is the location selected in TechnicalDetails/LocalClimate/Drought.
        #p2 = paste("Drought severity (90th percentile) - ",input$drought_facility)

        p2 = paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
        p2 = gsub(" ","_",p2)
        p2 = paste("Drought severity (90th percentile) - ",p2)
        p2b = paste("Drought severity (90th percentile) - ",input$inputLocations_drilldown)

        #p4 = paste("Extreme water-level - ",input$extremewaterLocation)
        p4 = paste("Coastal Flooding (return period 100yr level) - ",as.character(key))

        p6 = paste("Daily max temperature (90th percentile) - ",input$inputLocations_drilldown)

	paste(p6," ",p2b," ",p4,sep="\n")
        })

  output$tracebackVuln <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_overall) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_overall)
	key <- gsub(" ","_",key)

	p1 = paste("Cooling - auffhammer_peak_demand_electricity_2017")
	p2 = paste("Corn Yield - wang_crop_productivity_climate_midwestUS_2016")

	p3 = paste("Building Damage - HAZUS", as.character(input$hazus_damage_function_id))

	paste(p1," ",p2," ",p3,sep="\n")
        })

  output$tracebackVuln_drilldown <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	locvaluesSE <- read.table("./data/scoring_engine/nonphysical/locationvalues4SE.csv", header=TRUE, sep=";")
        locvalue_tx90p <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_tx90p)
        locvalue_pdsisc <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_pdsisc)
        locvalue_coastalflood <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_coastalflood)
        locvalue_carbonprice <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_carbonprice)
	#p1 = paste("Damage function - ",input$selectDamageFunction_drilldown)
	p1 = paste("Asset value at selected location for each damage function:")
	p2 = paste("Temperature (daily max 90th pctile)", as.character(locvalue_tx90p), "$M")
	p3 = paste("Drought Severity (90th percentile) ", as.character(locvalue_pdsisc), "$M")
	p4 = paste("Coastal Flooding (rtn pd 100yr lvl)", as.character(locvalue_coastalflood), "$M")
	p5 = paste("Carbon Price                       ", as.character(locvalue_carbonprice), "$M")

	paste(p1," ",p2," ",p3," ",p4," ",p5,sep="\n")
        })

  output$impactplot_screeningDFs_1 <- renderPlot({
    # dbsheet12 contains the TCSDB damage functions and created by load_tcsdb.r in ui.R.
    data <- dbsheet12 %>% filter(id==input$TCSDB_damage_function_id_1)
    xvalues <- data$list_xvalues
    yvalues <- data$list_yvalues
    # Handle the df data in the spreadsheet.  It is always entered as a string like "0;20;40;60;80;100".
    xvalues <- as.numeric( unlist( strsplit(xvalues, ";") ) )
    yvalues <- as.numeric( unlist( strsplit(yvalues, ";") ) )
    # Set up function.
    f2 = approxfun(xvalues, yvalues)
    # Set up plot.
    xlabel <- paste(data$xvariable," (",data$xunits,")", sep="")
    ylabel <- paste(data$yvariable," (",data$yunits,")", sep="")
    curve(f2, min(xvalues), max(xvalues), lwd=3, col="blue", main=data$description, xlab=xlabel, ylab=ylabel)
    #legend("topright", data$description)
  }) # end renderPlot

  output$impactplot_screeningDFs_2 <- renderPlot({
    # dbsheet12 contains the TCSDB damage functions and created by load_tcsdb.r in ui.R.
    data <- dbsheet12 %>% filter(id==input$TCSDB_damage_function_id_2)
    xvalues <- data$list_xvalues
    yvalues <- data$list_yvalues
    # Handle the df data in the spreadsheet.  It is always entered as a string like "0;20;40;60;80;100".
    xvalues <- as.numeric( unlist( strsplit(xvalues, ";") ) )
    yvalues <- as.numeric( unlist( strsplit(yvalues, ";") ) )
    # Set up function.
    f2 = approxfun(xvalues, yvalues)
    # Set up plot.
    xlabel <- paste(data$xvariable," (",data$xunits,")", sep="")
    ylabel <- paste(data$yvariable," (",data$yunits,")", sep="")
    curve(f2, min(xvalues), max(xvalues), lwd=3, col="red", main=data$description, xlab=xlabel, ylab=ylabel)
    #legend("topright", data$description)
  }) # end renderPlot

  output$impactplot_screeningDFs_3 <- renderPlot({
    # dbsheet12 contains the TCSDB damage functions and created by load_tcsdb.r in ui.R.
    data <- dbsheet12 %>% filter(id==input$TCSDB_damage_function_id_3)
    xvalues <- data$list_xvalues
    yvalues <- data$list_yvalues
    # Handle the df data in the spreadsheet.  It is always entered as a string like "0;20;40;60;80;100".
    xvalues <- as.numeric( unlist( strsplit(xvalues, ";") ) )
    yvalues <- as.numeric( unlist( strsplit(yvalues, ";") ) )
    # Set up function.
    f2 = approxfun(xvalues, yvalues)
    # Set up plot.
    xlabel <- paste(data$xvariable," (",data$xunits,")", sep="")
    ylabel <- paste(data$yvariable," (",data$yunits,")", sep="")
    curve(f2, min(xvalues), max(xvalues), lwd=3, col="green", main=data$description, xlab=xlabel, ylab=ylabel)
    #legend("topright", data$description)
  }) # end renderPlot

  output$impactplot_screeningDFs_4 <- renderPlot({
    # dbsheet12 contains the TCSDB damage functions and created by load_tcsdb.r in ui.R.
    data <- dbsheet12 %>% filter(id==input$TCSDB_damage_function_id_4)
    xvalues <- data$list_xvalues
    yvalues <- data$list_yvalues
    # Handle the df data in the spreadsheet.  It is always entered as a string like "0;20;40;60;80;100".
    xvalues <- as.numeric( unlist( strsplit(xvalues, ";") ) )
    yvalues <- as.numeric( unlist( strsplit(yvalues, ";") ) )
    # Set up function.
    f2 = approxfun(xvalues, yvalues)
    # Set up plot.
    xlabel <- paste(data$xvariable," (",data$xunits,")", sep="")
    ylabel <- paste(data$yvariable," (",data$yunits,")", sep="")
    curve(f2, min(xvalues), max(xvalues), lwd=3, col="orange", main=data$description, xlab=xlabel, ylab=ylabel)
    #legend("topright", data$description)
  }) # end renderPlot

  output$impactplot_screeningDFs_family <- renderPlot({
    # dbsheet12 contains the TCSDB damage functions and created by load_tcsdb.r in ui.R.
    data <- subset(dbsheet12, grepl(input$TCSDB_damage_function_id_family, dbsheet12$id))
    xvalues <- data$list_xvalues
    yvalues <- data$list_yvalues
    # Handle the df data in the spreadsheet.  It is always entered as a string like "0;20;40;60;80;100".
    xvalues2plot <- as.numeric( unlist( strsplit(xvalues[1], ";") ) )
    yvalues2plot <- as.numeric( unlist( strsplit(yvalues[1], ";") ) )
    # Set up function.
    # f2 = approxfun(xvalues, yvalues)
    # Set up plot.
    xlabel <- paste(data$xvariable," (",data$xunits,")", sep="")
    ylabel <- paste(data$yvariable," (",data$yunits,")", sep="")
    titlename <- paste(input$TCSDB_damage_function_id_family,"damage functions") 
    colorlist <- c("blue","red","green","orange","black","cyan","magenta","yellow","gray")
    #p <- plot(xvalues2plot, yvalues2plot, lwd=3, col="orange", main=data$description, xlab=xlabel, ylab=ylabel, type="b")
    p <- plot(xvalues2plot, yvalues2plot, ylim=c(0,100), lwd=3, col=colorlist[1], main=data$description, xlab="", ylab="", ann=FALSE, type="b")
    for(i in 2:length(xvalues)) {
        xvalues2plot <- as.numeric( unlist( strsplit(xvalues[i], ";") ) )
        yvalues2plot <- as.numeric( unlist( strsplit(yvalues[i], ";") ) )
	imodulo_color <- i %% length(colorlist)
	if(imodulo_color==0) col2use <- length(colorlist) else col2use <- imodulo_color
        p <- p + lines(xvalues2plot, yvalues2plot, lwd=3, col=colorlist[col2use], xlab="", ylab="", type="b", ann=FALSE)}
    #legend("topright", data$description)
    # Axes and xlab/ylab turned off above.  Add them in explicitly after the plot has been formed.  See https://nicercode.github.io/intro/plotting.html.  Title can be handled in the same way.
    axis(1)
    axis(2)
    mtext(xlabel, side = 1, line = 3)
    mtext(ylabel, side = 2, line = 3)
    title(titlename)
# ggplot has built-in grouping to do multiple lines, but the data must be treated with "melt".  See https://stackoverflow.com/questions/14704742/use-for-loop-to-plot-multiple-lines-in-single-plot-with-ggplot2.

  }) # end renderPlot

# --------------------------------------
# SYSTEM CONTROL
# --------------------------------------

  # Should be reactiveValue.  See pattern 3 at http://shiny.rstudio.com/articles/action-buttons.html
  corpTableNew <- reactiveValues()
  observeEvent(input$button_test_data_refresh, {
       corpTableNew <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
       #write.table(corpTableNew, "./junk")
      })

  observeEvent(input$button_runSE, {
      withProgress(message = 'Calculation in progress',
        detail = 'This may take a while...', value = 0, {
        #for (i in 1:15) {incProgress(1/15); Sys.sleep(0.25) }
	incProgress(1/3)
        system("./data/scoring_engine/script_runSE_from_app")
        }) # end withProgress

      #system("./data/scoring_engine/script_runSE_from_app")
      }) # end observeEvent

  observeEvent(input$button_runSE_with_userdata, {
      withProgress(message = 'Calculation in progress',
        detail = 'This may take a while...', value = 0, {
	incProgress(1/3)
        system("./data/TCSDB/script_apply_userdata4SE ./data/TCSDB/user_data.csv ./data/scoring_engine/nonphysical/locationvalues4SE.csv")
        system("./data/scoring_engine/script_runSE_from_app_with_userdata")
        }) # end withProgress
      }) # end observeEvent

  observeEvent(input$button_remove_report_graphics, {
      #dirname <- paste("./report/",USER$ParentCorpName,"/*map*png")
      dirname <- paste("./report/",USER$ParentCorpName,"/*png")
      dirname <- gsub(" ", "", dirname)
      system( paste("rm",dirname) )
      }) # end observeEvent

# ----------------------------
#         PORTFOLIO - ANALYZE
# ----------------------------  

  source("./server_portfolio_analyze.r", local=TRUE)
 
  # Added for jump capability.
   output$rb_portfolio_corp <- renderUI({
     portfolio <- input$inputLocationsPort
     portfolioSheet <- dbsheet15
     portfolio_members <- portfolioSheet %>% filter(portfolioSheet[[portfolio]]==1)
     tickers <- sort(portfolio_members$TickerSymbol)
     radioButtons('rbportmembers',label='Select portfolio member', tickers, inline=TRUE)
   })

  # Ref:  https://stackoverflow.com/questions/43552906/how-to-switch-between-navbar-tabs-with-a-button-r-shiny
  observeEvent(input$jumpToCompany, {
     portfolio <- input$inputLocationsPort
     portfolioSheet <- dbsheet15
     portfolio_members <- portfolioSheet %>% filter(portfolioSheet[[portfolio]]==1)
     selected_portmember <- portfolio_members %>% filter(portfolio_members$TickerSymbol==input$rbportmembers)
     USER$ParentCorpID <- selected_portmember$ParentCorpID
     USER$ParentCorpName <- selected_portmember$ParentCorpName
     updateTabsetPanel(session, "inTabset_corp_analysis", selected = "corp_analysis_byloc")
     #updateTabItems(session, 'sidebar', 'config')
     updateTabItems(session, 'sidebar', 'analyze')
    }) 


# ----------------------------
#         PORTFOLIO - SECTORS
# ----------------------------  

  source("./server_sector_analyze_dataprep.r", local=TRUE)
  source("./server_sector_analyze.r", local=TRUE)
   

  # ----------------------------
  #         REPORT
  # ----------------------------  
  
  output$report <- downloadHandler(

    filename = function() {
      paste("TCS-report-", USER$ParentCorpName, "-", Sys.Date(), ".docx", sep="")
    },

    content = function(file) {
      # Copy the report file to a temporary directory before processing it, in
      # case we don't have write permissions to the current working dir (which
      # can happen when deployed).
      # TT - note that knit and pandoc cannot find the images in the report directory unless they are also copied.  Hence disable the tempReport filepath for now.
      # tempReport <- file.path(tempdir(), "report.Rmd")
      # file.copy("report.Rmd", tempReport, overwrite = TRUE)
      
      file.copy("report.Rmd", "report_temp.Rmd", overwrite = TRUE)
      
      # Set up parameters to pass to Rmd document
      tempparams <- list(pParentCorpName = USER$ParentCorpName,
                     pTCFDGova = input$TCFDGova,
                     pTCFDGovb = input$TCFDGovb
                     )

      # Subset a table to pass to "knittr::kable in the RMD"
      corpKable = subset(corpTable,(ParentCorpID == USER$ParentCorpID & RiskYear == 2030), select = Location:ValueAtRisk)
      #corpKableBoise = subset(corpKable,Location == "Boise", select = Location:ValueAtRisk)

      # Make a portion of the final Rmd to handle the captured graphics.
        dirname <- gsub(" ", "",USER$ParentCorpName)
        command <- paste("ls ./report/",dirname,"/*png", sep="")
	glist <- system(command, intern=TRUE)
	#filenames <- noquote(glist)
	#write.table(filenames, "filenames.csv", col.names=FALSE, row.names=FALSE, quote=FALSE)
	#rmd_images <- paste("![plot](", noquote(glist), ")", sep="")
	#rmd_images <- gsub("SLASH", "\\\\", rmd_images)
	#rmd_images <- cat(rmd_images)
	#rmd_images <- paste("![plot \label{figurelabel}](", noquote(glist), ")", sep="")
	#rmd_images <- paste("![picture](", noquote(glist), ")", sep="")
	rmd_images <- paste(":", noquote(glist), "](", noquote(glist), "){ width=50% }", sep="")
	#rmd_images <- paste("![picture SLASHlabel{fig1}](", noquote(glist), ")", sep="")
	rmd_images <- noquote(rmd_images)
	write.table(rmd_images, "report_images.Rmd", col.names=FALSE, row.names=FALSE, quote=FALSE)
	system("./report_images_script_postprocess")
	system("cat report_temp.Rmd report_images.Rmd report_data_appendix.Rmd > report_final.Rmd")

      # Knit the document, passing in the `params` list, and eval it in a
      # child of the global environment (this isolates the code in the document
      # from the code in this app).
      # rmarkdown::render(tempReport, output_file = file,
      rmarkdown::render("report_final.Rmd", output_file = file,
                        params = tempparams
                        # envir = new.env(parent = globalenv())
      )

    } # end content
  ) # end downloadHandler
  

# Terry -----------------------------------------------------------

  # Functions
    source("./functions/fit_distributions.r")
    source("./functions/sigmoid.r")
    source("./functions/quadratic.r")
    source("./data/sealevel_us/function_annual_probability_withslr.r")

  # Data
    source("./data/transfer_functions/load_database_transfer_functions.r")
    source("./data/users/load_database_users.r")
    #source("./data/users/write_dbsqlite_test.r")
    fl_dept <- extract_hazus_functions()

  # Constants
    range_tempK = seq(270,320,0.01)
    # x-axis tickmarks are not labelled properly if the first period below is longer than 7 characters.
    periods <- c("1976-05", "2016-25", "2026-35", "2036-45", "2046-55", "2056-65", "2066-75", "2076-85", "2086-95")
    shapes <- c(81,82,83,84,85,86,87,88,89)
    scales <- c(292,293,294,295,296,297,298,299,300)
    thresholds <- c(285,290,295,300,305,310)
    initializer <- c(0,0,0,0,0,0,0)
    colors <- brewer.pal(length(thresholds), "Spectral")
    ltypes <- c(1:length(thresholds))
    labels <- c("285K","290K","295K","300K","305K","310K")
    slrScenarios = c("0.3_-_MED","0.5_-_MED","1.0_-_MED","1.5_-_MED","2.0_-_MED","2.5_-_MED")
    slrYears = c(2020,2030,2040,2050,2060,2070,2080,2090,2100)

# -----------
# Portfolio analysis
# -----------

  output$stockselected <- renderText({
#	stock_parameters = filter(stocks_nasdaq,Symbol==input$selected_nasdaq)
	stock_parameters = filter(stocks_nasdaq,Security.Name==input$selected_nasdaq)
	symbol = stock_parameters[1,1]
	name = stock_parameters[1,2]
	paste(symbol, "==", name,"== NASDAQ")
	})

  observeEvent(input$add2portfolio, {session$sendCustomMessage(type = 'testmessage',
      message = "This company will be added to the portfolio.") })

  output$stock_financial_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,3]
	p2 = stock_parameters[1,4]
	p3 = stock_parameters[1,5]
	paste(p1,p2,p3)
	# Use the following with htmlOutput in ui.R
	# if(p3 > 10){return(paste("<span style=\"color:red\">This is red text</span>"))} 
       	#        else{return(paste("<span style=\"color:blue\">This is blue text</span>"))}
	})

  output$stock_financial_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,3]
	p2 = stock_parameters[1,4]
	p3 = stock_parameters[1,5]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_overall_score_gauge <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = round( sum(stock_parameters[1,3:14])/12 )
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,3]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,4]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,5]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,6]
	p2 = stock_parameters[1,7]
	p3 = stock_parameters[1,8]
	paste(p1,p2,p3)
	})

  output$stock_transition_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,6]
	p2 = stock_parameters[1,7]
	p3 = stock_parameters[1,8]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_transition_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,6]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,7]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,8]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,9]
	p2 = stock_parameters[1,10]
	p3 = stock_parameters[1,11]
	paste(p1,p2,p3)
	})

  output$stock_physical_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,9]
	p2 = stock_parameters[1,10]
	p3 = stock_parameters[1,11]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_physical_gauge_temperature <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,9]
	# Score below is weighted value of percentage electrical load increases from /functions/damage_impacts_4function_elec_load.r .
	score_input = read.table("./output/score_input_elec_load.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_gauge_slr <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,10]
	# Score below is weighted value of percentage flood damage from /functions/damage_impacts_4function_hazus_flood_depth_damage.r .
	score_input = read.table("./output/score_input_flood.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_gauge_drought <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,11]
	# Score below is weighted value of percentage drought damage computed below when input$impact_selected == "Corn Yield (US, drought)" .
	score_input = read.table("./output/score_input_drought.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,12]
	p2 = stock_parameters[1,13]
	p3 = stock_parameters[1,14]
	paste(p1,p2,p3)
	})

  output$stock_opportunity_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,12]
	p2 = stock_parameters[1,13]
	p3 = stock_parameters[1,14]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_opportunity_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,12]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,13]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,14]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

# -----------
# Climate variables
# -----------

  output$temp_climplot1 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     #test.hist = read.table("./data/tasmax_day_BCSD_historical_r1i1p1_inmcm4_1950-2005.interpolated.merged.aggregated", header=TRUE)
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.1970-1979.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
     bins <- seq(min(x), max(x), length.out = input$bins + 1)
     #hist(x, breaks = bins, col = 'skyblue', border = 'white', main="1950-2005, inmcm4", xlab="Degrees K")
     hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 1970-1979, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.1981-2000.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 1981-2000", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	# Each row in the loca data below consists of 365 values for a single year at a given location from a single model.  The histogram includes values from all rows.
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.1981-2000.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 1981-2000", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot2 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_rcp85_r1i1p1_inmcm4_2006-2100.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2020-2029.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
     bins <- seq(min(x), max(x), length.out = input$bins + 1)
     #hist(x, breaks = bins, col = 'yellow', border = 'white', main="2006-2100, RCP8.5, inmcm4", xlab="Degrees K")
     hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2020-2029, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2011-2030.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2011-2030", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2011-2030.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2011-2030", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot3 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_historical_r1i1p1_CNRM-CM5_1950-2005.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2050-2059.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
    bins <- seq(min(x), max(x), length.out = input$bins + 1)
    #hist(x, breaks = bins, col = 'skyblue', border = 'white', main="1950-2005, CNRM-CM5", xlab="Degrees K")
    hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2050-2059, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2041-2060.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2041-2060", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2041-2060.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2041-2060", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot4 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_rcp85_r1i1p1_CNRM-CM5_2006-2100.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2090-2099.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
    bins <- seq(min(x), max(x), length.out = input$bins + 1)
    #hist(x, breaks = bins, col = 'yellow', border = 'white', main="2006-2100, RCP8.5, CNRM-CM5", xlab="Degrees K")
    hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2090-2099, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2071-2090.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2071-2090", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2071-2090.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2071-2090", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot5 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
    shapes <- c(81.8730, 93.0240, 88.9460, 84.7620, 95.8550, 90.0690, 86.1060, 90.3700, 91.5810)
    scales <- c(292.0320, 293.0880, 293.0820, 293.3870, 293.7670, 293.9150, 294.5310, 295.7390, 295.7960)
    #scales <- scales - 273.15
    #colors <- brewer.pal(length(shapes), "Spectral")
    colors <- brewer.pal(length(shapes), "Paired")
    ltypes <- c(1:length(shapes))
    labels <- c("1976-2005", "2016-25", "2026-35", "2036-45", "2046-55", "2056-65", "2066-75", "2076-85", "2086-95")
    x <- seq(275.15,315.15,1.0)
    xrange <- c(275.15,315.15)
    xcentigrade <- x - 273.15
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	xlim=xrange, 
	ylim=c(0,0.12), 
	main = "Temperature Distributions for Entire Year",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	xaxt="n"
	)
    for(i in 2:length(shapes) ) {
      lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
    #axis(1, at=x, labels=x)
    axis(1, at=x, labels=xcentigrade)
    legend("topright", inset=.05, title="Periods", labels, lwd=3, lty=ltypes, col=colors)
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the NORMAL distribution was best.
	# "1" "Normal 28.3077153023098 3.82693158121976"  "1" "Normal 29.6137309527853 3.97273119036855"  "1" "Normal 31.3714733780571 4.07573105989084"  "1" "Normal 33.3634844514267 4.25056671686859"
	# Fits were done in units of degC.
	shapes = c(28.3077153023098, 29.6137309527853, 31.3714733780571, 33.3634844514267)
	scales = c( 3.82693158121976, 3.97273119036855, 4.07573105989084, 4.25056671686859)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(15,45,0.5)
      plot(x,dnorm(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dnorm(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topright", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(30,55,0.5)
      plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topright", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)

  } # endif

  }) # end plot

  output$temp_facilities1 <- renderPlot({
	datadir <- "./data/temperature/nex-gddp/facilities/tasmax"
	input_facility <- input$temperature_facility
	input_scenario <- input$temperature_facility_scenario
	input_period <- input$temperature_facility_period
	input_season <- input$temperature_facility_season
	input_bins <- input$bins_temp_facilities

	source("./functions/setup_climate_variable_histogram.r", local=TRUE)
	d <- d - 273.15
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)"), xlab="Daily Maximum Temperature (degC)", xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$temp_facilities2 <- renderPlot({
	datadir <- "./data/temperature/nex-gddp/facilities/tasmax"
	input_facility <- input$temperature_facility2
	input_scenario <- input$temperature_facility_scenario2
	input_period <- input$temperature_facility_period2
	input_season <- input$temperature_facility_season2
	input_bins <- input$bins_temp_facilities

	source("./functions/setup_climate_variable_histogram.r", local=TRUE)
	d <- d - 273.15
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	hist(dt, breaks=bins, col = 'red', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)"), xlab="Daily Maximum Temperature (degC)", xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$temp_facilities3 <- renderPlot({
	datadir <- "./data/temperature/nex-gddp/facilities/tasmax"
	input_facility <- input$temperature_facility
	input_scenario <- input$temperature_facility_scenario
	input_period <- input$temperature_facility_period
	input_derived_variable <- input$temperature_facility_derived_variable
	input_bins <- input$bins_temp_facilities

	climvar <- "temperature"
	source("./functions/setup_climate_derived_variable_histogram.r", local=TRUE)
	# d <- d - 273.15  # derived variable max/min is in degC
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	bins <- unique(bins)
	label <- "Annual Number of Days Above Specified Temperature"
	if(input_derived_variable=="Maximum") label <- "Annual Maximum of Daily Maximum Temperature (degC)"
	if(input_derived_variable=="Minimum") label <- "Annual Minimum of Daily Maximum Temperature (degC)"
	if(substr(input_derived_variable,1,7)=="Average") label <- "Monthly Average of Daily Maximum Temperature (degC)"
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)\nMean =",format(mean(dt),digits=2) ), xlab=label, xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$temp_facilities4 <- renderPlot({
	datadir <- "./data/temperature/nex-gddp/facilities/tasmax"
	input_facility <- input$temperature_facility2
	input_scenario <- input$temperature_facility_scenario2
	input_period <- input$temperature_facility_period2
	input_derived_variable <- input$temperature_facility_derived_variable2
	input_bins <- input$bins_temp_facilities

	climvar <- "temperature"
	source("./functions/setup_climate_derived_variable_histogram.r", local=TRUE)
	# d <- d - 273.15  # derived variable max/min is in degC
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	bins <- unique(bins)
	label <- "Annual Number of Days Above Specified Temperature"
	if(input_derived_variable=="Maximum") label <- "Annual Maximum of Daily Maximum Temperature (degC)"
	if(input_derived_variable=="Minimum") label <- "Annual Minimum of Daily Maximum Temperature (degC)"
	if(substr(input_derived_variable,1,7)=="Average") label <- "Monthly Average of Daily Maximum Temperature (degC)"
	hist(dt, breaks=bins, col = 'red', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)\nMean =",format(mean(dt),digits=2) ), xlab=label, xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$temp_facilities5 <- renderPlot({
	datadir <- "./data/temperature/nex-gddp/facilities/tasmax"
	input_facility <- input$temperature_facility
	input_scenario <- input$temperature_facility_scenario
	input_period <- input$temperature_facility_period
	input_season <- input$temperature_facility_season
	input_bins <- input$bins_temp_facilities

	source("./functions/setup_climate_variable_distribution.r", local=TRUE)
	# The above returns the best fit row for the specified loc/scen/period.
	# XXX NEXT:  specify additional periods for the same location.

	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(30,55,0.5)
      plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	sub = paste("best fit", as.character(bestfit$type)),
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topright", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)

  }) # end plot

  output$precip_facilities1 <- renderPlot({
	datadir <- "./data/precipitation/nex-gddp/facilities/pr"
	input_facility <- input$precip_facility
	input_scenario <- input$precip_facility_scenario
	input_period <- input$precip_facility_period
	input_season <- input$precip_facility_season
	input_bins <- input$bins_precip_facilities

	source("./functions/setup_climate_variable_histogram.r", local=TRUE)
	d <- d*24*60*60
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins_precip_facilities + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)"), sub=paste("Maximum value =", max(dt), "(mm)"), xlab="Daily Precipitation (mm)", xlim=c(floor(min(dt)), ceiling(max(dt)/10) ) )

  }) # end plot

  output$precip_facilities2 <- renderPlot({
	datadir <- "./data/precipitation/nex-gddp/facilities/pr"
	input_facility <- input$precip_facility2
	input_scenario <- input$precip_facility_scenario2
	input_period <- input$precip_facility_period2
	input_season <- input$precip_facility_season2
	input_bins <- input$bins_precip_facilities

	source("./functions/setup_climate_variable_histogram.r", local=TRUE)
	d <- d*24*60*60
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins_precip_facilities + 1)
	hist(dt, breaks=bins, col = 'red', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)"), sub=paste("Maximum value =", max(dt), "(mm)"), xlab="Daily Precipitation (mm)", xlim=c(floor(min(dt)), ceiling(max(dt)/10) ) )

  }) # end plot

  output$precip_facilities3 <- renderPlot({
	datadir <- "./data/precipitation/nex-gddp/facilities/pr"
	input_facility <- input$precip_facility
	input_scenario <- input$precip_facility_scenario
	input_period <- input$precip_facility_period
	input_derived_variable <- input$precip_facility_derived_variable
	input_bins <- input$bins_precip_facilities

	climvar <- "precipitation"
	source("./functions/setup_climate_derived_variable_histogram.r", local=TRUE)
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	bins <- unique(bins)
	label <- "Annual Number of Days Above/Below Specified Precipitation Level"
	if(input_derived_variable=="Maximum") label <- "Annual Maximum of Daily Precipitation (mm)"
	if(input_derived_variable=="Minimum") label <- "Annual Minimum of Daily Precipitation (mm)"
	if(substr(input_derived_variable,1,5)=="Total") label <- "Total Precipitation (mm)"
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)\nMean =",format(mean(dt),digits=2) ), xlab=label, xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$precip_facilities4 <- renderPlot({
	datadir <- "./data/precipitation/nex-gddp/facilities/pr"
	input_facility <- input$precip_facility2
	input_scenario <- input$precip_facility_scenario2
	input_period <- input$precip_facility_period2
	input_derived_variable <- input$precip_facility_derived_variable2
	input_bins <- input$bins_precip_facilities

	climvar <- "precipitation"
	source("./functions/setup_climate_derived_variable_histogram.r", local=TRUE)
	dt <- t(d)
	bins <- seq(min(dt), max(dt), length.out = input_bins + 1)
	bins <- unique(bins)
	label <- "Annual Number of Days Above/Below Specified Precipitation Level"
	if(input_derived_variable=="Maximum") label <- "Annual Maximum of Daily Precipitation (mm)"
	if(input_derived_variable=="Minimum") label <- "Annual Minimum of Daily Precipitation (mm)"
	if(substr(input_derived_variable,1,5)=="Total") label <- "Total Precipitation (mm)"
	hist(dt, breaks=bins, col = 'red', border = 'white', main=paste(filename,"(21 models, NEX-GDDP)\nMean =",format(mean(dt),digits=2) ), xlab=label, xlim=c(floor(min(dt)), ceiling(max(dt)) ) )

  }) # end plot

  output$sealevel_extremes_plot1 <- renderPlot({
	location_parameters = filter(ewl,name==input$extremewaterLocation) %>% select(3:8)
      # z contains the location, scale, and shape parameters in rows 1, 3, and 5 of column 1.
      # z contains the +/-95% confidence interval of these parameters in rows 2, 4, and 6 of column 1.
	z = t(location_parameters)
	loc = z[1,1]
	sc = z[3,1]
	sh = z[5,1]
	return_periods = c(1.01,2,5,10,20,50,100,200,500)
	if(sh > 0) {yt=(-log((1-1/return_periods)))^(-sh);
		    return_levels = ((sc/sh)*(yt-1)) + loc}
	if(sh == 0) {yt=-log((1-1/return_periods));
		    return_levels = loc - sc*log(yt) }
	plot(return_levels, log="x", type="b", xlab="Return Period (years)", ylab="Level (m)", xaxt="n")
	axis(1, at=c(1:length(return_periods)), labels=return_periods)
	#grid(NULL, NULL, lwd=2)
	abline(v=return_periods, h=return_levels, col="gray", lty=3, lwd=2)
#axis(1, at=c(1:6), labels=c("location","location_range","scale","scale_range","shape","shape_param"))
  })

  output$sealevel_extremes_plot2 <- renderPlot({
	rtnlevels_m_hist = filter(world_ewl,CLSFID_LONGI_LATI==input$extremewaterLocation2) %>% select(7:15)
	z = t(rtnlevels_m_hist)
	plot(z, type="l",lwd=3,col="black", xlab="Return Period (years)", ylab="Return Level (m)", xaxt="n")
	#lines(z2, lwd=3, col="yellow")
	#lines(z3, lwd=3, col="green")
	axis(1, at=c(1:9), labels=c("2","5","10","25","50","100","250","500","1000"))
     	#legend("topleft", inset=.05, title="Scenarios",legend=c("RCP 8.5","RCP 4.5","RCP 2.6"), lwd=3, col=c("red","yellow","green"))
  })

  output$sealevel_extremes_plot3 <- renderPlot({
	loc <- input$extremewaterLocation2_with_slr_station
	scenario <- input$world_slr_scenario
	show_sealevel_world_plots <- "TRUE"
	source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)
  })

  output$sealevel_projections_plot1 <- renderPlot({
	profile1 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="0.3_-_MED") %>% select(7:17)
	z = t(profile1)
	profile2 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="0.5_-_MED") %>% select(7:17)
	z2 = t(profile2)
	profile3 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="1.0_-_MED") %>% select(7:17)
	z3 = t(profile3)
	profile4 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="1.5_-_MED") %>% select(7:17)
	z4 = t(profile4)
	profile5 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="2.0_-_MED") %>% select(7:17)
	z5 = t(profile5)
	profile6 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="2.5_-_MED") %>% select(7:17)
	z6 = t(profile6)
	plot(z, type="l",lwd=3,col="black", xlab="Year", ylab="Relative Local Sea Level Rise (cm)", xaxt="n")
	lines(z2, lwd=3, col="blue")
	lines(z3, lwd=3, col="green")
	lines(z4, lwd=3, col="yellow")
	lines(z5, lwd=3, col="orange")
	lines(z6, lwd=3, col="red")
	axis(1, at=c(1:11), labels=c("2000","2010","2020","2030","2040","2050","2060","2070","2080","2090","2100"))
     	legend("topleft", inset=.05, title="Scenarios (GMSL 2100)",legend=c("0.3m","0.5m","1.0m","1.5m","2.0m","2.5m"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
  })

  output$sealevel_projections_plot2 <- renderPlot({
	profile1 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(8:10)
	z = t(profile1)
	profile2 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(11:13)
	z2 = t(profile2)
	profile3 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(14:16)
	z3 = t(profile3)
	plot(z, type="l",lwd=3,col="red", xlab="Year", ylab="Relative Local Sea Level Rise (cm)", xaxt="n")
	lines(z2, lwd=3, col="yellow")
	lines(z3, lwd=3, col="green")
	axis(1, at=c(1:3), labels=c("2030","2050","2100"))
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP 8.5","RCP 4.5","RCP 2.6"), lwd=3, col=c("red","yellow","green"))
  })

  output$returnlevel_probability <- renderText({
	source("./data/sealevel_us/annual_probability_withslr.r", local=TRUE)
	#slrScenarios = c("0.3_-_MED","0.5_-_MED","1.0_-_MED","1.5_-_MED","2.0_-_MED","2.5_-_MED")
	#slrYears = c(2020,2030,2040,2050,2060,2070,2080,2090,2100)
	# slrScenarios and slrYears are defined in and returned as the second and third elements in a list by function_annual_probability_withslr.  The annual_probability_withslr matrix is the first element in the list.
	slrScenarios = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, input$returnLevel)[[2]]
	slrYears = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, input$returnLevel)[[3]]
	thresholds_flood_m <- c(0,1.5,3,4.5,6,7.5)
	thresholds_flood_m_midpoints = c(0.75, 2.25, 3.75, 5.25, 6.75)
	outputfile = "./output/output_flood_annual_prob.csv"
	annual_probability_withslr_1 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[1])[[1]]
	annual_probability_withslr_2 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[2])[[1]]
	annual_probability_withslr_3 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[3])[[1]]
	annual_probability_withslr_4 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[4])[[1]]
	annual_probability_withslr_5 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[5])[[1]]
	# The table is written explicitly here, rather than in function_annual_probability_     withslr.
	write.table(annual_probability_withslr_1,"./output/output_flood_annual_prob_level1.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_2,"./output/output_flood_annual_prob_level2.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_3,"./output/output_flood_annual_prob_level3.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_4,"./output/output_flood_annual_prob_level4.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_5,"./output/output_flood_annual_prob_level5.csv", row.names=slrScenarios, col.names=slrYears)

	if(input$slrScenario=="0.3 meter") selectedScenario="0.3_-_MED"
	if(input$slrScenario=="0.5 meter") selectedScenario="0.5_-_MED"
	if(input$slrScenario=="1.0 meter") selectedScenario="1.0_-_MED"
	if(input$slrScenario=="1.5 meters") selectedScenario="1.5_-_MED"
	if(input$slrScenario=="2.0 meters") selectedScenario="2.0_-_MED"
	if(input$slrScenario=="2.5 meters") selectedScenario="2.5_-_MED"
	#selectedScenario = paste(as.character(input$slrScenario),"_-_MED")
	if(input$slrYear=="2020") column=9
	if(input$slrYear=="2030") column=10
	if(input$slrYear=="2040") column=11
	if(input$slrYear=="2050") column=12
	if(input$slrYear=="2060") column=13
	if(input$slrYear=="2070") column=14
	if(input$slrYear=="2080") column=15
	if(input$slrYear=="2090") column=16
	if(input$slrYear=="2100") column=17
	slr_scenario_year = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario==selectedScenario) %>% select(column)
	location_parameters = filter(ewl,name==input$extremewaterLocation) %>% select(3:8)
      # z contains the location, scale, and shape parameters in rows 1, 3, and 5 of column 1.
      # z contains the +/-95% confidence interval of these parameters in rows 2, 4, and 6 of column 1.
	z = t(location_parameters)
	loc = z[1,1]
	sc = z[3,1]
	sh = z[5,1]
	return_level = as.numeric(input$returnLevel)
	# XXX need to handle sh==0
	if(sh != 0) {return_period = ((sh/sc)*(return_level-loc) + 1)^(1/sh);
		    a = 1/(1+exp(1/return_period)) }
	# Local slr change is in centimeters.
	return_level_withslr = return_level - slr_scenario_year/100
	# XXX need to handle sh==0
	if(sh != 0) {return_period_withslr = ((sh/sc)*(return_level_withslr-loc) + 1)^(1/sh) }
	annual_probability = round(100*1/return_period, digits=2)
	annual_probability_withslr = round(100*1/return_period_withslr, digits=2)
	#paste(input$slrScenario, input$slrYear, slr_scenario_year, "cm", loc,sc,sh,a,return_period,return_period_withslr,annual_probability,"%",annual_probability_withslr,"%")
	#paste("Historical:",annual_probability,"%","Future:",min(annual_probability_withslr,100),"%")
	#paste("Historical: ",annual_probability,"% -- ",input$slrYear,":",min(annual_probability_withslr,100),"%")
	p1 = paste("Historical - ",annual_probability,"%")
	p2 = paste(input$slrYear,"-       ",min(annual_probability_withslr,100),"%")
	paste(p1,p2,sep="\n")
	})

  output$sealevel_ewl_probabilities <- renderPlot({
	source("./data/sealevel_us/annual_probability_withslr.r", local=TRUE)
	position="topleft"
	if(input$returnLevel==1) position="topright"
    # slrYears are defined in annual_probability_withslr.r.
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(annual_probability_withslr[1,], type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Year", ylab="Annual Probability (%)", xaxt="n")
	lines(annual_probability_withslr[2,], col="blue")
	lines(annual_probability_withslr[3,], col="green")
	lines(annual_probability_withslr[4,], col="yellow")
	lines(annual_probability_withslr[5,], col="orange")
	lines(annual_probability_withslr[6,], col="red")
	axis(1, at=c(1:length(slrYears)), labels=slrYears)
     	legend(position, inset=.05, title="Scenarios (GMSL 2100)",legend=c("0.3m","0.5m","1.0m","1.5m","2.0m","2.5m"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
	})

output$drought_frequencies_lonlat <- renderPlot({
	# Processed drought data is read into dataframe d by /data/drought/load_drought_data.r, which is sourced at the beginning of server.R.
	lon=as.numeric(input$droughtlon)
	lat=as.numeric(input$droughtlat)
	source("./data/drought/process_drought_data.r", local=TRUE)
	#paste(input$droughtlon,input$droughtlat,upperlon,lowerlon,upperlat,lowerlat)
	#paste(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#plot(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	
	# Fields in d3 used below are lon, lat, and 9 periods defined in load_drought_data.r.
	values = select(d3, V3:V11)
	tvalues = 100*as.numeric( t(values) )
	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Period", ylab="Annual Probability (%)", xaxt="n")
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(d4[3,1]=="No_data") legend("center", title="NO DATA AVAILABLE AT SPECIFIED LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
	})

output$drought_frequencies_facility <- renderPlot({
	# Processed drought data is read into dataframe d by load_drought_data.r, which is sourced at the beginning of server.R.
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)
	lon=as.numeric(fac_selected[1,2])
	lat=as.numeric(fac_selected[1,3])

	#source("./data/drought/process_drought_data.r", local=TRUE)
	#paste(input$droughtlon,input$droughtlat,upperlon,lowerlon,upperlat,lowerlat)
	#paste(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#plot(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#values = select(d3, V3:V11)
	#tvalues = 100*as.numeric( t(values) )

	nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	tvalues = 100*as.numeric( t(values) )

	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Period", ylab="Annual Probability (%)", xaxt="n")
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(values$V8=="No_data") legend("center", title="NO DATA AVAILABLE AT THIS LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
	})

# -----------
# Impact functions (damage functions)
# -----------
  output$impactplot1 <- renderPlot({
    x = range_tempK
    plot(x,sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$impactplot2 <- renderPlot({
    x = range_tempK
    plot(x,quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$impactplot3 <- renderPlot({
    x = range_tempK
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$energy_expenditure_temperature <- renderPlot({
    source("./functions/energy_expenditure_temperature.r", local=TRUE)
  })

  output$labor_productivity_temperature <- renderPlot({
    source("./functions/labor_productivity_temperature.r", local=TRUE)
  })

  output$gdp_reduction_temperature <- renderPlot({
    source("./functions/gdp_reduction_temperature.r", local=TRUE)
  })

  output$mortality_temperature <- renderPlot({
    source("./functions/mortality_temperature.r", local=TRUE)
  })

  output$crop_yields_temperature <- renderPlot({
    source("./functions/crop_yields_temperature.r", local=TRUE)
  })

  output$crime_temperature <- renderPlot({
    source("./functions/crime_temperature.r", local=TRUE)
  })

  output$impactplot_elecload <- renderPlot({
    source("./functions/fit_elec_load_v1.r", local=TRUE)
  })

  output$impactplot_building_flood <- renderPlot({
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
	#s2 = paste(s[1])
    damage_function_id = as.numeric(s[1])
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
  })

  output$impactplot_corn_drought_return_period <- renderPlot({
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
  })

  output$impactplot_agriculture_brazil <- renderPlot({
    source("./functions/fit_agriculture_brazil_v1.r", local=TRUE)
  })

  output$impactplot_maize_us <- renderPlot({
    source("./functions/fit_maize_yield_us_hourly_temp.r", local=TRUE)
  })

  output$comingsoon <- renderImage({
    list(src = "./images/coming_soon.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig3_precip"))
  }, deleteFile = FALSE)

  output$impactplot4 <- renderImage({
    #filename <- normalizePath(file.path('./images/lobell_crop_yields_2017_fig1.png'))
    list(src = "./images/lobell_crop_yields_2017_fig1.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig1_temperature"))
  }, deleteFile = FALSE)

  output$impactplot5 <- renderImage({
    list(src = "./images/lobell_crop_yields_2017_fig3.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig3_precip"))
  }, deleteFile = FALSE)

  output$impactplot6 <- renderImage({
    list(src = "./images/troy_climate_indices_crop_yields_2015_fig2.png",width=300,height=300,alt = paste("troy_climate_indices_crop_yields_2015_fig2_multiplevariables"))
  }, deleteFile = FALSE)

  output$impactplot7 <- renderImage({
    list(src = "./images/carleton_hsiang_climate_dose_response_2016_fig3a.png",width=1000,height=500,alt = paste("carleton_hsiang_climate_dose_response_2016_fig3a_multiplesectors"))
  }, deleteFile = FALSE)

  output$impactplot8 <- renderImage({
    list(src = "./images/carleton_hsiang_climate_dose_response_2016_fig3b.png",width=1000,height=500,alt = paste("carleton_hsiang_climate_dose_response_2016_fig3b_multiplesectors"))
  }, deleteFile = FALSE)

  output$impactplot9 <- renderImage({
    list(src = "./images/thompson_cooling_water_Teffects_v1b_power_airtemp.png",width=600,height=450,alt = paste("thompson_power_generation_air_and_water_temperature"))
  }, deleteFile = FALSE)

  output$impactplot10 <- renderImage({
    list(src = "./images/thompson_cooling_water_Teffects_v1b_water.png",width=500,height=300,alt = paste("thompson_water_needed_water_temperature"))
  }, deleteFile = FALSE)

  output$impactplot_crops_wang <- renderImage({
    list(src = "./images/wang_crop_productivity_climate_midwestUS_2016_fig13.png",width=500,height=300,alt = paste("wang_crop_productivity_climate_midwestUS_2016_fig13"))
  }, deleteFile = FALSE)

  output$impactplot_crops_mishra <- renderImage({
    list(src = "./images/mishra_corn_soy_midwestUS_drought_2010_fig5.png",width=500,height=300,alt = paste("mishra_corn_soy_midwestUS_drought_2010_fig5"))
  }, deleteFile = FALSE)

  output$impactplot_crops_mhakbela <- renderImage({
    list(src = "./images/mhakbela_drought_wheat_canada_2010_fig2.png",width=500,height=300,alt = paste("mhakbela_drought_wheat_canada_2010_fig2"))
  }, deleteFile = FALSE)

# -----------
# Probability of Exceeding Thresholds
# -----------
  # Note that the shapes and scales values are for a pre-determined Weibull distribution for South Sudan.

  output$impactestimateplot1 <- renderPlot({
    #shapes <- c(81.8730, 93.0240, 88.9460, 84.7620, 95.8550, 90.0690, 86.1060, 90.3700, 91.5810)
    #scales <- c(292.0320, 293.0880, 293.0820, 293.3870, 293.7670, 293.9150, 294.5310, 295.7390, 295.7960)
    x <- seq(270,320,0.1)
    # pweibull is the CDF for dweibull.
    probexceed = matrix(0,length(thresholds),length(shapes))
    for(i in 1:length(shapes)) {probexceed[1,i] <- (1.0-pweibull(input$threshold,shapes[i],scales[i]) ) }
    #colnames(probexceed) <- periods
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(probexceed[1,], type="l", lwd=3, lty=1, col=colors[1], ylim=c(0,1.0), xlab="Time Periods", ylab="Probability of Exceeding Threshold", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
#   for(j in 1:length(thresholds)) { for(i in 1:length(shapes)) {probexceed[j,i] <- (1.0-pweibull(thresholds[j],shapes[i],scales[i]) ) } }
#    plot(probexceed[1,], type="l", lwd=3, lty=1, col=colors[1], ylim=c(0,1.0), xlab="Periods", ylab="Probability of Exceeding Threshold")
#    for(i in 2:length(thresholds) ) {
#      lines( probexceed[i,], lwd=3, lty=i, col=colors[i] )
#    }
#    legend("topright", inset=.01, title="Thresholds", labels, lwd=3, lty=ltypes, col=colors)
  })

# -----------
# Probabilistic Impact Estimate
# -----------
  output$impactestimateplot2 <- renderPlot({

  if (input$impact_selected == "Custom-built") {
    x <- seq(270,320,0.1)

# The following fails because the threshold inputs to damagej1/2 are functions of j.
#    damage = damage %>% fdamage(thresholds, shapes, sigmoidlimit, sigmoidsteepness, sigmoidmidpoint, quadraticlimit, quadraticshape, quadraticmidpoint, wt1, wt2)

    source("./functions/damage_impacts.r", local=TRUE)

    write.table(damage, file="./output/damage_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Probabilistic Impact(%)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
        current_risk = round(impactbyperiod_relative2baseperiod[2], digits=2)
	if(current_risk>=0) {thiscol="blue"} else {thiscol="red"}
        lines(c(2,2),c(0,current_risk), col=thiscol, lwd=2 )
        lines(c(1,length(periods)), c(0,0), col="green" )
        text(3.2,0,"CURRENT IMPACT (%) = ", font=4, col=thiscol)
        text(5.2,0,current_risk, font=4, col=thiscol)
    } #endif

  if (input$impact_selected == "Electricity Load (US; temperature)") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
    source("./functions/damage_impacts_4function_elec_load.r", local=TRUE)

    write.table(damage, file="./output/damage_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Change in Peak Load (Mw)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    } #endif

  if (input$impact_selected == "Building Damage (flood depth)") {
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    #source("./data/hazus/extract_hazus_flood_depth_damage.r", local=TRUE)
    #source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    source("./data/hazus/function_extract_hazus_flood_depth_damage_return_damage_at_depth.r", local=TRUE)

    #damage_function_id = input$hazus_damage_function_id
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    damage_function_id = as.numeric(s[1])
    #get_hazus_damage_function(damage_function_id)

    # The following reads the table of annual probabilities created by ./data/sealevel_us/annual_probability_withslr.r. Note that this is a dynamic table created by the selection of location and return level from the SLR section of the localized climate probabilities tab.  The table has rows for each GMSL scenario and colums for years 2020-2100 in 10-year increments.
    annual_prob_given_return_level = read.table("./output/output_flood_annual_prob.csv", header=TRUE)
    annual_prob_given_return_level1 = read.table("./output/output_flood_annual_prob_level1.csv", header=TRUE)
    source("./functions/damage_impacts_4function_hazus_flood_depth_damage.r", local=TRUE)

    write.table(damage, file="./output/damage_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Expected Building Damage for Selected RL (%)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    } #endif

  if (input$impact_selected == "Corn Yield (US, drought)") {
	# Processed drought data is read into dataframe d by load_drought_data.r, which is sourced at the beginning of server.R.
	location_name = "Selected Location"
	lon=as.numeric(input$droughtlon)
	lat=as.numeric(input$droughtlat)
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)
	if(input$use_facility_for_drought=="TRUE") {
		lon=as.numeric(fac_selected[1,2])
		lat=as.numeric(fac_selected[1,3]) 
		location_name = fac_selected[1,1]}

	#source("./data/drought/process_drought_data.r", local=TRUE)
	# process_drought_data.r produces the data vector d3.  It also writes this data to /output/output_drought_annual_prob.csv .
	# Fields in d3 used below are lon, lat, and fractional annual probabilities for 9 periods defined in load_drought_data.r.
	# For example, droughtPeriods = c("1950-99","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	#values = select(d3, V3:V11)
	#tvalues = 100*as.numeric( t(values) )

	nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	tvalues = 100*as.numeric( t(values) )

        source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
        historical_reduction_10yr_return_period = yield_reduction_pct[4]
        projected_return_period_same_reduction = (10/tvalues) * 10
	annual_expected_reduction = (-1.0*historical_reduction_10yr_return_period) * tvalues/100

    	impactbyperiod = annual_expected_reduction
    	impactbyperiod_relative2baseperiod = impactbyperiod - impactbyperiod[1]
    	write.table(impactbyperiod, file="./output/impactbyperiod_corn_yield_us_drought.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    	write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_corn_yield_us_drought.csv", row.names = FALSE, col.names = FALSE, sep=" ")

	# Calculate weighted vector of impact by period for climate score.
	weightbyperiod = c(0,80,10,5,1,1,1,1,1)
	#weightbyperiod = c(0,50,50,0,0,0,0,0,0)
	#percent_change = 100*(impactbyperiod/impactbyperiod[1] - 1.0)
	# Impacts on corn yields due to drought are annual percent yield reduction and are negative.
	percent_change = -1.0*(impactbyperiod - impactbyperiod[1])
	score_input_drought = sum( weightbyperiod*percent_change)/100
	#score_input_drought = sum( weightbyperiod*impactbyperiod_relative2baseperiod )/100
	write.table(score_input_drought, "./output/score_input_drought.csv", row.names=FALSE, col.names=FALSE)

	plot(annual_expected_reduction, type="l", lwd=3, lty=1, col="black", main=paste("Yield Change at",location_name,"(",lon,",",lat,")"), xlab="Periods", ylab="Expected Annual Yield Loss (%)", xaxt="n", ylim=c(-1.0*historical_reduction_10yr_return_period, 0))
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topright", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(values$V8=="No_data") legend("center", title="NO DATA AVAILABLE AT SPECIFIED LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
    } #endif

  if (input$impact_selected == "Agricultural Income (Brazil)") {
    return()
    } #endif

  if (input$impact_selected == "Maize Yield (US)") {
    return()
    } #endif

  })

  # Impact Function for impact estimate (controlled from impact-function tab)
  output$impactestimateplot3 <- renderPlot({
  
  if (input$impact_selected == "Custom-built") {
    x = range_tempK
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact (%)")
    } #endif

  if (input$impact_selected == "Electricity Load (US; temperature)") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Building Damage (flood depth)") {
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    #source("./data/hazus/extract_hazus_flood_depth_damage.r", local=TRUE)
    #damage_function_id = input$hazus_damage_function_id
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    damage_function_id = as.numeric(s[1])
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
    } #endif

  if (input$impact_selected == "Corn Yield (US, drought)") {
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Agricultural Income (Brazil)") {
    source("./functions/fit_agriculture_brazil_v1.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Maize Yield (US)") {
    source("./functions/fit_maize_yield_us_hourly_temp.r", local=TRUE)
    } #endif

  })

  # Beta Multiplier By Period
  output$financialplot1 <- renderPlot({
    x <- seq(275,315,0.1)
    # pweibull is the CDF for dweibull.
    source("./functions/damage_impacts.r", local=TRUE)
    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }
    plot(betamultiplier, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Beta Multiplier", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
  })

  # NPV impact on project
  output$financialplot2 <- renderPlot({
    x <- seq(275,315,0.1)
    
    source("./functions/damage_impacts.r", local=TRUE)

    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }

    # NPV calculation
    # Assume project starts in period 3 and that each period is a decade.
    cashflowinputs <- c(input$cashflow1,input$cashflow2,input$cashflow3,input$cashflow4,input$cashflow5,input$cashflow6,input$cashflow7)
    cashflow <- initializer
    for(i in 1:length(cashflow)) {cashflow[i] = cashflowinputs[i] }
    capitalcost <- input$capitalcost
    discount <- input$discount
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}
    discountedcashflow <- initializer
    for(i in 1:length(discountbydecade)) {discountedcashflow[i] = discountbydecade[i] * cashflow[i] }
    npv = sum(discountedcashflow) - capitalcost
    npvmultiplier <- initializer
    offset=2
    for(i in 1:length(npvmultiplier)) {npvmultiplier[i] = betamultiplier[i+offset]}
    for(i in 1:length(npvmultiplier)) {npvmultiplier[i] = npvmultiplier[i] - npvmultiplier[1] +1}
    discountedcashflow_modified <- discountedcashflow
    for(i in 1:length(npvmultiplier)) {discountedcashflow_modified[i] = discountedcashflow[i] / npvmultiplier[i]}
    npv_modified = sum(discountedcashflow_modified) - capitalcost

    write.table(c("betamultiplier",betamultiplier), file="./output/betamultiplier.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("npvmultiplier",npvmultiplier), file="./output/npvmultiplier.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("npv npv_modified",paste(npv,npv_modified)), file="./output/npv_base_and_modified.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("discountbydecade",discountbydecade), file="./output/discountbydecade.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("discountedcashflow,discountedcashflow_modified",paste(discountedcashflow,discountedcashflow_modified)), file="./output/discountedcashflow_base_and_modified.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    barplot(c(npv,npv_modified), col=c("green","red"), names.arg=c("Without Climate Impacts", "With Climate Impacts"),xlab="Unmodified and Modified NPV", ylab="NPV", ylim=c(-20,50) )
  })

# -----------
# Climate score
# -----------

  # Climate score by period

  output$scoreplot1 <- renderPlot({
    labels <- c("Without Adaptation","With Adaptation")
    x <- seq(275,315,0.1)
    
    source("./functions/damage_impacts.r", local=TRUE)

    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }

    # Climate score calculation
    score <- betamultiplier
    # for(i in 1:length(betamultiplier)) {score[i] = 100 - 10*betamultiplier[i]^i}
    for(i in 1:length(score)) {score[i] = 100 + impactbyperiod_relative2baseperiod[i]}
    # for(i in 1:length(score)) {score[i] = 100 + impactbyperiod[i]}
    adaptation_adjustment <- c(0,0,0,0,5,10,15,20,20)
      if(input$adaptationplan=="None") {adaptation_adjustment = c(0,0,0,0,0,0,0,0,0)}
      if(input$adaptationplan=="Minimal") {adaptation_adjustment = c(0,0,1,5,5,5,5,5,5)}
      if(input$adaptationplan=="Moderate") {adaptation_adjustment = c(0,0,2,10,10,15,15,20,20)}
      if(input$adaptationplan=="Maximal") {adaptation_adjustment = c(0,0,3,10,15,20,20,30,30)}
    score2 = score + adaptation_adjustment
    plot(score, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Climate Score", xaxt="n", ylim=c(0,max(score)) )
	axis(1, at=c(1:length(periods)), labels=periods)
    lines(score2, lwd=3, lty=2, col=colors[2] )
    legend("topright", inset=.01, title="Scenarios", labels, lwd=3, lty=c(1,2), col=c(colors[1],colors[2]))
  })

   output$climatescores <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts.r", local=TRUE)
    score = impactbyperiod
    for(i in 1:length(score)) {score[i] = 100 + impactbyperiod_relative2baseperiod[i]}
    # for(i in 1:length(score)) {score[i] = 100 + impactbyperiod[i]}
    paste("Near-term (2016-25):", round(score[2],digits=0),"Mid-term (2026-35):", round(score[3],digits=0), "Long-term (2036-45):", round(score[4],digits=0), sep="\n") 
    })

   output$adaptationplan <- renderText({
      if(input$adaptationplan=="None") {adaptation_adjustment = "0  0  0  0  0  0  0  0  0"}
      if(input$adaptationplan=="Minimal") {adaptation_adjustment = "0  0  1  5  5  5  5  5  5"}
      if(input$adaptationplan=="Moderate") {adaptation_adjustment = "0  0  2  10  10  15  15  20  20"}
      if(input$adaptationplan=="Maximal") {adaptation_adjustment = "0  0  3  10  15  20  20  30  30"}
      paste("CREDITS TO CLIMATE SCORE BY PERIOD:   ", adaptation_adjustment)
    })

  # Impact function from impact-function tab.
  output$scoreplot2 <- renderPlot({
    x <- seq(270,320,0.01)
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

# -----------
# Adaptation planning
# -----------

  # Impact function from impact-function tab.
  output$adaptationplot1 <- renderPlot({
    x <- seq(270,320,0.01)
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  # Asset-value damage
  output$adaptationplot2 <- renderPlot({
    x <- seq(270,320,0.1)
    nadaptplans = 2
   
  # Asset risk below is sum of values by asset, weighted by sensitivity to given impact function.  Sensitivity varies with adaptation plan.
  #   Impact functions give percent impact, so we allow different assets to have different sensitivities to a given impact function.
  #   This is a simplified way to get different impacts by scaling by asset type; ideally, they would have different impact functions. 
  #   This is also a simplified (linear) way to connect asset value with loss of capacity or condition in the impact function.

    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    labels <- c("No Adaptation","Adaptation Plan 1","Adaptation Plan 2")
    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Impact on Asset Value ($M)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    lines(impactbyperiod_relative2baseperiod_plan1, type="l", lwd=3, lty=1, col=colors[3])
    lines(impactbyperiod_relative2baseperiod_plan2, type="l", lwd=3, lty=1, col=colors[5])
    legend("topright", inset=.01, title="Scenarios", labels, lwd=3, lty=c(1,1,1), col=c(colors[1],colors[3],colors[5]))
  })

  # Adaptation-plan benefits.
  # Benefit for plan i = Sum(over periods j) [ (impact_no_adapt(period j) - impact_plan_i(period j)) / (1+discount_rate)^j ]
  output$adaptationbenefit1 <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    discount <- input$discount2
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}

    benefitbydecade_plan1 <- initializer
    for(i in 1:length(benefitbydecade_plan1)) {benefitbydecade_plan1[i] = impactbyperiod_relative2noadaptation_plan1[i] / ((1+discountbydecade[i])^i) }
    benefit_plan1 = sum(benefitbydecade_plan1)

    totalcost = (input$cost2implement_plan1 + input$cost2maintain_relative2base_plan1)
    benefit2cost = benefit_plan1 / totalcost

    paste("Adaptation Plan 1 - Benefit, Cost, and B/C Ratio:  ", round(benefit_plan1, digits=2), "$M ,", round(totalcost, digits=2), "$M ,",round(benefit2cost, digits=2) )
  })

  output$adaptationbenefit2 <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    discount <- input$discount3
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}

    benefitbydecade_plan2 <- initializer
    for(i in 1:length(benefitbydecade_plan2)) {benefitbydecade_plan2[i] = impactbyperiod_relative2noadaptation_plan2[i] / ((1+discountbydecade[i])^i) }
    benefit_plan2 = sum(benefitbydecade_plan2)

    totalcost = (input$cost2implement_plan2 + input$cost2maintain_relative2base_plan2)
    benefit2cost = benefit_plan2 / totalcost

    paste("Adaptation Plan 2 - Benefit, Cost, and B/C Ratio:  ", round(benefit_plan2, digits=2), "$M ,", round(totalcost, digits=2), "$M ,",round(benefit2cost, digits=2) )
  })

  output$database1_name <- renderText({
    source("./data/users/load_database_users.r", local=TRUE)
    db = dbname
    paste("Database 1:  ", db)
  })

  output$database2_name <- renderText({
    source("./data/users/load_dbsqlite_test.r", local=TRUE)
    db = dbtitle
    paste("Database 2:  ", db)
  })

  output$database2_table12_contents <- renderText({
    source("./data/users/load_dbsqlite_test.r", local=TRUE)
    paste("Contents of table",table12," :  ", qlist)
  })

  output$database2_write <- renderText({
    # XXX next make the sourcing of the write script dependent on an input variable.
    if(input$write_new_table=="Yes") {source("./data/users/write_dbsqlite_test.r", local=TRUE)}
    paste("New table created.")
  })


# -----------
# Links
# -----------
    #googleurl <- a("Google Homepage", href="https://www.google.com/")
    #output$googlelink <- renderUI({ tagList("URL link:", googleurl) })
    output$googlelink <- renderUI({ tags$a("Google Search", href="https:www.google.com", target="_blank") })
    output$ndgain_countries <- renderUI({ tags$a("ND-GAIN Country Index", href="https://gain.nd.edu/our-work/country-index/rankings/", target="_blank") })
    output$actuaries_climate_index <- renderUI({ tags$a("Actuaries Climate Index", href="http://actuariesclimateindex.org/explore/regional-graphs/", target="_blank") })
    output$worldbank_development_indicators <- renderUI({ tags$a("World Bank Development Indicators", href="http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators", target="_blank") })

# Terry -----------------------------------------------------------


} # end server


