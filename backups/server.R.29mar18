## app.R ##
# Reference:  	https://rstudio.github.io/shinydashboard/
# Icons:	http://fontawesome.io/icons/
#		http://getbootstrap.com/components/#glyphicons

# Notes:
#
#


server <- function(input, output, session) {

# -----------
# LOG IN
# -----------
  userDB = dbsheet10
   
  USER <- reactiveValues(LoggedIn = FALSE)
  
  observeEvent(input$btnLogin, {
    USER$ParentCorpID <- pull(subset(userDB, Username == input$Username, select = "ParentCorpID"))
    USER$ParentCorpName <- pull(subset(userDB, Username == input$Username, select = "ParentCorpName"))
    updateTabItems(session, 'sidebar', 'config')})
    
  output$login_response <- renderText({
    if (USER$LoggedIn == FALSE) {
        Id.username <- which(userDB$Username == input$Username)
        Id.password <- which(userDB$Password == input$Password)
        if (length(Id.username) > 0 & length(Id.password) > 0) {
          if (Id.username == Id.password) {
            USER$ParentCorpID <- pull(subset(userDB, Username == input$Username, select = "ParentCorpID"))
            enable('btnLogin')
            USER$LoggedIn <- TRUE
            }
        } else  {
          "User name or password doesn't match"
        }
    }
  })
  
# ----------------------------
#         CONFIGURE
# ----------------------------
   # UI Inputs

   # Read in James's locations csv (based on Terry's)
   # corpLocations <- readr::read_csv("data/TCSDB/locations.csv")

   # TCSDB in excel format is read in ui.R via:  source("./data/TCSDB/load_tcsdb.r")
   # The locations sheet is currently sheet 3.
   corpLocations = dbsheet3
   businessTypes = dbsheet13
   businessFunctions = dbsheet14
   # userdata now read below in each data type in order to have user see saved data without reinitiation of session.  XXX This may be inefficient when userdata gets very large.
   # userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)

   output$rbLocations <- renderUI({
     locs = pull(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName)))
     # radioButtons('rbLocations',label = 'Select a location to configure',c('All locations',unique(as.character(corpTable$Location))))
     radioButtons('rbLocations',label='Select a location to configure', c('All locations',locs))
     #selectInput('rbLocations',label='Select a location to configure', c('All locations',locs))
   })

   output$businessTypes <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    btypes = pull(unique(subset(businessTypes, select = BusinessType)))
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations=='All locations')
    btype_from_userdata = as.character(entry$input.cbGroupBizType)
    selectInput('industry_sector',"Industry Sector",c(btypes),selected=btype_from_userdata,selectize = TRUE)
   })


   output$numEmployees <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtNumEmployees
    textInput('numEmployees',"Number of employees",width = "100px", value=n_from_userdata)
    #textInputRow('numEmployees',"Number of employees", value=n_from_userdata)
    #textInputRow('numEmployees2',"Number of employees2", value=n_from_userdata)
   })

   output$assetValue_tx90p <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_tx90p
    textInput('assetValue_tx90p',"Value of assets sensitive to high temperatures ($M)",width = "250px", value=n_from_userdata)
   })

   output$assetValue_pdsisc <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_pdsisc
    textInput('assetValue_pdsisc',"Value of assets sensitive to drought ($M)",width = "250px", value=n_from_userdata)
   })

   output$assetValue_coastalflood <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtAssetValue_coastalflood
    textInput('assetValue_coastalflood',"Value of assets sensitive to coastal flooding ($M)",width = "250px", value=n_from_userdata)
   })

   output$ghgEmissions <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    n_from_userdata = entry$input.txtghgEmissions
    textInput('ghgEmissions',"GHG emissions at this location (Mtonnes/year))",width = "200px", value=n_from_userdata)
   })

   output$businessFunctions <- renderUI({
    userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
    bfunctions = pull(unique(subset(businessFunctions, select = BusinessFunction)))
    entry = userdata %>% filter(USER.ParentCorpID==USER$ParentCorpID) %>% filter(input.rbLocations==input$rbLocations)
    bfunctions_from_userdata = as.character(entry$cbBusinessFunctions)
    dbfu = data.frame(bfunctions_from_userdata)
    bfunctions_from_userdata_list = do.call(rbind, str_split(dbfu$bfunctions_from_userdata, ', '))
    #a = dbfu2[1,1]
    #for(i in 1:length(dbfu2)) a = c(a,",",dbfu2[1,i])
    #for(i in 1:1) a = c(a,",",dbfu2[1,i])
    #bfunctions_from_userdata = paste("c(", as.character(entry$cbBusinessFunctions[1]), ")" )
    checkboxGroupInput('cbBusinessFunctions',"Business functions performed at this location",c(bfunctions),selected=bfunctions_from_userdata_list[1,])
   })

   #Maps

   output$facility_location_map <- renderLeaflet({
     leaflet(data = subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationID:lat)) %>%
       addTiles() %>%
       addScaleBar() %>%
       addMarkers(~lon, ~lat, popup = ~as.character(LocationName))
   })

   output$individual_location_map <- renderLeaflet({
     leaflet(data = subset(corpLocations, ParentCorpID == USER$ParentCorpID & LocationName == input$rbLocations, select = LocationID:lat)) %>%
       addTiles() %>%
       addScaleBar() %>%
       addMarkers(~lon, ~lat, popup = ~as.character(LocationName))
   })
   
   observeEvent(input$btnConfig, {
     updateTabItems(session, 'sidebar', 'analyze')})
   
   observeEvent(input$button_save_data_corp, {
        source("./data/TCSDB/save_user_data.r", local=TRUE)
	# Below is now also part of the runSE_with_userdata button.  However, it is also needed to update ./data/TCSDB/locationvalues4SE.csv and ./data/TCSDB/user_data.csv.latest.csv .
        system("./data/TCSDB/script_apply_userdata4SE ./data/TCSDB/user_data.csv ./data/scoring_engine/nonphysical/locationvalues4SE.csv")
        #userdata = read.csv("./data/TCSDB/user_data.csv.latest.csv", sep=";", header=TRUE)
      })

# ----------------------------
#         CORP ANALYZE
# ----------------------------  
   
  # TCSDB in excel format is read in ui.R via:  source("./data/TCSDB/load_tcsdb.r")
  # The version of this table with scoring-engine outputs for RCP8.5 and 9 decades is sheet 9.
  # When using the decadal form, set the sliderInputYear to the decadal version in ui.R.
  # corpTable = dbsheet9
  #corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure_v3_locations.csv.damages.allDFs.with.nonphysical.csv")
  #corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.with.nonphysical.csv")
  corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")

  # UI Input selectors for the corporate finance page, based on the database values  
  output$selectInput_location <- renderUI({
    selectInput('inputLocations',"Locations",c('All locations', unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))),selected='All locations',selectize = TRUE)
  })
  
  output$selectInput_scenario <- renderUI({
    # XXX If corpTable is set to type reactiveValues and controlled with button_test_reset_data, the following is not initialized properly and does not get updated by the reset button.
    selectInput('inputScenarios',"Scenario",c(unique(as.character(corpTable$ScenarioName))),selected='RCP8.5',selectize = TRUE)
  })
  
  #barByRiskFactor
  output$barByRiskFactor <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")

    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }

    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      corpTable = select(corpTable, RiskFactorName, ValueAtRisk)
      corpTable = as.data.table(corpTable)
      corpTable = corpTable[,lapply(.SD,sum),by="RiskFactorName"]
    }

    plot_ly(x=corpTable$ValueAtRisk, y=corpTable$RiskFactorName, type = 'bar', orientation = 'h') %>% layout(margin = list(l=180, b=100)) %>%
      layout(xaxis = list(title = 'Impact ($M)'))
  }) 
  
  #barByLocation
  output$barByLocation <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
    }
    ncorp <- pull(count(corpTable))
    plot_ly(corpTable, x = ~Location, y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))
  }) 
  
  #stacked area by Time
  output$areaByTime <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID),]
      #corpTable = select(corpTable, RiskYear, ValueAtRisk)
      #corpTable = as.data.table(corpTable)
      #corpTable = corpTable[,lapply(.SD,sum),by="RiskYear"]
    }
    
    # to chart a time series, need to build a new datafame with additive traces. I'm sure there's a better way to do this.
    nriskyears = length(corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull())
    time_series = as.data.frame( matrix(0, nrow = nriskyears, ncol = 10, dimnames = list(c(1:nriskyears), c("RiskYear", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9"))) )

    time_series$RiskYear <- corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull()
    time_series$s1 <- corpTable %>% filter(TCFDSubCatName=='Policy and Legal') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$s2 <- corpTable %>% filter(TCFDSubCatName=='Technology') %>% group_by(RiskYear) %>% summarise(s2=sum(ValueAtRisk)) %>% select(s2) %>% pull()
    time_series$s3 <- corpTable %>% filter(TCFDSubCatName=='Market') %>% group_by(RiskYear) %>% summarise(s3=sum(ValueAtRisk)) %>% select(s3) %>% pull()
    time_series$s4 <- corpTable %>% filter(TCFDSubCatName=='Reputation') %>% group_by(RiskYear) %>% summarise(s4=sum(ValueAtRisk)) %>% select(s4) %>% pull()
    time_series$s5 <- corpTable %>% filter(TCFDSubCatName=='Acute') %>% group_by(RiskYear) %>% summarise(s5=sum(ValueAtRisk)) %>% select(s5) %>% pull()
    time_series$s6 <- corpTable %>% filter(TCFDSubCatName=='Chronic') %>% group_by(RiskYear) %>% summarise(s6=sum(ValueAtRisk)) %>% select(s6) %>% pull()
    time_series$s7 <- corpTable %>% filter(TCFDSubCatName=='Resource Efficiency') %>% group_by(RiskYear) %>% summarise(s7=sum(ValueAtRisk)) %>% select(s7) %>% pull()
    time_series$s8 <- corpTable %>% filter(TCFDSubCatName=='Energy Source') %>% group_by(RiskYear) %>% summarise(s8=sum(ValueAtRisk)) %>% select(s8) %>% pull()
    time_series$s9 <- corpTable %>% filter(TCFDSubCatName=='Resilience') %>% group_by(RiskYear) %>% summarise(s9=sum(ValueAtRisk)) %>% select(s9) %>% pull()

    # hack the stacking (plotly doesn't actually do stacking - it's a documented problem.)
  if(input$riskfactor_subset=="All") { 
    time_series$stack1 <- time_series$s1
    time_series$stack2 <- time_series$stack1 + time_series$s2
    time_series$stack3 <- time_series$stack2 + time_series$s3
    time_series$stack4 <- time_series$stack3 + time_series$s4
    time_series$stack5 <- time_series$stack4 + time_series$s5
    time_series$stack6 <- time_series$stack5 + time_series$s6
    time_series$stack7 <- time_series$stack6 + time_series$s7
    time_series$stack8 <- time_series$stack7 + time_series$s8
    time_series$stack9 <- time_series$stack8 + time_series$s9
    } # endif
    
# Draw the graph

  # Note that the plot is saved as object tplot under each conditional; this is needed to avoid the following:
  #    Error in UseMethod: no applicable method for 'ggplotly' applied to an object of class "NULL".

  if(input$riskfactor_subset=="Chronic physical + Carbon price") { 
    time_series$stack1 <- time_series$s1
    time_series$stack2 <- time_series$stack1 + time_series$s6
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal - Carbon Price', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Chronic', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))
    } # endif

  if(input$riskfactor_subset=="All") { 
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Technology', fill = 'tonexty') %>%
      add_trace(y = ~stack3, name = 'Market', fill = 'tonexty') %>%
      add_trace(y = ~stack4, name = 'Reputation', fill = 'tonexty') %>%
      add_trace(y = ~stack5, name = 'Acute', fill = 'tonexty') %>%
      add_trace(y = ~stack6, name = 'Chronic', fill = 'tonexty') %>%
      add_trace(y = ~stack7, name = 'Resource Efficiency', fill = 'tonexty') %>%
      add_trace(y = ~stack8, name = 'Energy Source', fill = 'tonexty') %>%
      add_trace(y = ~stack9, name = 'Resilience', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))
    } # endif

  tplot

  }) 
  
  # TCFD stacked bar chart
  output$stackedCorpFinImpactsPlot <- renderPlotly({
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    if (input$inputLocations != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
    }
    if (input$inputLocations == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      #corpTable = select(corpTable, TCFDCategoryName, ValueAtRisk)
      #corpTable = as.data.table(corpTable)
      #corpTable = corpTable[,lapply(.SD,sum),by="TCFDCategoryName"]
    }
    ncorp <- pull(count(corpTable))
    plot_ly(corpTable, x = ~TCFDCategoryName, y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))
    #plot_ly(corpTable, x = list("Opportunity","Physical Risk","Transition Risk"), y = ~ValueAtRisk, type='bar', text=corpTable$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      #layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100), showlegend=TRUE)
  })
  
  #Data table
  output$corpFinImpacts <- DT::renderDataTable({
     #colnames(corpTable) = c('Location','TCFD Category','Subcategory','Risk Factor','Scenario','Year','Value at Risk ($M)') #someday figure this out
      corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
      if(input$riskfactor_subset=="Chronic physical + Carbon price") corpTable <- filter(corpTable, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
      #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
      if (input$inputLocations != 'All locations') {
        corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations & corpTable$RiskYear == input$sliderInputYear),]
      }
      if (input$inputLocations == 'All locations') {
        corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$RiskYear == input$sliderInputYear),]
      }
      corpTable[1:7]
  })

# --------------------------------------
#              CORP METHODOLOGY
# --------------------------------------

#  output$selectCausalVariable<- renderUI({
#    selectInput("selectCausalVariable","Causal Variable (Hazard)",c("Temperature","Coastal Flooding","Drought"),selected = c("Coastal Flooding"), selectize=TRUE)
#  })

#  output$selectDamageFunction<- renderUI({
#    selectInput("selectDamageFunction","Damage Function",c("Building Damage","Cooling","Corn Yield"),selected = c("Building Damage"), selectize=TRUE)
#  })

#  output$selectPeriod<- renderUI({
#    selectInput("selectPeriod","Time Period",choices = c("1980","1990","2000","2010","2020","2030","2040","2050","2060","2070","2080","2090","2100"), selected=c("2010"), selectize=TRUE)
#  })

  # UI Input selectors for Corporate/Methodology/Overall, based on the database values  
  output$selectInput_location_overall <- renderUI({
    selectInput('inputLocations_overall',"Select Location",c(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))), selectize = TRUE)
  })
  
  output$plot_selectHazard <- renderPlot({

   if(input$selectCausalVariable=="Temperature") {

	# Using LOCA data from 32 models at 4 locations near Phoenix, AZ, airport.
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(20,55,0.5)
      plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topleft", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)

  } # endif

   if(input$selectCausalVariable=="Drought Severity") {
	source("./data/drought/script_pdsisc_pdfs.r")
   }

   if(input$selectCausalVariable=="Coastal Flooding") {

#	source("./data/sealevel_us/annual_probability_withslr.r", local=TRUE)
#	position="topleft"
#	if(input$returnLevel==1) position="topright"
#	level = as.character(input$returnLevel)
#    # slrYears are defined in annual_probability_withslr.r.
#    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
#    plot(annual_probability_withslr[1,], type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Year", ylab=paste("Ann. Prob. Exceed Flood Level",level,"m (%)"), xaxt="n")
#	lines(annual_probability_withslr[2,], col="blue")
#	lines(annual_probability_withslr[3,], col="green")
#	lines(annual_probability_withslr[4,], col="yellow")
#	lines(annual_probability_withslr[5,], col="orange")
#	lines(annual_probability_withslr[6,], col="red")
#	axis(1, at=c(1:length(slrYears)), labels=slrYears)
#     	legend(position, inset=.05, title="Scenarios (GMSL 2100)",legend=c("0.3m","0.5m","1.0m","1.5m","2.0m","2.5m"), lwd=3, col=c("black","blue","green","yellow","orange","red"))

        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_overall) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_overall)
	key <- gsub(" ","_",key)
	nd = read.table("./data/scoring_engine/coastalflooding/TCSDB_structure.locations.csv.nearest.gtsr.segment", header=TRUE)
	# V17 (RLm2yr) is the first historical return level in the nd table; if the location is outside the coastal distance threshold in the SE, this value will be a string (e.g., "TooFarFromCoast_threshold_10km") rather than a number.
	# Force the elements of RLM2yr that are not numbers to be "NA".
	  nd$RLm2yr <- as.numeric(as.character(nd$RLm2yr))
	#ele = nd %>% filter(nd$V1==key) %>% select(V14:V17, V27)
	ele = nd %>% filter(nd$LocationID_ParentCorpID_LocationName==key) %>% select(mindistid2, nearestseglon, nearestseglat, RLm2yr, station)

	#if(is.numeric(ele$RLm2yr)==TRUE) {
	if(toString(ele$RLm2yr)!="NA") {
	   # key2 is the string that identifies the element in world_ewl_with_slr_stations (created by /data/sealevel_world/load_sealevel_world.r) that has been associated with the current corporate facility.  It consists of of the id of the nearest coastal segment, the segment's lon/lat, and the name of the EWL station associated with that segement.  An example is 3873_-79.472_8.999_BALBOA.
	   #key2 <- paste(ele$V14, ele$V15, ele$V16, ele$V27)
	   key2 <- paste(ele$mindistid2, ele$nearestseglon, ele$nearestseglat, ele$station)
	   key2 <- gsub(" ","_",key2)
	   #loc <- input$extremewaterLocation2_with_slr_station
	   loc <- key2
	   # The following sets the scenario from the backend, not Corporate/Analyze
	   # scenario <- input$world_slr_scenario
	   # The following sets the scenario from Corporate/Analyze, using uiOutput("selectInput_scenario") in ui.R and its definition in server.R.
	   scenario <- input$selectscenario_overall

	   source("./data/sealevel_world/input4_plot_sealevel_data_world_ewl_slr.r", local=TRUE)
	   show_sealevel_world_plots <- "TRUE"
	   source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)
	}

	#if(is.numeric(ele$RLm2yr)==FALSE) {
	if(toString(ele$RLm2yr)=="NA") {
	   # This is not returning the text properly because it is in a renderPlot output statement (see start of section).
	   #paste("Location beyond distance threshold.")
	   source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr_null_data.r", local=TRUE)
	}
   }

  }) # end output$plot_selectHazard
  
  # UI Input selectors for Corporate/Methodology/Drilldown, based on the database values  
  output$selectInput_location_drilldown <- renderUI({
    selectInput('inputLocations_drilldown',"Select Location",c(unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))), selectize = TRUE)
  })
  
  output$plot_selectHazard_drilldown <- renderPlot({

   #if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)" | input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)" | input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {

	# Processed drought data is read into dataframe d by ./data/drought/load_drought_data.r, which is sourced at the beginning of server.R.
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	# input$drought_facility is set from TechnicalDetails/LocalizedClimateProbabilities/Drought and consists of concatenated LocationID_ParentCorpID_LocationName generated by script_build_nonphysical within the SE.
	# input$inputLocations_drilldown is set from Corporate/Methodology/Drilldown/selectInput_location_drilldown and consists of just the LocationName.

	# The following sets up the graph based on location selected in TechnicalDetails/LocalClimate/Drought.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	#fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)

	# The following sets up the graph based on location selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
	  nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	  # The following sets up the graph based on location selected in TechnicalDetails/LocalClimate/Drought.
	  # values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	  # The following sets up the graph based on location selected in Corporate/Analyze.
	  # The SE is run on drought data with one historical period (1950-99) and 9 future periods.  See script_runall_physical.
	  values = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  firstfield = values$V8
	  periods = c("1950-99","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = 100*as.numeric( t(values) )
	  ylabel = "Ann. Prob. of 90th-pctile Drought (%)"
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
	  nd = read.table("./data/scoring_engine/tmax90pct/TCSDB_structure.locations.csv.tx90p", header=FALSE)
	  # The SE is run on tmax90p data with one historical period (1970-99) and 9 future periods.  See script_runall_physical.  
	  # Note that there are 5 historical periods in the data, but the last one (1970-99) is used as the baseline for scoring of tmax90p impacts.
	  values = nd %>% filter(nd$V1==key) %>% select(V12,V17:V25)
	  firstfield = values$V12
	  periods = c("1970-99","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = as.numeric( t(values) )
	  ylabel = "Percent of Days Above 90th Percentile"
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Carbon Price") {
	  nd = read.table("./data/scoring_engine/carbonprice/TCSDB_structure.locations.csv.carbonprice", header=FALSE)
	  # The SE is run on carbonprice data with one historical period and 9 future periods.  See script_runall_physical.  
	  values = nd %>% filter(nd$V1==key) %>% select(V8:V17)
	  firstfield = values$V8
	  periods = c("Hist","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = as.numeric( t(values) )
	  ylabel = "Carbon Price (US$2005/t CO2)"
	  legend_nodata="No data available at this location."
	}

	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
	  # The SE is run on coastal-flood data and finds the annual probability of the historical 100-year flood level for 9 future periods.  See script_runall_physical.  
	  data = read.table("./data/scoring_engine/coastalflooding/input4r.nearest.gtsr.segment", header=TRUE)
	  data2 = read.table("./data/scoring_engine/coastalflooding/future_annprob_fromR", header=TRUE)
	  locs <- select(data, LocationID_ParentCorpID_LocationName)
	  annPhist100_historical <- matrix(0.01, nrow=151)
	  histvalues <- data.frame(annPhist100_historical)
	  nd <- cbind(locs, histvalues, data2)
	  values = nd %>% filter(nd$LocationID_ParentCorpID_LocationName==key) %>% select(annPhist100_historical:annPhist100_rcp85_2090)
	  firstfield = values$annPhist100_rcp85_2010
	  #nd = read.table("./data/scoring_engine/tmax90pct/TCSDB_structure.locations.csv.tx90p", header=FALSE)
	  #values = nd %>% filter(nd$V1==key) %>% select(V12,V17:V25)
	  #firstfield = values$V12
	  periods = c("Hist","2006-15","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	  tvalues = 100*as.numeric( t(values) )
	  ylabel = "Annual Probability of 100-year Flood Level (%)"
	  legend_nodata="Does not apply; location not close to coast."
	} # endif on coastal flooding

	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,200), xlab="Period", ylab=ylabel, xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
	# For coastal flooding, the following line corresponds to the lower limit on the future value of the return period of the historical 100-year return level.  This is applied in ./data/scoring_engine/coastal_flooding/script_estimate_future_rp_v1.r.  This is currently set to 1.0, so the annual probability has an upper limit of 100%.
	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
	   abline(h=100, col = "red", lty=2)  }
     	if(firstfield=="No_data" | firstfield=="Inf") { 
	   legend("center", legend=legend_nodata)
	   #legend("center", legend=legend_nodata, bg="red", text.col="white", text.font=2)
	  } else {
     	   legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
	}

  }) # end output$plot_selectHazard_drilldown
  
  output$plot_selectDamageFunction <- renderPlot({

   if(input$selectDamageFunction=="Building Damage") {
    damage_function_name = as.character(input$hazus_damage_function_id)
    s = unlist( strsplit(damage_function_name, "_") )
    # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    #s2 = paste(s[1])
    damage_function_id = as.numeric(s[1])
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
   }

   if(input$selectDamageFunction=="Corn Yield") {
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
   }

   if(input$selectDamageFunction=="Cooling") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
   }

  }) # end output$plot_selectDamageFunction

  output$plot_selectDamageFunction_drilldown <- renderPlot({

   if(input$selectDamageFunction_drilldown=="Selected Location and Hazard") {

   #if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)" | input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)" | input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {

	dfdata = read.table("./data/scoring_engine/df.csv.cln", sep=",", header=TRUE)

	if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_pdsisc)
	}

	if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_tx90p)
	}

	if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_coastalflood)
	}
	
	if(input$selectCausalVariable_drilldown=="Carbon Price") {
          loc_df <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_carbonprice)
	}
	
	  loc_df <- as.character(loc_df[1,])  # converts to character string for use in filter below.
	  xvalues <- dfdata %>% filter(dfdata$id==loc_df) %>% select(list_xvalues)
	  x2 <- strsplit(as.character(xvalues[1,]), ";", fixed=TRUE)
	  x3 <- as.numeric( unlist(x2) )
	  yvalues <- dfdata %>% filter(dfdata$id==loc_df) %>% select(list_yvalues)
	  y2 <- strsplit(as.character(yvalues[1,]), ";", fixed=TRUE)
	  y3 <- as.numeric( unlist(y2) )

	  xrange = c(min(x3), max(x3))
	  if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {xrange = c(min(x3), 1.1) }

	  xvariable <- dfdata %>% filter(dfdata$id==loc_df) %>% select(xvariable)
	  xvariable <- as.character(xvariable[1,])
	  yvariable <- dfdata %>% filter(dfdata$id==loc_df) %>% select(yvariable)
	  yvariable <- as.character(yvariable[1,])

	  xunits <- dfdata %>% filter(dfdata$id==loc_df) %>% select(xunits)
	  xunits <- as.character(xunits[1,])
	  yunits <- dfdata %>% filter(dfdata$id==loc_df) %>% select(yunits)
	  yunits <- as.character(yunits[1,])
	  
	plot(x3, y3, type="l", lwd=3, lty=1, col="black", xlab=paste(xvariable,",",xunits), ylab=paste(yvariable,",",yunits), xlim=xrange )
	legend("topright", title="Damage Function", legend=loc_df)

   #} 
	#else {
	# This is plotted if none of the 3 physical hazards are selected.
	# source("./functions/fit_corn_yield_us_drought.r", local=TRUE) }

   } # end if(input$selectDamageFunction_drilldown=="Selected Location and Hazard")

  }) # end output$plot_selectDamageFunction_drilldown
 
  output$losscurve <- renderImage({list(src = "./images/Mandel-121514-graph.png", height="230px", alt = paste("loss curve"))
  }, deleteFile = FALSE)

  output$plot_losscurve2 <- renderPlot({

   if(input$selectCausalVariable=="Temperature" & input$selectDamageFunction=="Cooling") {

	# The following creates functions f4avgload(t) and f4peakload(t).
        source("./functions/fit_elec_load_v1.r.noplot", local=TRUE)

	# Using LOCA data from 32 models at 4 locations near Phoenix, AZ, airport.
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
	tdist <- function(x) {dweibull(x, shape=shapes[1], scale=scales[1]) }
	if(input$selectPeriod=="2011-2030") {tdist <- function(x) {dweibull(x, shape=shapes[2], scale=scales[2]) } }
	if(input$selectPeriod=="2041-2060") {tdist <- function(x) {dweibull(x, shape=shapes[3], scale=scales[3]) } }
	if(input$selectPeriod=="2071-2090") {tdist <- function(x) {dweibull(x, shape=shapes[4], scale=scales[4]) } }
	tmin <- 20
	tmax <- 55
	t <- seq(tmin, tmax)
	tlen <- length(t)

	# Get the damage values and the probability values across the range of temperatures.
	damvals <- matrix(0, nrow=1, ncol=tlen)
	probvals <- matrix(0, nrow=1, ncol=tlen)
	for(i in 1:tlen) damvals[1,i] = f4avgload(i+tmin-1)
	for(i in 1:tlen) probvals[1,i] = tdist(i+tmin-1)

	# Get the expected value of the damage.
	eval <- sum(probvals * damvals)

	# Plot the product of the temperature distribution and the damage function.
	#fproduct <- function(t) { tdist(t) * f4avgload(t) }
	#plot(fproduct, xlim = c(min(t), max(t)) )

	# Plot the loss curve as probability versus damage values.
	plot(damvals, probvals, type="l", lwd=3, col="blue",
		main="Average Load Probability Distribution",
		xlab="Load (Mw) Relative to 15-18 degC",
		ylab="Probability")
	abline(v=eval, col = "blue", lty=2)
	#abline(h=0.01, col = "red", lty=2)
    	legend("topleft", inset=.01, "Expected Value", lwd=2, lty=2, col="blue")
	grid(col="lightgray")
	
     } # endif on temperature and cooling

   if(input$selectCausalVariable=="Drought Severity" & input$selectDamageFunction=="Corn Yield") {

	# The normal fits for 4 periods described by para2, para3, etc., were created by ./data/drought/script_pdsisc_pdfs.r .
	ntimeperiods <- 4
	function1 <- function(x) { dnorm(x, para2[1], para2[2]) }
	function2 <- function(x) { dnorm(x, para3[1], para3[2]) }
	function3 <- function(x) { dnorm(x, para4[1], para4[2]) }
	function4 <- function(x) { dnorm(x, para5[1], para5[2]) }

	# Set up return periods and calculate corresponding quantile values.  qnorm(1/rp) gives the value of the variable in the normal distribution that has cumulative probability <= 1/rp.  For example qnorm(0.2)=-.84, where the distribution has default values mean=0 and sd=1.
	# The following corresponds to return periods of 2, 5, 10, 20, 50, and 100 years.
	rp <- c(2, 5, 10, 20, 50, 100)
	#rp <- c(1, 2, 5, 10, 20, 50, 100)
	rp <- c(1, 1.5, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 100, 200, 500, 1000, 2000, 5000)
	#rp <- seq(1,500, by=0.5)
	qnorm_values <- qnorm(1/rp)
	#qnorm_values = c(qnorm(0.5), qnorm(0.2),qnorm(0.1),qnorm(0.05),qnorm(0.02),qnorm(0.01) )

	nvals <- length(rp)

	# Calculate values of the drought index corresponding to each return period.
	# The index-value formula is based on adjusting the qnorm values above that use mean=0, sd=1.  For example, qnorm(0.2, mean=m, sd=s)=qnorm(0.2)*s + m.
        index_values <- matrix(0, nrow=ntimeperiods, ncol=nvals)
	# index_values[1,] contains the drought-index values for the historical return periods.
	index_values[1,] <- qnorm_values * as.numeric(para2[2]) + as.numeric(para2[1])
	# The following are drought index values associated with the standard return periods in the future.  They are not used futher in this calculation.  See below.
	index_values[2,] <- qnorm_values * as.numeric(para3[2]) + as.numeric(para3[1])
	index_values[3,] <- qnorm_values * as.numeric(para4[2]) + as.numeric(para4[1])
	index_values[4,] <- qnorm_values * as.numeric(para5[2]) + as.numeric(para5[1])

	# This creates the DF f4yield_reduction_pct; note that the x variable is log10(drought return period in years).
    	source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
	
	# Get the damage values and the probability values across the range of temperatures.
	damvals <- matrix(0, nrow=1, ncol=nvals)
	probvals <- matrix(0, nrow=ntimeperiods, ncol=nvals)
	for(i in 1:nvals) damvals[1,i] = f4yield_reduction_pct( log(rp[i],10) )
	# Note that only the historical index_values[1,i] are used since these are the values of the drought index that correspond to the damages associated with the historical return periods.  The probabilities of these drought-index values change throught time.
	for(i in 1:nvals) probvals[1,i] = function1(index_values[1,i])
	for(i in 1:nvals) probvals[2,i] = function2(index_values[1,i])
	for(i in 1:nvals) probvals[3,i] = function3(index_values[1,i])
	for(i in 1:nvals) probvals[4,i] = function4(index_values[1,i])

	# Get the expected value of the damage for each time period.
	evals <- matrix(0, nrow=1, ncol=ntimeperiods)
	for(i in 1:ntimeperiods) evals[i] <- sum(probvals[i,] * damvals)/sum(probvals[i,])
	# XXX should the widths of the damvals intervals be used?
	#damvals_widths <- damvals
	#for(i in 2:nvals) damvals_widths[,i] <- damvals[,i] - damvals[,i-1]
	#for(i in 1:ntimeperiods) evals[i] <- sum(probvals[i,] * damvals_widths)

	#fproduct <- function(rp) { index_historical(rp) * f4yield_reduction_pct(rp) }
	
	#curve(dnorm(x, para2[1], para2[2]), from=-5, to=5, col = 3, ylim=c(0,0.5), ylab="Probability", xlab="Drought Severity Index (lower value = worse drought)")

	prob2plot <- probvals[1,]/sum(probvals[1,])
	eval2plot <- evals[1]
	if(input$selectPeriod=="2011-2030") {prob2plot <- probvals[2,]/sum(probvals[2,]); eval2plot <- evals[2]}
	if(input$selectPeriod=="2041-2060") {prob2plot <- probvals[3,]/sum(probvals[3,]); eval2plot <- evals[3]}
	if(input$selectPeriod=="2071-2090") {prob2plot <- probvals[4,]/sum(probvals[4,]); eval2plot <- evals[4]}

	# Plot the loss curve as probability versus damage values.
	plot(damvals, prob2plot, type="l", lwd=3, col="blue",
		main="Yield Reduction Probability Distribution",
		xlab="Yield Reduction (%)", xlim=c(0,100),
		ylab="Probability")
	abline(v=eval2plot, col = "blue", lty=2)
	#abline(h=0.01, col = "red", lty=2)
    	legend("topright", inset=.01, "Expected Value", lwd=2, lty=2, col="blue")
	grid(col="lightgray")

     } # endif on drought severity and corn yield

   if(input$selectCausalVariable=="Coastal Flooding" & input$selectDamageFunction=="Building Damage") {
	# The function for the rl distribution (prob versus rl) is defined in ./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r .
	# Compute probvals and damvals for the loss curve.

	show_sealevel_world_plots <- "FALSE"
	source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)

	# y1 and y2 are the lower and upper values of the return levels for the current location.
	curve(f4rldistmodel, y1, y2)
     } # endif on drought severity and corn yield

  }) # end output$plot_losscurve2

  output$plot_expectedDamage <- renderPlotly({

   if(input$selectDamageFunction_drilldown=="Selected Location and Hazard" & input$selectPeriod_drilldown=="All Periods") { 
	#source("./functions/plot_area_by_time_single_hazards.r", local=TRUE)

    corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")

    if (input$inputLocations_drilldown != 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID & corpTable$Location == input$inputLocations_drilldown),]
    }
    if (input$inputLocations_drilldown == 'All locations') {
      corpTable <- corpTable[which(corpTable$ParentCorpID == USER$ParentCorpID),]
    }

    nriskyears = length(corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull())
    time_series = as.data.frame( matrix(0, nrow = nriskyears, ncol = 10, dimnames = list(c(1:nriskyears), c("RiskYear", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9"))) )

    time_series$RiskYear <- corpTable %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull()
    time_series$s1 <- corpTable %>% filter(RiskFactorName=='Temperature extremes') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$s2 <- corpTable %>% filter(RiskFactorName=='Drought') %>% group_by(RiskYear) %>% summarise(s2=sum(ValueAtRisk)) %>% select(s2) %>% pull()
    time_series$s3 <- corpTable %>% filter(RiskFactorName=='Coastal flooding') %>% group_by(RiskYear) %>% summarise(s3=sum(ValueAtRisk)) %>% select(s3) %>% pull()
    time_series$s4 <- corpTable %>% filter(RiskFactorName=='Carbon pricing') %>% group_by(RiskYear) %>% summarise(s4=sum(ValueAtRisk)) %>% select(s4) %>% pull()

  if(input$selectCausalVariable_drilldown=="Temperature (daily maximum 90th percentile)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s1, name='Temperature (daily maximum 90th percentile)', type='scatter', mode = 'none', fill = 'tonexty')
    } # endif

  if(input$selectCausalVariable_drilldown=="Drought Severity (90th percentile)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s2, name='Drought Severity (90th percentile)', type='scatter', mode = 'none', fill = 'tonexty')
    } # endif

  if(input$selectCausalVariable_drilldown=="Coastal Flooding (return period 100yr level)") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s3, name='Coastal Flooding (return period 100yr level)', type='scatter', mode = 'none', fill = 'tonexty')
    } # endif

  if(input$selectCausalVariable_drilldown=="Carbon Price") {
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~s4, name='Carbon Price', type='scatter', mode = 'none', fill = 'tonexty')
    } # endif

   tplot %>%
       layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))

  } # endif on input$selectDamageFunction & input$selectPeriod

  }) # end output$plot_expectedDamage

# --------------------------------------
# TRACEBACK/DRILLDOWN
# --------------------------------------
  
# Note use of "sep" below to get line break via verbatimTextOutput in ui.R.

  output$tracebackHazard <- renderText({

  # XXX This structure does not return "Select a location" when input$inputLocations != 'All locations'

    if (input$inputLocations_overall == 'All locations') {
        p5=paste("Select a location.")
	p1=" "
	p3=" " 
    }

    if (input$inputLocations_overall != 'All locations') {
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_overall) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_overall)
	key <- gsub(" ","_",key)

        p1 = paste("Drought severity (all values) - ","Boise, Idaho")

        #p3 = paste("Sea-level projection - ",input$sealevelProjectionLocation)
        p3 = paste("Coastal Flooding (all EWLs with SLR) - ",as.character(key))

        p5 = paste("Temperature (all values) - ","Phoenix, AZ; 32 models; LOCA downscaling to 7-km resolution") 
    } 

	paste(p5," ",p1," ",p3,sep="\n")
  })

  output$tracebackHazard_drilldown <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	# The following is the location selected in TechnicalDetails/LocalClimate/Drought.
        #p2 = paste("Drought severity (90th percentile) - ",input$drought_facility)

        p2 = paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
        p2 = gsub(" ","_",p2)
        p2 = paste("Drought severity (90th percentile) - ",p2)
        p2b = paste("Drought severity (90th percentile) - ",input$inputLocations_drilldown)

        #p4 = paste("Extreme water-level - ",input$extremewaterLocation)
        p4 = paste("Coastal Flooding (return period 100yr level) - ",as.character(key))

        p6 = paste("Daily max temperature (90th percentile) - ",input$inputLocations_drilldown)

	paste(p6," ",p2b," ",p4,sep="\n")
        })

  output$tracebackVuln <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_overall) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_overall)
	key <- gsub(" ","_",key)

	p1 = paste("Cooling - auffhammer_peak_demand_electricity_2017")
	p2 = paste("Corn Yield - wang_crop_productivity_climate_midwestUS_2016")

	p3 = paste("Building Damage - HAZUS", as.character(input$hazus_damage_function_id))

	paste(p1," ",p2," ",p3,sep="\n")
        })

  output$tracebackVuln_drilldown <- renderText({
	# The following is the location (with locationID and ParentCorpID) selected in Corporate/Analyze.
        locID <- corpLocations %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(LocationID)
	key <- paste(locID,USER$ParentCorpID,input$inputLocations_drilldown)
	key <- gsub(" ","_",key)

	locvaluesSE <- read.table("./data/scoring_engine/nonphysical/locationvalues4SE.csv", header=TRUE, sep=";")
        locvalue_tx90p <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_tx90p)
        locvalue_pdsisc <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_pdsisc)
        locvalue_coastalflood <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_coastalflood)
        locvalue_carbonprice <- locvaluesSE %>% filter(ParentCorpID==USER$ParentCorpID & LocationName==input$inputLocations_drilldown) %>% select(df_carbonprice)
	#p1 = paste("Damage function - ",input$selectDamageFunction_drilldown)
	p1 = paste("Asset value at selected location for each damage function:")
	p2 = paste("Temperature (daily max 90th pctile)", as.character(locvalue_tx90p), "$M")
	p3 = paste("Drought Severity (90th percentile) ", as.character(locvalue_pdsisc), "$M")
	p4 = paste("Coastal Flooding (rtn pd 100yr lvl)", as.character(locvalue_coastalflood), "$M")
	p5 = paste("Carbon Price                       ", as.character(locvalue_carbonprice), "$M")

	paste(p1," ",p2," ",p3," ",p4," ",p5,sep="\n")
        })

# --------------------------------------
# SYSTEM CONTROL
# -------t------------------------------

  # Should be reactiveValue.  See pattern 3 at http://shiny.rstudio.com/articles/action-buttons.html
  corpTableNew <- reactiveValues()
  observeEvent(input$button_test_data_refresh, {
       corpTableNew <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.csv")
       #write.table(corpTableNew, "./junk")
      })

  observeEvent(input$button_runSE, {
      withProgress(message = 'Calculation in progress',
        detail = 'This may take a while...', value = 0, {
        #for (i in 1:15) {incProgress(1/15); Sys.sleep(0.25) }
	incProgress(1/3)
        system("./data/scoring_engine/script_runSE_from_app")
        }) # end withProgress

      #system("./data/scoring_engine/script_runSE_from_app")
      }) # end observeEvent

  observeEvent(input$button_runSE_with_userdata, {
      withProgress(message = 'Calculation in progress',
        detail = 'This may take a while...', value = 0, {
	incProgress(1/3)
        system("./data/TCSDB/script_apply_userdata4SE ./data/TCSDB/user_data.csv ./data/scoring_engine/nonphysical/locationvalues4SE.csv")
        system("./data/scoring_engine/script_runSE_from_app_with_userdata")
        }) # end withProgress
      }) # end observeEvent

# ----------------------------
#         PORTFOLIO - ANALYZE
# ----------------------------  
   
  # TCSDB in excel format is read in ui.R via:  source("./data/TCSDB/load_tcsdb.r")
  # The version of this table with scoring-engine outputs for RCP8.5 and 9 decades is sheet 9.
  # When using the decadal form, set the sliderInputYear to the decadal version in ui.R.
  # corpTable = dbsheet9
  #corpTable <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure_locations.csv.cln.damages.allDFs.with.nonphysical.csv")
  #corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.with.nonphysical.byparentcorp.csv")
  corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
  parentCorp = dbsheet4

  # UI Input selectors for the corporate finance page, based on the database values  
  output$selectInput_locationPort <- renderUI({
    #selectInput('inputLocationsPort',"Locations",c('All locations', unique(subset(corpLocations, ParentCorpID == USER$ParentCorpID, select = LocationName))),selected='All locations',selectize = TRUE)
    selectInput('inputLocationsPort',"Portfolios",c('Entire portfolio', unique(subset(parentCorp, select = TickerSymbol))),selected='All locations',selectize = TRUE)
  })
  
  output$selectInput_scenarioPort <- renderUI({
    selectInput('inputScenariosPort',"Scenario",c(unique(as.character(corpTable2$ScenarioName))),selected='RCP8.5',selectize = TRUE)
  })
  
  #barByRiskFactor
  output$barByRiskFactorPort <- renderPlotly({
    corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
    #if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, RiskFactorName=="Temperature extremes" | RiskFactorName=="Drought" | RiskFactorName=="Coastal flooding" | RiskFactorName=="Carbon pricing")
    if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    parentCorp = dbsheet4
    if (input$inputLocationsPort != 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    if (input$inputLocationsPort == 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    plot_ly(x=corpTable2$ValueAtRisk, y=corpTable2$RiskFactorName, type = 'bar', orientation = 'h') %>% layout(margin = list(l=180, b=100)) %>%
      layout(xaxis = list(title = 'Impact ($M)'))
  }) 
  
  #barByLocation
  output$barByLocationPort <- renderPlotly({
    corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
    if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    parentCorp = dbsheet4
    if (input$inputLocationsPort != 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    if (input$inputLocationsPort == 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    ncorp <- pull(count(corpTable2))
    plot_ly(corpTable2, x = ~Location, y = ~ValueAtRisk, type='bar', text=corpTable2$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))
  }) 
  
  #stacked area by Time
  output$areaByTimePort <- renderPlotly({
    corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
    parentCorp = dbsheet4
    if (input$inputLocationsPort != 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$Location == input$inputLocationsPort),]
      corpTable2 <- corpTable2[which(corpTable2$Location == input$inputLocationsPort),]
    }
    #if (input$inputLocationsPort == 'Entire portfolio') {
    #  corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID),]
    #}
    
    # to chart a time series, need to build a new datafame with additive traces. I'm sure there's a better way to do this.
    nriskyears = length(corpTable2 %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull())
    time_series = as.data.frame( matrix(0, nrow = nriskyears, ncol = 10, dimnames = list(c(1:nriskyears), c("RiskYear", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8", "s9"))) )

    time_series$RiskYear <- corpTable2 %>% group_by(RiskYear) %>% summarise(svar=sum(ValueAtRisk)) %>% select(RiskYear) %>% pull()
    time_series$s1 <- corpTable2 %>% filter(TCFDSubCatName=='Policy and Legal') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$s2 <- corpTable2 %>% filter(TCFDSubCatName=='Technology') %>% group_by(RiskYear) %>% summarise(s2=sum(ValueAtRisk)) %>% select(s2) %>% pull()
    time_series$s3 <- corpTable2 %>% filter(TCFDSubCatName=='Market') %>% group_by(RiskYear) %>% summarise(s3=sum(ValueAtRisk)) %>% select(s3) %>% pull()
    time_series$s4 <- corpTable2 %>% filter(TCFDSubCatName=='Reputation') %>% group_by(RiskYear) %>% summarise(s4=sum(ValueAtRisk)) %>% select(s4) %>% pull()
    time_series$s5 <- corpTable2 %>% filter(TCFDSubCatName=='Acute') %>% group_by(RiskYear) %>% summarise(s5=sum(ValueAtRisk)) %>% select(s5) %>% pull()
    time_series$s6 <- corpTable2 %>% filter(TCFDSubCatName=='Chronic') %>% group_by(RiskYear) %>% summarise(s6=sum(ValueAtRisk)) %>% select(s6) %>% pull()
    time_series$s7 <- corpTable2 %>% filter(TCFDSubCatName=='Resource Efficiency') %>% group_by(RiskYear) %>% summarise(s7=sum(ValueAtRisk)) %>% select(s7) %>% pull()
    time_series$s8 <- corpTable2 %>% filter(TCFDSubCatName=='Energy Source') %>% group_by(RiskYear) %>% summarise(s8=sum(ValueAtRisk)) %>% select(s8) %>% pull()
    time_series$s9 <- corpTable2 %>% filter(TCFDSubCatName=='Resilience') %>% group_by(RiskYear) %>% summarise(s9=sum(ValueAtRisk)) %>% select(s9) %>% pull()
    
    # hack the stacking (plotly doesn't actually do stacking - it's a documented problem.)
    time_series$stack1 <- time_series$s1
    time_series$stack2 <- time_series$stack1 + time_series$s2
    time_series$stack3 <- time_series$stack2 + time_series$s3
    time_series$stack4 <- time_series$stack3 + time_series$s4
    time_series$stack5 <- time_series$stack4 + time_series$s5
    time_series$stack6 <- time_series$stack5 + time_series$s6
    time_series$stack7 <- time_series$stack6 + time_series$s7
    time_series$stack8 <- time_series$stack7 + time_series$s8
    time_series$stack9 <- time_series$stack8 + time_series$s9
    
# Draw the graph

  # Note that the plot is saved as object tplot under each conditional; this is needed to avoid the following:
  #    Error in UseMethod: no applicable method for 'ggplotly' applied to an object of class "NULL".

  if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") { 
    time_series$stack1 <- corpTable2 %>% filter(RiskFactorName=='Carbon pricing') %>% group_by(RiskYear) %>% summarise(s1=sum(ValueAtRisk)) %>% select(s1) %>% pull()
    time_series$stack2 <- time_series$stack1 + time_series$s6
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal - Carbon Price', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Chronic', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = TRUE), xaxis = list(showgrid = TRUE), margin = list(l=80,b=100))
    } # endif

  if(input$riskfactor_subset_portfolio=="All") { 
    tplot <- plot_ly(time_series, x = ~RiskYear, y = ~stack1, name='Policy & Legal', type='scatter', mode = 'none', fill = 'tonexty') %>% 
      add_trace(y = ~stack2, name = 'Technology', fill = 'tonexty') %>%
      add_trace(y = ~stack3, name = 'Market', fill = 'tonexty') %>%
      add_trace(y = ~stack4, name = 'Reputation', fill = 'tonexty') %>%
      add_trace(y = ~stack5, name = 'Acute', fill = 'tonexty') %>%
      add_trace(y = ~stack6, name = 'Chronic', fill = 'tonexty') %>%
      add_trace(y = ~stack7, name = 'Resource Efficiency', fill = 'tonexty') %>%
      add_trace(y = ~stack8, name = 'Energy Source', fill = 'tonexty') %>%
      add_trace(y = ~stack9, name = 'Resilience', fill = 'tonexty') %>%
      layout(yaxis = list(title = 'Impact ($M)', showgrid = FALSE), xaxis = list(showgrid = FALSE), margin = list(l=80,b=100))
    } # endif

   tplot

  }) 
  
  # TCFD stacked bar chart
  output$stackedCorpFinImpactsPlotPort <- renderPlotly({
    corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
    if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    parentCorp = dbsheet4
    if (input$inputLocationsPort != 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    if (input$inputLocationsPort == 'Entire portfolio') {
      #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$RiskYear == input$sliderInputYearPort),]
      corpTable2 <- corpTable2[which(corpTable2$RiskYear == input$sliderInputYearPort),]
    }
    ncorp <- pull(count(corpTable2))
    plot_ly(corpTable2, x = ~TCFDCategoryName, y = ~ValueAtRisk, type='bar', text=corpTable2$RiskFactorName, marker = list(color = colorRampPalette(brewer.pal(11,"Spectral"))(ncorp))) %>%
      layout(yaxis = list(title = 'Impact ($M)'), barmode = 'stack', margin = list(l=80,b=100))
  })
  
  #Data table
  output$corpFinImpactsPort <- DT::renderDataTable({
     #colnames(corpTable2) = c('Location','TCFD Category','Subcategory','Risk Factor','Scenario','Year','Value at Risk ($M)') #someday figure this out
    corpTable2 <- readr::read_csv("./data/scoring_engine/nonphysical/TCSDB_structure.locations.csv.damages.allDFs.withvalues.with.nonphysical.byparentcorp.csv")
    if(input$riskfactor_subset_portfolio=="Chronic physical + Carbon price") corpTable2 <- filter(corpTable2, TCFDSubCatName=="Chronic" | RiskFactorName=="Carbon pricing")
    parentCorp = dbsheet4
      if (input$inputLocationsPort != 'Entire portfolio') {
        #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
        corpTable2 <- corpTable2[which(corpTable2$Location == input$inputLocationsPort & corpTable2$RiskYear == input$sliderInputYearPort),]
      }
      if (input$inputLocationsPort == 'Entire portfolio') {
        #corpTable2 <- corpTable2[which(corpTable2$ParentCorpID == USER$ParentCorpID & corpTable2$RiskYear == input$sliderInputYearPort),]
        corpTable2 <- corpTable2[which(corpTable2$RiskYear == input$sliderInputYearPort),]
      }
      corpTable2[1:7]
  })

  # ----------------------------
  #         REPORT
  # ----------------------------  
  
  output$report <- downloadHandler(
    filename = "report.docx",
    content = function(file) {
      # Copy the report file to a temporary directory before processing it, in
      # case we don't have write permissions to the current working dir (which
      # can happen when deployed).
      tempReport <- file.path(tempdir(), "report.Rmd")
      file.copy("report.Rmd", tempReport, overwrite = TRUE)
      
      # Set up parameters to pass to Rmd document
      tempparams <- list(pParentCorpName = USER$ParentCorpName,
                     pTCFDGova = input$TCFDGova,
                     pTCFDGovb = input$TCFDGovb
                     )

      # Subset a table to pass to "knittr::kable in the RMD"
      corpKable = subset(corpTable,(ParentCorpID == USER$ParentCorpID & RiskYear == 2030), select = Location:ValueAtRisk)
      corpKableBoise = subset(corpKable,Location == "Boise", select = Location:ValueAtRisk)
      # Knit the document, passing in the `params` list, and eval it in a
      # child of the global environment (this isolates the code in the document
      # from the code in this app).
      rmarkdown::render(tempReport, output_file = file,
                        params = tempparams
                        # envir = new.env(parent = globalenv())
      )
    }
  )
  
  
  
#I think this is all old & can be deleted soon.  
  # output$map_micron_boise <- renderUI({
  #   input$Member
  #   # iframe finds its target source in the www directory.
  #   thismap <- tags$iframe(src="map.html", height=300, width=300)
  #   thismap
  # })
  # 
  # output$map_micron_singapore <- renderUI({
  #   # iframe finds its target source in the www directory.
  #   thismap <- tags$iframe(src="map_singapore.html", height=300, width=300)
  #   thismap
  # })
  # 
  # output$plot1 <- renderPlot({
  #   data <- histdata[seq_len(input$slider)]
  #   hist(data)
  # })


# Terry -----------------------------------------------------------

  # Functions
    source("./functions/fit_distributions.r")
    source("./functions/sigmoid.r")
    source("./functions/quadratic.r")
    source("./data/sealevel_us/function_annual_probability_withslr.r")

  # Data
    source("./data/transfer_functions/load_database_transfer_functions.r")
    source("./data/users/load_database_users.r")
    #source("./data/users/write_dbsqlite_test.r")
    fl_dept <- extract_hazus_functions()

  # Constants
    range_tempK = seq(270,320,0.01)
    # x-axis tickmarks are not labelled properly if the first period below is longer than 7 characters.
    periods <- c("1976-05", "2016-25", "2026-35", "2036-45", "2046-55", "2056-65", "2066-75", "2076-85", "2086-95")
    shapes <- c(81,82,83,84,85,86,87,88,89)
    scales <- c(292,293,294,295,296,297,298,299,300)
    thresholds <- c(285,290,295,300,305,310)
    initializer <- c(0,0,0,0,0,0,0)
    colors <- brewer.pal(length(thresholds), "Spectral")
    ltypes <- c(1:length(thresholds))
    labels <- c("285K","290K","295K","300K","305K","310K")
    slrScenarios = c("0.3_-_MED","0.5_-_MED","1.0_-_MED","1.5_-_MED","2.0_-_MED","2.5_-_MED")
    slrYears = c(2020,2030,2040,2050,2060,2070,2080,2090,2100)

# -----------
# Portfolio analysis
# -----------

  output$stockselected <- renderText({
#	stock_parameters = filter(stocks_nasdaq,Symbol==input$selected_nasdaq)
	stock_parameters = filter(stocks_nasdaq,Security.Name==input$selected_nasdaq)
	symbol = stock_parameters[1,1]
	name = stock_parameters[1,2]
	paste(symbol, "==", name,"== NASDAQ")
	})

  observeEvent(input$add2portfolio, {session$sendCustomMessage(type = 'testmessage',
      message = "This company will be added to the portfolio.") })

  output$stock_financial_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,3]
	p2 = stock_parameters[1,4]
	p3 = stock_parameters[1,5]
	paste(p1,p2,p3)
	# Use the following with htmlOutput in ui.R
	# if(p3 > 10){return(paste("<span style=\"color:red\">This is red text</span>"))} 
       	#        else{return(paste("<span style=\"color:blue\">This is blue text</span>"))}
	})

  output$stock_financial_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,3]
	p2 = stock_parameters[1,4]
	p3 = stock_parameters[1,5]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_overall_score_gauge <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = round( sum(stock_parameters[1,3:14])/12 )
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,3]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,4]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_financial_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,5]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,6]
	p2 = stock_parameters[1,7]
	p3 = stock_parameters[1,8]
	paste(p1,p2,p3)
	})

  output$stock_transition_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,6]
	p2 = stock_parameters[1,7]
	p3 = stock_parameters[1,8]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_transition_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,6]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,7]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_transition_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,8]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,9]
	p2 = stock_parameters[1,10]
	p3 = stock_parameters[1,11]
	paste(p1,p2,p3)
	})

  output$stock_physical_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,9]
	p2 = stock_parameters[1,10]
	p3 = stock_parameters[1,11]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_physical_gauge_temperature <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,9]
	# Score below is weighted value of percentage electrical load increases from /functions/damage_impacts_4function_elec_load.r .
	score_input = read.table("./output/score_input_elec_load.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_gauge_slr <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,10]
	# Score below is weighted value of percentage flood damage from /functions/damage_impacts_4function_hazus_flood_depth_damage.r .
	score_input = read.table("./output/score_input_flood.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_physical_gauge_drought <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,11]
	# Score below is weighted value of percentage drought damage computed below when input$impact_selected == "Corn Yield (US, drought)" .
	score_input = read.table("./output/score_input_drought.csv")
	if(input$selected_nasdaq=="Micron Technology, Inc. - Common Stock") p = 1000 - round(10*as.numeric(score_input))
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_parameters <- renderText({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,12]
	p2 = stock_parameters[1,13]
	p3 = stock_parameters[1,14]
	paste(p1,p2,p3)
	})

  output$stock_opportunity_factors <- renderText({
	stock_parameters = filter(stocks_nasdaq_factors,Security.Name==input$selected_nasdaq)
	p1 = stock_parameters[1,12]
	p2 = stock_parameters[1,13]
	p3 = stock_parameters[1,14]
	paste(p1,p2,p3,sep="\n")
	})

  output$stock_opportunity_gauge1 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,12]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_gauge2 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,13]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

  output$stock_opportunity_gauge3 <- renderGauge({
	stock_parameters = filter(stocks_nasdaq_parameters,Security.Name==input$selected_nasdaq)
	p = stock_parameters[1,14]
	gauge(p, min = 0, max = 1000, symbol = '', 
            gaugeSectors( success = c(800, 1000), warning = c(400, 790), danger = c(0, 390))
            )
	})

# -----------
# Climate variables
# -----------

  output$temp_climplot1 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     #test.hist = read.table("./data/tasmax_day_BCSD_historical_r1i1p1_inmcm4_1950-2005.interpolated.merged.aggregated", header=TRUE)
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.1970-1979.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
     bins <- seq(min(x), max(x), length.out = input$bins + 1)
     #hist(x, breaks = bins, col = 'skyblue', border = 'white', main="1950-2005, inmcm4", xlab="Degrees K")
     hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 1970-1979, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.1981-2000.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 1981-2000", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.1981-2000.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 1981-2000", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot2 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_rcp85_r1i1p1_inmcm4_2006-2100.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2020-2029.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
     bins <- seq(min(x), max(x), length.out = input$bins + 1)
     #hist(x, breaks = bins, col = 'yellow', border = 'white', main="2006-2100, RCP8.5, inmcm4", xlab="Degrees K")
     hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2020-2029, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2011-2030.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2011-2030", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2011-2030.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2011-2030", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot3 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_historical_r1i1p1_CNRM-CM5_1950-2005.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2050-2059.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
    bins <- seq(min(x), max(x), length.out = input$bins + 1)
    #hist(x, breaks = bins, col = 'skyblue', border = 'white', main="1950-2005, CNRM-CM5", xlab="Degrees K")
    hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2050-2059, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2041-2060.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2041-2060", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2041-2060.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2041-2060", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot4 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
     #test.hist = read.table("./data/tasmax_day_BCSD_rcp85_r1i1p1_CNRM-CM5_2006-2100.interpolated.merged.aggregated", header=TRUE)
     # The original data set contains 159650 daily tasmax values:  10 years, 31 days covering June, 5 models, 103 NEX-GDDP grid centers in Western Equatoria region of South Sudan.  This has been downselected to fewer points to reduce loading speed.
     test.hist = read.table("./data/temperature/nex_gddp_western_equatoria_103pts_5models/tasmax.2090-2099.allmodels.westernequatoria.jun.csv.10pts", header=FALSE)
     test.hist[,1] <- NULL
     x = ts(test.hist[1,])
     x <- x - 273.15
    bins <- seq(min(x), max(x), length.out = input$bins + 1)
    #hist(x, breaks = bins, col = 'yellow', border = 'white', main="2006-2100, RCP8.5, CNRM-CM5", xlab="Degrees K")
    hist(x, breaks = bins, col = 'skyblue', border = 'white', main="June 2090-2099, 5 models, Western Equatoria", xlab="Daily Maximum Temperature (degC)")
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	d <- read.table("./data/temperature/loca/lga/tasmax_day_input4r.lga.2locs.32models.2071-2090.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Queens, NY, 32 models, JJA 2071-2090", xlab="Daily Maximum Temperature (degC)", xlim=c(15,45) )
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	d <- read.table("./data/temperature/loca/phx/tasmax_day_input4r.phx.4locs.32models.2071-2090.annual", header=FALSE)
	d <- d - 273.15
	d <- d %>% select(V152:243)  # summer JJA
	dt <- t(d)
        bins <- seq(min(dt), max(dt), length.out = input$bins + 1)
	hist(dt, breaks=bins, col = 'skyblue', border = 'white', main="Phoenix, AZ, 32 models, JJA 2071-2090", xlab="Daily Maximum Temperature (degC)", xlim=c(30,55) )
  } # endif

  }) # end plot

  output$temp_climplot5 <- renderPlot({

   if(input$temperatureProjectionLocation=="Western Equatoria, South Sudan") {
    shapes <- c(81.8730, 93.0240, 88.9460, 84.7620, 95.8550, 90.0690, 86.1060, 90.3700, 91.5810)
    scales <- c(292.0320, 293.0880, 293.0820, 293.3870, 293.7670, 293.9150, 294.5310, 295.7390, 295.7960)
    #scales <- scales - 273.15
    #colors <- brewer.pal(length(shapes), "Spectral")
    colors <- brewer.pal(length(shapes), "Paired")
    ltypes <- c(1:length(shapes))
    labels <- c("1976-2005", "2016-25", "2026-35", "2036-45", "2046-55", "2056-65", "2066-75", "2076-85", "2086-95")
    x <- seq(275.15,315.15,1.0)
    xrange <- c(275.15,315.15)
    xcentigrade <- x - 273.15
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	xlim=xrange, 
	ylim=c(0,0.12), 
	main = "Temperature Distributions for Entire Year",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	xaxt="n"
	)
    for(i in 2:length(shapes) ) {
      lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
    #axis(1, at=x, labels=x)
    axis(1, at=x, labels=xcentigrade)
    legend("topright", inset=.05, title="Periods", labels, lwd=3, lty=ltypes, col=colors)
  } # endif

   if(input$temperatureProjectionLocation=="Queens, NY") {
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the NORMAL distribution was best.
	# "1" "Normal 28.3077153023098 3.82693158121976"  "1" "Normal 29.6137309527853 3.97273119036855"  "1" "Normal 31.3714733780571 4.07573105989084"  "1" "Normal 33.3634844514267 4.25056671686859"
	# Fits were done in units of degC.
	shapes = c(28.3077153023098, 29.6137309527853, 31.3714733780571, 33.3634844514267)
	scales = c( 3.82693158121976, 3.97273119036855, 4.07573105989084, 4.25056671686859)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(15,45,0.5)
      plot(x,dnorm(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dnorm(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topright", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)
  } # endif

   if(input$temperatureProjectionLocation=="Phoenix, AZ") {
	# Compiled fit data for 1981-2000, 2011-2030, 2041-2060, 2071-2090.
	# Visual inspection of plots for all distributions showed that the WEIBULL distribution was best.
	# "1" "Weibull 16.7809908064543 41.1370130351604" "1" "Weibull 16.5311810167565 42.4277739861075" "1" "Weibull 16.6090200453762 44.2031463365842" "1" "Weibull 15.705047999892 46.3894333282642"
	# Fits were done in units of degC.
	shapes = c(16.7809908064543, 16.5311810167565, 16.6090200453762, 15.705047999892)
	scales = c(41.1370130351604, 42.4277739861075, 44.2031463365842, 46.3894333282642)
    	#colors <- brewer.pal(length(shapes), "Paired")
    	colors <- c("green", "blue", "orange", "red")
    	ltypes <- c(1:length(shapes))
    	labels <- c("1981-2000", "2011-2030", "2041-2060", "2071-2090")
       
      x <- seq(30,55,0.5)
      plot(x,dweibull(x,shapes[1],scales[1]), type="l", lwd=3, lty=1, col=colors[1], 
	#xlim=xrange, 
	#ylim=c(0,0.12), 
	main = "Summer (JJA) Temperature Distributions",
	xlab="Daily Maximum Surface Temperature (degC)", ylab="Probability Density", 
	#xaxt="n"
	)
      for(i in 2:length(shapes) ) {
        lines( x, dweibull(x,shapes[i],scales[i]), lwd=2, lty=i, col=colors[i] )
      }
      legend("topright", inset=.01, title="Periods", labels, lwd=3, lty=ltypes, col=colors)

  } # endif

  }) # end plot

  output$sealevel_extremes_plot1 <- renderPlot({
	location_parameters = filter(ewl,name==input$extremewaterLocation) %>% select(3:8)
      # z contains the location, scale, and shape parameters in rows 1, 3, and 5 of column 1.
      # z contains the +/-95% confidence interval of these parameters in rows 2, 4, and 6 of column 1.
	z = t(location_parameters)
	loc = z[1,1]
	sc = z[3,1]
	sh = z[5,1]
	return_periods = c(1.01,2,5,10,20,50,100,200,500)
	if(sh > 0) {yt=(-log((1-1/return_periods)))^(-sh);
		    return_levels = ((sc/sh)*(yt-1)) + loc}
	if(sh == 0) {yt=-log((1-1/return_periods));
		    return_levels = loc - sc*log(yt) }
	plot(return_levels, log="x", type="b", xlab="Return Period (years)", ylab="Level (m)", xaxt="n")
	axis(1, at=c(1:length(return_periods)), labels=return_periods)
	#grid(NULL, NULL, lwd=2)
	abline(v=return_periods, h=return_levels, col="gray", lty=3, lwd=2)
#axis(1, at=c(1:6), labels=c("location","location_range","scale","scale_range","shape","shape_param"))
  })

  output$sealevel_extremes_plot2 <- renderPlot({
	rtnlevels_m_hist = filter(world_ewl,CLSFID_LONGI_LATI==input$extremewaterLocation2) %>% select(7:15)
	z = t(rtnlevels_m_hist)
	plot(z, type="l",lwd=3,col="black", xlab="Return Period (years)", ylab="Return Level (m)", xaxt="n")
	#lines(z2, lwd=3, col="yellow")
	#lines(z3, lwd=3, col="green")
	axis(1, at=c(1:9), labels=c("2","5","10","25","50","100","250","500","1000"))
     	#legend("topleft", inset=.05, title="Scenarios",legend=c("RCP 8.5","RCP 4.5","RCP 2.6"), lwd=3, col=c("red","yellow","green"))
  })

  output$sealevel_extremes_plot3 <- renderPlot({
	loc <- input$extremewaterLocation2_with_slr_station
	scenario <- input$world_slr_scenario
	source("./data/sealevel_world/plot_sealevel_data_world_ewl_slr.r", local=TRUE)
  })

  output$sealevel_projections_plot1 <- renderPlot({
	profile1 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="0.3_-_MED") %>% select(7:17)
	z = t(profile1)
	profile2 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="0.5_-_MED") %>% select(7:17)
	z2 = t(profile2)
	profile3 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="1.0_-_MED") %>% select(7:17)
	z3 = t(profile3)
	profile4 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="1.5_-_MED") %>% select(7:17)
	z4 = t(profile4)
	profile5 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="2.0_-_MED") %>% select(7:17)
	z5 = t(profile5)
	profile6 = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario=="2.5_-_MED") %>% select(7:17)
	z6 = t(profile6)
	plot(z, type="l",lwd=3,col="black", xlab="Year", ylab="Relative Local Sea Level Rise (cm)", xaxt="n")
	lines(z2, lwd=3, col="blue")
	lines(z3, lwd=3, col="green")
	lines(z4, lwd=3, col="yellow")
	lines(z5, lwd=3, col="orange")
	lines(z6, lwd=3, col="red")
	axis(1, at=c(1:11), labels=c("2000","2010","2020","2030","2040","2050","2060","2070","2080","2090","2100"))
     	legend("topleft", inset=.05, title="Scenarios (GMSL 2100)",legend=c("0.3m","0.5m","1.0m","1.5m","2.0m","2.5m"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
  })

  output$sealevel_projections_plot2 <- renderPlot({
	profile1 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(8:10)
	z = t(profile1)
	profile2 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(11:13)
	z2 = t(profile2)
	profile3 = filter(world_slr,Site==input$sealevelProjectionLocation2) %>% select(14:16)
	z3 = t(profile3)
	plot(z, type="l",lwd=3,col="red", xlab="Year", ylab="Relative Local Sea Level Rise (cm)", xaxt="n")
	lines(z2, lwd=3, col="yellow")
	lines(z3, lwd=3, col="green")
	axis(1, at=c(1:3), labels=c("2030","2050","2100"))
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP 8.5","RCP 4.5","RCP 2.6"), lwd=3, col=c("red","yellow","green"))
  })

  output$returnlevel_probability <- renderText({
	source("./data/sealevel_us/annual_probability_withslr.r", local=TRUE)
	#slrScenarios = c("0.3_-_MED","0.5_-_MED","1.0_-_MED","1.5_-_MED","2.0_-_MED","2.5_-_MED")
	#slrYears = c(2020,2030,2040,2050,2060,2070,2080,2090,2100)
	# slrScenarios and slrYears are defined in and returned as the second and third elements in a list by function_annual_probability_withslr.  The annual_probability_withslr matrix is the first element in the list.
	slrScenarios = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, input$returnLevel)[[2]]
	slrYears = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, input$returnLevel)[[3]]
	thresholds_flood_m <- c(0,1.5,3,4.5,6,7.5)
	thresholds_flood_m_midpoints = c(0.75, 2.25, 3.75, 5.25, 6.75)
	outputfile = "./output/output_flood_annual_prob.csv"
	annual_probability_withslr_1 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[1])[[1]]
	annual_probability_withslr_2 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[2])[[1]]
	annual_probability_withslr_3 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[3])[[1]]
	annual_probability_withslr_4 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[4])[[1]]
	annual_probability_withslr_5 = function_annual_probability_withslr(input$extremewaterLocation, input$sealevelProjectionLocation, thresholds_flood_m_midpoints[5])[[1]]
	# The table is written explicitly here, rather than in function_annual_probability_     withslr.
	write.table(annual_probability_withslr_1,"./output/output_flood_annual_prob_level1.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_2,"./output/output_flood_annual_prob_level2.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_3,"./output/output_flood_annual_prob_level3.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_4,"./output/output_flood_annual_prob_level4.csv", row.names=slrScenarios, col.names=slrYears)
	write.table(annual_probability_withslr_5,"./output/output_flood_annual_prob_level5.csv", row.names=slrScenarios, col.names=slrYears)

	if(input$slrScenario=="0.3 meter") selectedScenario="0.3_-_MED"
	if(input$slrScenario=="0.5 meter") selectedScenario="0.5_-_MED"
	if(input$slrScenario=="1.0 meter") selectedScenario="1.0_-_MED"
	if(input$slrScenario=="1.5 meters") selectedScenario="1.5_-_MED"
	if(input$slrScenario=="2.0 meters") selectedScenario="2.0_-_MED"
	if(input$slrScenario=="2.5 meters") selectedScenario="2.5_-_MED"
	#selectedScenario = paste(as.character(input$slrScenario),"_-_MED")
	if(input$slrYear=="2020") column=9
	if(input$slrYear=="2030") column=10
	if(input$slrYear=="2040") column=11
	if(input$slrYear=="2050") column=12
	if(input$slrYear=="2060") column=13
	if(input$slrYear=="2070") column=14
	if(input$slrYear=="2080") column=15
	if(input$slrYear=="2090") column=16
	if(input$slrYear=="2100") column=17
	slr_scenario_year = filter(proj,Site==input$sealevelProjectionLocation) %>% filter(Scenario==selectedScenario) %>% select(column)
	location_parameters = filter(ewl,name==input$extremewaterLocation) %>% select(3:8)
      # z contains the location, scale, and shape parameters in rows 1, 3, and 5 of column 1.
      # z contains the +/-95% confidence interval of these parameters in rows 2, 4, and 6 of column 1.
	z = t(location_parameters)
	loc = z[1,1]
	sc = z[3,1]
	sh = z[5,1]
	return_level = as.numeric(input$returnLevel)
	# XXX need to handle sh==0
	if(sh != 0) {return_period = ((sh/sc)*(return_level-loc) + 1)^(1/sh);
		    a = 1/(1+exp(1/return_period)) }
	# Local slr change is in centimeters.
	return_level_withslr = return_level - slr_scenario_year/100
	# XXX need to handle sh==0
	if(sh != 0) {return_period_withslr = ((sh/sc)*(return_level_withslr-loc) + 1)^(1/sh) }
	annual_probability = round(100*1/return_period, digits=2)
	annual_probability_withslr = round(100*1/return_period_withslr, digits=2)
	#paste(input$slrScenario, input$slrYear, slr_scenario_year, "cm", loc,sc,sh,a,return_period,return_period_withslr,annual_probability,"%",annual_probability_withslr,"%")
	#paste("Historical:",annual_probability,"%","Future:",min(annual_probability_withslr,100),"%")
	#paste("Historical: ",annual_probability,"% -- ",input$slrYear,":",min(annual_probability_withslr,100),"%")
	p1 = paste("Historical - ",annual_probability,"%")
	p2 = paste(input$slrYear,"-       ",min(annual_probability_withslr,100),"%")
	paste(p1,p2,sep="\n")
	})

  output$sealevel_ewl_probabilities <- renderPlot({
	source("./data/sealevel_us/annual_probability_withslr.r", local=TRUE)
	position="topleft"
	if(input$returnLevel==1) position="topright"
    # slrYears are defined in annual_probability_withslr.r.
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(annual_probability_withslr[1,], type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Year", ylab="Annual Probability (%)", xaxt="n")
	lines(annual_probability_withslr[2,], col="blue")
	lines(annual_probability_withslr[3,], col="green")
	lines(annual_probability_withslr[4,], col="yellow")
	lines(annual_probability_withslr[5,], col="orange")
	lines(annual_probability_withslr[6,], col="red")
	axis(1, at=c(1:length(slrYears)), labels=slrYears)
     	legend(position, inset=.05, title="Scenarios (GMSL 2100)",legend=c("0.3m","0.5m","1.0m","1.5m","2.0m","2.5m"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
	})

output$drought_frequencies_lonlat <- renderPlot({
	# Processed drought data is read into dataframe d by /data/drought/load_drought_data.r, which is sourced at the beginning of server.R.
	lon=as.numeric(input$droughtlon)
	lat=as.numeric(input$droughtlat)
	source("./data/drought/process_drought_data.r", local=TRUE)
	#paste(input$droughtlon,input$droughtlat,upperlon,lowerlon,upperlat,lowerlat)
	#paste(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#plot(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	
	# Fields in d3 used below are lon, lat, and 9 periods defined in load_drought_data.r.
	values = select(d3, V3:V11)
	tvalues = 100*as.numeric( t(values) )
	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Period", ylab="Annual Probability (%)", xaxt="n")
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(d4[3,1]=="No_data") legend("center", title="NO DATA AVAILABLE AT SPECIFIED LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
	})

output$drought_frequencies_facility <- renderPlot({
	# Processed drought data is read into dataframe d by load_drought_data.r, which is sourced at the beginning of server.R.
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)
	lon=as.numeric(fac_selected[1,2])
	lat=as.numeric(fac_selected[1,3])

	#source("./data/drought/process_drought_data.r", local=TRUE)
	#paste(input$droughtlon,input$droughtlat,upperlon,lowerlon,upperlat,lowerlat)
	#paste(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#plot(as.numeric(d4[3,]), as.numeric(d4[4,]) )
	#values = select(d3, V3:V11)
	#tvalues = 100*as.numeric( t(values) )

	nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	tvalues = 100*as.numeric( t(values) )

	plot(tvalues, type="l", lwd=3, lty=1, col="black", ylim=c(0,100), xlab="Period", ylab="Annual Probability (%)", xaxt="n")
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topleft", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(values$V8=="No_data") legend("center", title="NO DATA AVAILABLE AT THIS LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
	})

# -----------
# Impact functions (damage functions)
# -----------
  output$impactplot1 <- renderPlot({
    x = range_tempK
    plot(x,sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$impactplot2 <- renderPlot({
    x = range_tempK
    plot(x,quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$impactplot3 <- renderPlot({
    x = range_tempK
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  output$impactplot_elecload <- renderPlot({
    source("./functions/fit_elec_load_v1.r", local=TRUE)
  })

  output$impactplot_building_flood <- renderPlot({
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
	#s2 = paste(s[1])
    damage_function_id = as.numeric(s[1])
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
  })

  output$impactplot_corn_drought_return_period <- renderPlot({
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
  })

  output$impactplot_agriculture_brazil <- renderPlot({
    source("./functions/fit_agriculture_brazil_v1.r", local=TRUE)
  })

  output$impactplot_maize_us <- renderPlot({
    source("./functions/fit_maize_yield_us_hourly_temp.r", local=TRUE)
  })

  output$comingsoon <- renderImage({
    list(src = "./images/coming_soon.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig3_precip"))
  }, deleteFile = FALSE)

  output$impactplot4 <- renderImage({
    #filename <- normalizePath(file.path('./images/lobell_crop_yields_2017_fig1.png'))
    list(src = "./images/lobell_crop_yields_2017_fig1.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig1_temperature"))
  }, deleteFile = FALSE)

  output$impactplot5 <- renderImage({
    list(src = "./images/lobell_crop_yields_2017_fig3.png",width=300,height=300,alt = paste("lobell_crop_yields_2017_fig3_precip"))
  }, deleteFile = FALSE)

  output$impactplot6 <- renderImage({
    list(src = "./images/troy_climate_indices_crop_yields_2015_fig2.png",width=300,height=300,alt = paste("troy_climate_indices_crop_yields_2015_fig2_multiplevariables"))
  }, deleteFile = FALSE)

  output$impactplot7 <- renderImage({
    list(src = "./images/carleton_hsiang_climate_dose_response_2016_fig3a.png",width=1000,height=500,alt = paste("carleton_hsiang_climate_dose_response_2016_fig3a_multiplesectors"))
  }, deleteFile = FALSE)

  output$impactplot8 <- renderImage({
    list(src = "./images/carleton_hsiang_climate_dose_response_2016_fig3b.png",width=1000,height=500,alt = paste("carleton_hsiang_climate_dose_response_2016_fig3b_multiplesectors"))
  }, deleteFile = FALSE)

  output$impactplot9 <- renderImage({
    list(src = "./images/thompson_cooling_water_Teffects_v1b_power_airtemp.png",width=600,height=450,alt = paste("thompson_power_generation_air_and_water_temperature"))
  }, deleteFile = FALSE)

  output$impactplot10 <- renderImage({
    list(src = "./images/thompson_cooling_water_Teffects_v1b_water.png",width=500,height=300,alt = paste("thompson_water_needed_water_temperature"))
  }, deleteFile = FALSE)

  output$impactplot_crops_wang <- renderImage({
    list(src = "./images/wang_crop_productivity_climate_midwestUS_2016_fig13.png",width=500,height=300,alt = paste("wang_crop_productivity_climate_midwestUS_2016_fig13"))
  }, deleteFile = FALSE)

  output$impactplot_crops_mishra <- renderImage({
    list(src = "./images/mishra_corn_soy_midwestUS_drought_2010_fig5.png",width=500,height=300,alt = paste("mishra_corn_soy_midwestUS_drought_2010_fig5"))
  }, deleteFile = FALSE)

  output$impactplot_crops_mhakbela <- renderImage({
    list(src = "./images/mhakbela_drought_wheat_canada_2010_fig2.png",width=500,height=300,alt = paste("mhakbela_drought_wheat_canada_2010_fig2"))
  }, deleteFile = FALSE)

# -----------
# Probability of Exceeding Thresholds
# -----------
  # Note that the shapes and scales values are for a pre-determined Weibull distribution for South Sudan.

  output$impactestimateplot1 <- renderPlot({
    #shapes <- c(81.8730, 93.0240, 88.9460, 84.7620, 95.8550, 90.0690, 86.1060, 90.3700, 91.5810)
    #scales <- c(292.0320, 293.0880, 293.0820, 293.3870, 293.7670, 293.9150, 294.5310, 295.7390, 295.7960)
    x <- seq(270,320,0.1)
    # pweibull is the CDF for dweibull.
    probexceed = matrix(0,length(thresholds),length(shapes))
    for(i in 1:length(shapes)) {probexceed[1,i] <- (1.0-pweibull(input$threshold,shapes[i],scales[i]) ) }
    #colnames(probexceed) <- periods
    # xaxt="n" in plot below turns off xaxis tickmarks.  These are added explicitly with axis.
    plot(probexceed[1,], type="l", lwd=3, lty=1, col=colors[1], ylim=c(0,1.0), xlab="Time Periods", ylab="Probability of Exceeding Threshold", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
#   for(j in 1:length(thresholds)) { for(i in 1:length(shapes)) {probexceed[j,i] <- (1.0-pweibull(thresholds[j],shapes[i],scales[i]) ) } }
#    plot(probexceed[1,], type="l", lwd=3, lty=1, col=colors[1], ylim=c(0,1.0), xlab="Periods", ylab="Probability of Exceeding Threshold")
#    for(i in 2:length(thresholds) ) {
#      lines( probexceed[i,], lwd=3, lty=i, col=colors[i] )
#    }
#    legend("topright", inset=.01, title="Thresholds", labels, lwd=3, lty=ltypes, col=colors)
  })

# -----------
# Probabilistic Impact Estimate
# -----------
  output$impactestimateplot2 <- renderPlot({

  if (input$impact_selected == "Custom-built") {
    x <- seq(270,320,0.1)

# The following fails because the threshold inputs to damagej1/2 are functions of j.
#    damage = damage %>% fdamage(thresholds, shapes, sigmoidlimit, sigmoidsteepness, sigmoidmidpoint, quadraticlimit, quadraticshape, quadraticmidpoint, wt1, wt2)

    source("./functions/damage_impacts.r", local=TRUE)

    write.table(damage, file="./output/damage_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_custom.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Probabilistic Impact(%)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
        current_risk = round(impactbyperiod_relative2baseperiod[2], digits=2)
	if(current_risk>=0) {thiscol="blue"} else {thiscol="red"}
        lines(c(2,2),c(0,current_risk), col=thiscol, lwd=2 )
        lines(c(1,length(periods)), c(0,0), col="green" )
        text(3.2,0,"CURRENT IMPACT (%) = ", font=4, col=thiscol)
        text(5.2,0,current_risk, font=4, col=thiscol)
    } #endif

  if (input$impact_selected == "Electricity Load (US; temperature)") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
    source("./functions/damage_impacts_4function_elec_load.r", local=TRUE)

    write.table(damage, file="./output/damage_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_elecload.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Change in Peak Load (Mw)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    } #endif

  if (input$impact_selected == "Building Damage (flood depth)") {
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    #source("./data/hazus/extract_hazus_flood_depth_damage.r", local=TRUE)
    #source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    source("./data/hazus/function_extract_hazus_flood_depth_damage_return_damage_at_depth.r", local=TRUE)

    #damage_function_id = input$hazus_damage_function_id
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    damage_function_id = as.numeric(s[1])
    #get_hazus_damage_function(damage_function_id)

    # The following reads the table of annual probabilities created by ./data/sealevel_us/annual_probability_withslr.r. Note that this is a dynamic table created by the selection of location and return level from the SLR section of the localized climate probabilities tab.  The table has rows for each GMSL scenario and colums for years 2020-2100 in 10-year increments.
    annual_prob_given_return_level = read.table("./output/output_flood_annual_prob.csv", header=TRUE)
    annual_prob_given_return_level1 = read.table("./output/output_flood_annual_prob_level1.csv", header=TRUE)
    source("./functions/damage_impacts_4function_hazus_flood_depth_damage.r", local=TRUE)

    write.table(damage, file="./output/damage_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impacts, file="./output/impacts_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(impactbyperiod, file="./output/impactbyperiod_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_buildingflood.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Expected Building Damage for Selected RL (%)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    } #endif

  if (input$impact_selected == "Corn Yield (US, drought)") {
	# Processed drought data is read into dataframe d by load_drought_data.r, which is sourced at the beginning of server.R.
	location_name = "Selected Location"
	lon=as.numeric(input$droughtlon)
	lat=as.numeric(input$droughtlat)
	# facility_locations list is defined by ./data/financial/load_financial_data.r
	# The most up-to-date locations list is created by the last run of the SE and is located at ./data/scoring_engine/TCSDB_structure.locations.csv.  This is accessed by load_financial_data.r.
	#fac_selected = facility_locations %>% filter(facility==input$drought_facility)
	fac_selected = facility_locations %>% filter(LocationID_ParentCorpID_LocationName==input$drought_facility)
	if(input$use_facility_for_drought=="TRUE") {
		lon=as.numeric(fac_selected[1,2])
		lat=as.numeric(fac_selected[1,3]) 
		location_name = fac_selected[1,1]}

	#source("./data/drought/process_drought_data.r", local=TRUE)
	# process_drought_data.r produces the data vector d3.  It also writes this data to /output/output_drought_annual_prob.csv .
	# Fields in d3 used below are lon, lat, and fractional annual probabilities for 9 periods defined in load_drought_data.r.
	# For example, droughtPeriods = c("1950-99","2016-25","2026-35","2036-45","2046-55","2056-65","2066-75","2076-85","2086-95")
	#values = select(d3, V3:V11)
	#tvalues = 100*as.numeric( t(values) )

	nd = read.table("./data/scoring_engine/drought/TCSDB_structure.locations.csv.pdsisc", header=FALSE)
	values = nd %>% filter(nd$V1==input$drought_facility) %>% select(V8:V17)
	tvalues = 100*as.numeric( t(values) )

        source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
        historical_reduction_10yr_return_period = yield_reduction_pct[4]
        projected_return_period_same_reduction = (10/tvalues) * 10
	annual_expected_reduction = (-1.0*historical_reduction_10yr_return_period) * tvalues/100

    	impactbyperiod = annual_expected_reduction
    	impactbyperiod_relative2baseperiod = impactbyperiod - impactbyperiod[1]
    	write.table(impactbyperiod, file="./output/impactbyperiod_corn_yield_us_drought.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    	write.table(c("impactbyperiod impactbyperiod_relative2baseperiod",paste(impactbyperiod,impactbyperiod_relative2baseperiod)), file="./output/impactbyperiod_base_and_relative2baseperiod_corn_yield_us_drought.csv", row.names = FALSE, col.names = FALSE, sep=" ")

	# Calculate weighted vector of impact by period for climate score.
	weightbyperiod = c(0,80,10,5,1,1,1,1,1)
	#weightbyperiod = c(0,50,50,0,0,0,0,0,0)
	#percent_change = 100*(impactbyperiod/impactbyperiod[1] - 1.0)
	# Impacts on corn yields due to drought are annual percent yield reduction and are negative.
	percent_change = -1.0*(impactbyperiod - impactbyperiod[1])
	score_input_drought = sum( weightbyperiod*percent_change)/100
	#score_input_drought = sum( weightbyperiod*impactbyperiod_relative2baseperiod )/100
	write.table(score_input_drought, "./output/score_input_drought.csv", row.names=FALSE, col.names=FALSE)

	plot(annual_expected_reduction, type="l", lwd=3, lty=1, col="black", main=paste("Yield Change at",location_name,"(",lon,",",lat,")"), xlab="Periods", ylab="Expected Annual Yield Loss (%)", xaxt="n", ylim=c(-1.0*historical_reduction_10yr_return_period, 0))
	axis(1, at=c(1:length(droughtPeriods)), labels=droughtPeriods)
     	legend("topright", inset=.05, title="Scenarios",legend=c("RCP4.5","RCP8.5"), lwd=3, col=c("black","blue","green","yellow","orange","red"))
     	if(values$V8=="No_data") legend("center", title="NO DATA AVAILABLE AT SPECIFIED LOCATION", legend=" ", bg="red", text.col="white", text.font=2)
    } #endif

  if (input$impact_selected == "Agricultural Income (Brazil)") {
    return()
    } #endif

  if (input$impact_selected == "Maize Yield (US)") {
    return()
    } #endif

  })

  # Impact Function for impact estimate (controlled from impact-function tab)
  output$impactestimateplot3 <- renderPlot({
  
  if (input$impact_selected == "Custom-built") {
    x = range_tempK
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact (%)")
    } #endif

  if (input$impact_selected == "Electricity Load (US; temperature)") {
    source("./functions/fit_elec_load_v1.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Building Damage (flood depth)") {
    #fl_dept <- extract_hazus_functions()  # done at start of server.R in data section
    #source("./data/hazus/extract_hazus_flood_depth_damage.r", local=TRUE)
    #damage_function_id = input$hazus_damage_function_id
    damage_function_name = as.character(input$hazus_damage_function_id)
	s = unlist( strsplit(damage_function_name, "_") )
        # Given a list structure x, unlist simplifies it to produce a vector which contains all the atomic components which occur in x.
    damage_function_id = as.numeric(s[1])
    source("./data/hazus/function_extract_hazus_flood_depth_damage.r", local=TRUE)
    get_hazus_damage_function(damage_function_id)
    } #endif

  if (input$impact_selected == "Corn Yield (US, drought)") {
    source("./functions/fit_corn_yield_us_drought.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Agricultural Income (Brazil)") {
    source("./functions/fit_agriculture_brazil_v1.r", local=TRUE)
    } #endif

  if (input$impact_selected == "Maize Yield (US)") {
    source("./functions/fit_maize_yield_us_hourly_temp.r", local=TRUE)
    } #endif

  })

  # Beta Multiplier By Period
  output$financialplot1 <- renderPlot({
    x <- seq(275,315,0.1)
    # pweibull is the CDF for dweibull.
    source("./functions/damage_impacts.r", local=TRUE)
    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }
    plot(betamultiplier, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Beta Multiplier", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
  })

  # NPV impact on project
  output$financialplot2 <- renderPlot({
    x <- seq(275,315,0.1)
    
    source("./functions/damage_impacts.r", local=TRUE)

    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }

    # NPV calculation
    # Assume project starts in period 3 and that each period is a decade.
    cashflowinputs <- c(input$cashflow1,input$cashflow2,input$cashflow3,input$cashflow4,input$cashflow5,input$cashflow6,input$cashflow7)
    cashflow <- initializer
    for(i in 1:length(cashflow)) {cashflow[i] = cashflowinputs[i] }
    capitalcost <- input$capitalcost
    discount <- input$discount
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}
    discountedcashflow <- initializer
    for(i in 1:length(discountbydecade)) {discountedcashflow[i] = discountbydecade[i] * cashflow[i] }
    npv = sum(discountedcashflow) - capitalcost
    npvmultiplier <- initializer
    offset=2
    for(i in 1:length(npvmultiplier)) {npvmultiplier[i] = betamultiplier[i+offset]}
    for(i in 1:length(npvmultiplier)) {npvmultiplier[i] = npvmultiplier[i] - npvmultiplier[1] +1}
    discountedcashflow_modified <- discountedcashflow
    for(i in 1:length(npvmultiplier)) {discountedcashflow_modified[i] = discountedcashflow[i] / npvmultiplier[i]}
    npv_modified = sum(discountedcashflow_modified) - capitalcost

    write.table(c("betamultiplier",betamultiplier), file="./output/betamultiplier.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("npvmultiplier",npvmultiplier), file="./output/npvmultiplier.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("npv npv_modified",paste(npv,npv_modified)), file="./output/npv_base_and_modified.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("discountbydecade",discountbydecade), file="./output/discountbydecade.csv", row.names = FALSE, col.names = FALSE, sep=" ")
    write.table(c("discountedcashflow,discountedcashflow_modified",paste(discountedcashflow,discountedcashflow_modified)), file="./output/discountedcashflow_base_and_modified.csv", row.names = FALSE, col.names = FALSE, sep=" ")

    barplot(c(npv,npv_modified), col=c("green","red"), names.arg=c("Without Climate Impacts", "With Climate Impacts"),xlab="Unmodified and Modified NPV", ylab="NPV", ylim=c(-20,50) )
  })

# -----------
# Climate score
# -----------

  # Climate score by period

  output$scoreplot1 <- renderPlot({
    labels <- c("Without Adaptation","With Adaptation")
    x <- seq(275,315,0.1)
    
    source("./functions/damage_impacts.r", local=TRUE)

    betamultiplier = impactbyperiod
    for(i in 1:length(betamultiplier)) {betamultiplier[i]= 1 / (1 + impactbyperiod_relative2baseperiod[i]/100 )  }

    # Climate score calculation
    score <- betamultiplier
    # for(i in 1:length(betamultiplier)) {score[i] = 100 - 10*betamultiplier[i]^i}
    for(i in 1:length(score)) {score[i] = 100 + impactbyperiod_relative2baseperiod[i]}
    # for(i in 1:length(score)) {score[i] = 100 + impactbyperiod[i]}
    adaptation_adjustment <- c(0,0,0,0,5,10,15,20,20)
      if(input$adaptationplan=="None") {adaptation_adjustment = c(0,0,0,0,0,0,0,0,0)}
      if(input$adaptationplan=="Minimal") {adaptation_adjustment = c(0,0,1,5,5,5,5,5,5)}
      if(input$adaptationplan=="Moderate") {adaptation_adjustment = c(0,0,2,10,10,15,15,20,20)}
      if(input$adaptationplan=="Maximal") {adaptation_adjustment = c(0,0,3,10,15,20,20,30,30)}
    score2 = score + adaptation_adjustment
    plot(score, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Climate Score", xaxt="n", ylim=c(0,max(score)) )
	axis(1, at=c(1:length(periods)), labels=periods)
    lines(score2, lwd=3, lty=2, col=colors[2] )
    legend("topright", inset=.01, title="Scenarios", labels, lwd=3, lty=c(1,2), col=c(colors[1],colors[2]))
  })

   output$climatescores <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts.r", local=TRUE)
    score = impactbyperiod
    for(i in 1:length(score)) {score[i] = 100 + impactbyperiod_relative2baseperiod[i]}
    # for(i in 1:length(score)) {score[i] = 100 + impactbyperiod[i]}
    paste("Near-term (2016-25):", round(score[2],digits=0),"Mid-term (2026-35):", round(score[3],digits=0), "Long-term (2036-45):", round(score[4],digits=0), sep="\n") 
    })

   output$adaptationplan <- renderText({
      if(input$adaptationplan=="None") {adaptation_adjustment = "0  0  0  0  0  0  0  0  0"}
      if(input$adaptationplan=="Minimal") {adaptation_adjustment = "0  0  1  5  5  5  5  5  5"}
      if(input$adaptationplan=="Moderate") {adaptation_adjustment = "0  0  2  10  10  15  15  20  20"}
      if(input$adaptationplan=="Maximal") {adaptation_adjustment = "0  0  3  10  15  20  20  30  30"}
      paste("CREDITS TO CLIMATE SCORE BY PERIOD:   ", adaptation_adjustment)
    })

  # Impact function from impact-function tab.
  output$scoreplot2 <- renderPlot({
    x <- seq(270,320,0.01)
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

# -----------
# Adaptation planning
# -----------

  # Impact function from impact-function tab.
  output$adaptationplot1 <- renderPlot({
    x <- seq(270,320,0.01)
    wt1 = input$impactfunctionweight
    wt2 = 1 - wt1
    plot(x,wt1*sigmoid(x,input$sigmoidlimit,input$sigmoidsteepness,input$sigmoidmidpoint) + wt2*quadratic(x,input$quadraticlimit,input$quadraticshape,input$quadraticmidpoint), type="l", lwd=3, lty=1, col="red", xlim=c(270,320), ylim=c(-100,100), xlab="Daily Maximum Surface Temperature (degK)", ylab="Relative Impact")
  })

  # Asset-value damage
  output$adaptationplot2 <- renderPlot({
    x <- seq(270,320,0.1)
    nadaptplans = 2
   
  # Asset risk below is sum of values by asset, weighted by sensitivity to given impact function.  Sensitivity varies with adaptation plan.
  #   Impact functions give percent impact, so we allow different assets to have different sensitivities to a given impact function.
  #   This is a simplified way to get different impacts by scaling by asset type; ideally, they would have different impact functions. 
  #   This is also a simplified (linear) way to connect asset value with loss of capacity or condition in the impact function.

    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    labels <- c("No Adaptation","Adaptation Plan 1","Adaptation Plan 2")
    plot(impactbyperiod_relative2baseperiod, type="l", lwd=3, lty=1, col=colors[1], xlab="Periods", ylab="Impact on Asset Value ($M)", xaxt="n")
	axis(1, at=c(1:length(periods)), labels=periods)
    lines(impactbyperiod_relative2baseperiod_plan1, type="l", lwd=3, lty=1, col=colors[3])
    lines(impactbyperiod_relative2baseperiod_plan2, type="l", lwd=3, lty=1, col=colors[5])
    legend("topright", inset=.01, title="Scenarios", labels, lwd=3, lty=c(1,1,1), col=c(colors[1],colors[3],colors[5]))
  })

  # Adaptation-plan benefits.
  # Benefit for plan i = Sum(over periods j) [ (impact_no_adapt(period j) - impact_plan_i(period j)) / (1+discount_rate)^j ]
  output$adaptationbenefit1 <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    discount <- input$discount2
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}

    benefitbydecade_plan1 <- initializer
    for(i in 1:length(benefitbydecade_plan1)) {benefitbydecade_plan1[i] = impactbyperiod_relative2noadaptation_plan1[i] / ((1+discountbydecade[i])^i) }
    benefit_plan1 = sum(benefitbydecade_plan1)

    totalcost = (input$cost2implement_plan1 + input$cost2maintain_relative2base_plan1)
    benefit2cost = benefit_plan1 / totalcost

    paste("Adaptation Plan 1 - Benefit, Cost, and B/C Ratio:  ", round(benefit_plan1, digits=2), "$M ,", round(totalcost, digits=2), "$M ,",round(benefit2cost, digits=2) )
  })

  output$adaptationbenefit2 <- renderText({
    x <- seq(275,315,0.1)
    source("./functions/damage_impacts_adaptation.r", local=TRUE)

    discount <- input$discount3
    discountbydecade <- initializer
    discountbydecade[1] = 1 / ((1+discount)^10)
    for(i in 2:length(discountbydecade)) {discountbydecade[i] = discountbydecade[1]^i}

    benefitbydecade_plan2 <- initializer
    for(i in 1:length(benefitbydecade_plan2)) {benefitbydecade_plan2[i] = impactbyperiod_relative2noadaptation_plan2[i] / ((1+discountbydecade[i])^i) }
    benefit_plan2 = sum(benefitbydecade_plan2)

    totalcost = (input$cost2implement_plan2 + input$cost2maintain_relative2base_plan2)
    benefit2cost = benefit_plan2 / totalcost

    paste("Adaptation Plan 2 - Benefit, Cost, and B/C Ratio:  ", round(benefit_plan2, digits=2), "$M ,", round(totalcost, digits=2), "$M ,",round(benefit2cost, digits=2) )
  })

  output$database1_name <- renderText({
    source("./data/users/load_database_users.r", local=TRUE)
    db = dbname
    paste("Database 1:  ", db)
  })

  output$database2_name <- renderText({
    source("./data/users/load_dbsqlite_test.r", local=TRUE)
    db = dbtitle
    paste("Database 2:  ", db)
  })

  output$database2_table12_contents <- renderText({
    source("./data/users/load_dbsqlite_test.r", local=TRUE)
    paste("Contents of table",table12," :  ", qlist)
  })

  output$database2_write <- renderText({
    # XXX next make the sourcing of the write script dependent on an input variable.
    if(input$write_new_table=="Yes") {source("./data/users/write_dbsqlite_test.r", local=TRUE)}
    paste("New table created.")
  })


# -----------
# Links
# -----------
    #googleurl <- a("Google Homepage", href="https://www.google.com/")
    #output$googlelink <- renderUI({ tagList("URL link:", googleurl) })
    output$googlelink <- renderUI({ tags$a("Google Search", href="https:www.google.com", target="_blank") })
    output$ndgain_countries <- renderUI({ tags$a("ND-GAIN Country Index", href="https://gain.nd.edu/our-work/country-index/rankings/", target="_blank") })
    output$actuaries_climate_index <- renderUI({ tags$a("Actuaries Climate Index", href="http://actuariesclimateindex.org/explore/regional-graphs/", target="_blank") })
    output$worldbank_development_indicators <- renderUI({ tags$a("World Bank Development Indicators", href="http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators", target="_blank") })

# Terry -----------------------------------------------------------


} # end server


